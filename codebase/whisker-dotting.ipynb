{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# Arash SC create a project for head position\n",
    "\n",
    "\n",
    "\n",
    "This notebook demonstrates the necessary steps to use python and DeepLabCut for creating and analysins videos from orientation \n",
    "experiment \n",
    "\n",
    "This notebook illustrates how to:\n",
    " \n",
    "- make a movie from images \n",
    "- create a project\n",
    "- extract training frames\n",
    "- label the frames\n",
    "- plot the labeled images (optional)\n",
    "- create a training set\n",
    "- train a network\n",
    "- evaluate a network\n",
    "- analyze a novel video\n",
    "- create an automatically labeled video (optional)\n",
    "- Go to Matlab \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Create a new project\n",
    "\n",
    "It is always good idea to keep the projects seperate. This function creates a new project with subdirectories and a basic configuration file in the user defined directory otherwise the project is created in the current working directory.\n",
    "\n",
    "You can always add new videos to the project at any stage of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [],
   "source": [
    "import deeplabcut\n",
    "## https://github.com/AlexEMG/DeepLabCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task='ar21_07_06_20LR_R' # Enter the name of your experiment Task\n",
    "task='Sideview_Aug' \n",
    "task='Topview3435_FEB22' \n",
    "\n",
    "experimenter='Arash' # Enter the name of the experimenter\n",
    "Mainfolder =  'D:\\\\\\videos\\\\AR19distance\\\\2020_09_14_ 215321'; # Enter the name of the folder with images folders inside \n",
    "Mainfolder = 'F:\\\\videos\\\\ar34motor\\\\2022_02_04\\\\';\n",
    "filenames = ['130video.mp4','140video.mp4','19video.mp4','24video.mp4','60video.mp4','33video.mp4']; # Enter the name of the files you want to train\n",
    "video = [str(Mainfolder)+str(f) for f in filenames]; # add path to each file\n",
    "Mainfolder2 = 'F:\\\\videos\\\\ar35motor\\\\2022_02_04\\\\';\n",
    "filenames2 = ['80video.mp4','90video.mp4','44video.mp4','40video.mp4','287video.mp4','286video.mp4']; # Enter the name of the files you want to train\n",
    "video2 = [str(Mainfolder2)+str(f) for f in filenames2]; # add path to each file\n",
    "video = video+video2\n",
    "#Mainfolder3 = 'D:\\\\Sidevideos\\\\ar343rdday\\\\2021_07_16\\\\';\n",
    "\n",
    "#filenames2 = ['22.avi','24.avi','25.avi']; # Enter the name of the files you want to train\n",
    "#video2 = [str(Mainfolder3)+str(f) for f in filenames2]; # add path to each file\n",
    "#video = video+video2\n",
    "\n",
    "print(video)\n",
    "#deeplabcut.create_new_project(task,experimenter,video, working_directory=Mainfolder,copy_videos=False) #change the working directory to where you want the folders created.\n",
    "deeplabcut.create_new_project(task,experimenter, video, working_directory='D:\\\\Sidevideos\\\\DLC',copy_videos=True, multianimal=False)\n",
    "#deeplabcut.create_new_project(task,experimenter, video,copy_videos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yXW0bx1oEJA"
   },
   "source": [
    "## Extract frames from videos \n",
    "A key point for a successful feature detector is to select diverse frames, which are typical for the behavior you study that should be labeled.\n",
    "\n",
    "This function selects N frames either uniformly sampled from a particular video (or folder) (algo=='uniform'). Note: this might not yield diverse frames, if the behavior is sparsely distributed (consider using kmeans), and/or select frames manually etc.\n",
    "\n",
    "Also make sure to get select data from different (behavioral) sessions and different animals if those vary substantially (to train an invariant feature detector).\n",
    "\n",
    "Individual images should not be too big (i.e. < 850 x 850 pixel). Although this can be taken care of later as well, it is advisable to crop the frames, to remove unnecessary parts of the frame as much as possible.\n",
    "\n",
    "Always check the output of cropping. If you are happy with the results proceed to labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1ulumCuoEJC"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "wrapped C/C++ object of type FileDialog has been deleted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\frame_extraction_toolbox.py\u001b[0m in \u001b[0;36mbrowseDir\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[0mdlg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDestroy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[0mdlg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDestroy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m         \u001b[0mselectedvideo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideo_source\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: wrapped C/C++ object of type FileDialog has been deleted"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face2-Arash-2020-09-15\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar32_10_09_20Face3-Arash-2020-10-10\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar30_10_10_14spouts-Arash-2020-10-24\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\ar32_10_11_12-Arash-2020-11-14\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\ar302_10_11_14-Arash-2020-11-16\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\ar32_10_11_24-Arash-2020-11-25\\\\config.yaml';\n",
    "path_config_file ='D:\\\\Sidevideos\\\\DLC\\\\Sideview_Aug-Arash-2021-08-04\\\\config.yaml';\n",
    "path_config_file ='D:\\\\Sidevideos\\\\DLC\\\\Topview3435_FEB22-Arash-2022-02-06\\\\config.yaml';\n",
    "path_config_file ='F:\\\\videos\\\\Ar30motor\\\\2021_08_03_184113\\\\ar30shiwker-Arash-2021-09-13\\\\config.yaml';#deeplabcut.extract_frames(path_config_file,'automatic','uniform',crop=True) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n",
    "#deeplabcut.extract_frames(path_config_file,'automatic','uniform',crop=True, checkcropping=True) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n",
    "#You can change the cropping to false, then delete the checkcropping part!\n",
    "deeplabcut.extract_frames(path_config_file,'manual',crop=True) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the config path and load deeplabcut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the Path config file path\n",
    "path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19LR_R-Arash-2020-04-30\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar21\\\\2020-07-06\\\\ar21_07_06_20Face2-Arash-2020-07-07\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face3-Arash-2020-09-16\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\2020_10_09\\\\ar32_10_09_20Face3-Arash-2020-10-10\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\notebook\\\\ar30_10_10_14spouts-Arash-2020-10-24\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar30\\\\ar30_10_11_04-Arash-2020-11-05\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\ar32_10_11_12-Arash-2020-11-14\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\ar302_10_11_14-Arash-2020-11-16\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\ar32_10_11_24-Arash-2020-11-25\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\ar32_10_11_24-Arash-2020-11-25\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\Sideview4-Arash-2021-07-18\\\\config.yaml'\n",
    "path_config_file = 'D:\\\\Sidevideos\\\\DLC\\\\Sideview4-Arash-2021-07-18\\\\config.yaml'\n",
    "\n",
    "path_config_file ='D:\\\\Sidevideos\\\\DLC\\\\Sideview_Aug-Arash-2021-08-04\\\\config.yaml';\n",
    "path_config_file ='D:\\\\Sidevideos\\\\DLC\\\\Topview3435_FEB22-Arash-2022-02-06\\\\config.yaml';\n",
    "path_config_file ='E:\\\\DLC\\\\SideviewLeft_Feb2022-Arash-2022-02-08\\\\config.yaml';\n",
    "\n",
    "path_config_file ='F:\\\\videos\\\\Ar30motor\\\\2021_08_03_184113\\\\ar30shiwker-Arash-2021-09-13\\\\config.yaml';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add videos from other folders and rats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying the videos\n",
      "Copying the videos\n",
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n"
     ]
    }
   ],
   "source": [
    "Mainfolder =  'F:\\\\videos\\\\ar35motor\\\\2022_02_04\\\\'; # Enter the name of the folder with images folders inside \n",
    "filenames = ['Mask96videoL.avi','Mirror96videoR.avi','Mask97videoL.avi','Mirror97videoR.avi',]; # Enter the name of the files you want to train\n",
    "#filenames = ['6L.avi']; # Enter the name of the files you want to train\n",
    "video = [str(Mainfolder)+str(f) for f in filenames]; # add path to each file\n",
    "Mainfolder2 = 'F:\\\\videos\\\\ar34Motor\\\\2022_02_04\\\\';\n",
    "filenames2 = ['Mask96videoL.avi','Mirror96videoR.avi','Mask94videoL.avi','Mirror94videoR.avi',]; # Enter the name of the files you want to train\n",
    "video2 = [str(Mainfolder2)+str(f) for f in filenames2]; # add path to each file\n",
    "video = video+video2\n",
    "deeplabcut.add_new_videos(path_config_file, video, copy_videos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gjn6ZDonoEJH"
   },
   "source": [
    "## Label the extracted frames\n",
    "Only videos in the config file can be used to extract the frames. Extracted labels for each video are stored in the project directory under the subdirectory **'labeled-data'**. Each subdirectory is named after the name of the video. The toolbox has a labeling toolbox which could be used for labeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyROSOiEoEJI"
   },
   "outputs": [],
   "source": [
    "%gui wx\n",
    "\n",
    "deeplabcut.label_frames(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vim95ZvkPSeN"
   },
   "source": [
    "**Check the labels**\n",
    "\n",
    "Checking if the labels were created and stored correctly is beneficial for training, since labeling is one of the most critical parts for creating the training dataset. The DeepLabCut toolbox provides a function `check\\_labels'  to do so. It is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwvgPJouPP2O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Arash.\n",
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\labeled-data\\Mirror5R_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 23.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\labeled-data\\Mirror21R_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 23.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\labeled-data\\Mask5L_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 26.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\labeled-data\\Mask31L_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 26.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\labeled-data\\Mask22L_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 24.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 44.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention: F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\labeled-data\\Mirror96videoR does not appear to have labeled data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 25.30it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 47.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 41.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 41.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add_new_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mainfolder =  'D:\\\\videos\\\\ar32\\\\2020_11_12\\\\'; # Enter the name of the folder with images folders inside \n",
    "filenames = ['158.avi','160.avi']; # Enter the name of the files you want to train\n",
    "#filenames = ['6L.avi']; # Enter the name of the files you want to train\n",
    "video = [str(Mainfolder)+str(f) for f in filenames]; # add path to each file\n",
    "deeplabcut.add_new_videos(path_config_file, video, copy_videos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder: Build your skeleton connections before you create a training set!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\ipykernel\\eventloops.py\u001b[0m in \u001b[0;36mon_timer\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mdef\u001b[0m \u001b[0mon_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<deeplabcut.utils.skeleton.SkeletonBuilder at 0x19350436cc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.SkeletonBuilder(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "of87fOjgPqzH"
   },
   "source": [
    "If the labels need adjusted, you can use the refinement GUI to move them around! Check that out below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "This function generates the training data information for DeepCut (which requires a mat file) based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles. \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\training-datasets\\iteration-0\\UnaugmentedDataSet_ar30shiwkerSep13  already exists!\n",
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\labeled-data\\Mirror96videoR\\CollectedData_Arash.h5  not found (perhaps not annotated). If training on cropped data, make sure to call `cropimagesandlabels` prior to creating the dataset.\n",
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\dlc-models\\iteration-0\\ar30shiwkerSep13-trainset95shuffle1  already exists!\n",
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\dlc-models\\iteration-0\\ar30shiwkerSep13-trainset95shuffle1/train  already exists!\n",
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\dlc-models\\iteration-0\\ar30shiwkerSep13-trainset95shuffle1/test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([ 23,  19,  77,  91,  65,  53,   2,  89, 108,  49,   1,  88,  85,\n",
       "           72,  81,  59,  71,  48,  51,  67,  35,  15,  36,  40,  17,  83,\n",
       "          106,  99,  13,  27,  97,  14,  43, 110,   9,  79,  76,  52,  11,\n",
       "           90,  62,  98,  61,  24,  87,  29,  12,  94,  82, 101,  41, 103,\n",
       "           93,   7,  60,  96,  57,  20,  69,  54,   6,  68,  34,  78, 102,\n",
       "           38,  32, 100,  73,   8, 104,  63,  70,  25,  26,  21,  16,  44,\n",
       "           28,  18,  31,  45,  47, 105,  58,  84,  33,   5,  50,  37,   0,\n",
       "           55,   3,  66,  75,  80,  22,  74, 107, 109,  92,  95,   4,  10,\n",
       "           46,  39]), array([ 30,  64,  56,  42,  86, 111])))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\training-datasets\\iteration-0\\UnaugmentedDataSet_ar30shiwkerSep13  already exists!\n",
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\training-datasets\\iteration-0\\UnaugmentedDataSet_ar30shiwkerSep13  already exists!\n",
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\labeled-data\\Mirror96videoR\\CollectedData_Arash.h5  not found (perhaps not annotated). If training on cropped data, make sure to call `cropimagesandlabels` prior to creating the dataset.\n",
      "You passed a split with the following fraction: 95%\n",
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\dlc-models\\iteration-0\\ar30shiwkerSep13-trainset95shuffle3  already exists!\n",
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\dlc-models\\iteration-0\\ar30shiwkerSep13-trainset95shuffle3/train  already exists!\n",
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\dlc-models\\iteration-0\\ar30shiwkerSep13-trainset95shuffle3/test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n",
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\training-datasets\\iteration-0\\UnaugmentedDataSet_ar30shiwkerSep13  already exists!\n",
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\labeled-data\\Mirror96videoR\\CollectedData_Arash.h5  not found (perhaps not annotated). If training on cropped data, make sure to call `cropimagesandlabels` prior to creating the dataset.\n",
      "You passed a split with the following fraction: 95%\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_training_model_comparison(path_config_file, num_shuffles=1, net_types=['resnet_50'], augmenter_types=['default', 'imgaug'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training  \n",
    "### If yu want to use your GPU, you need to exit here and either work from the Docker container, your own TensorFlow installation in an Anaconda env\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['w1', 'w2', 'w3', 'w4'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar30shiwkerSep13\\\\ar30shiwker_Arash95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Tennessee\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar30shiwkerSep13\\\\Documentation_data-ar30shiwker_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'F:\\\\videos\\\\Ar30motor\\\\2021_08_03_184113\\\\ar30shiwker-Arash-2021-09-13',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'F:\\\\videos\\\\Ar30motor\\\\2021_08_03_184113\\\\ar30shiwker-Arash-2021-09-13\\\\dlc-models\\\\iteration-0\\\\ar30shiwkerSep13-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching batchsize to 1, as default/tensorpack/deterministic loaders do not support batches >1. Use imgaug loader.\n",
      "Starting with standard pose-dataset loader.\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Display_iters overwritten as 1000\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'F:\\\\videos\\\\Ar30motor\\\\2021_08_03_184113\\\\ar30shiwker-Arash-2021-09-13\\\\dlc-models\\\\iteration-0\\\\ar30shiwkerSep13-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'weigh_only_present_joints': False, 'pairwise_huber_loss': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['w1', 'w2', 'w3', 'w4'], 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar30shiwkerSep13\\\\ar30shiwker_Arash95shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\Tennessee\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar30shiwkerSep13\\\\Documentation_data-ar30shiwker_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': 'F:\\\\videos\\\\Ar30motor\\\\2021_08_03_184113\\\\ar30shiwker-Arash-2021-09-13', 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000 loss: 0.0219 lr: 0.005\n",
      "iteration: 2000 loss: 0.0100 lr: 0.005\n",
      "iteration: 3000 loss: 0.0082 lr: 0.005\n",
      "iteration: 4000 loss: 0.0075 lr: 0.005\n",
      "iteration: 5000 loss: 0.0069 lr: 0.005\n",
      "iteration: 6000 loss: 0.0066 lr: 0.005\n",
      "iteration: 7000 loss: 0.0063 lr: 0.005\n",
      "iteration: 8000 loss: 0.0062 lr: 0.005\n",
      "iteration: 9000 loss: 0.0059 lr: 0.005\n",
      "iteration: 10000 loss: 0.0060 lr: 0.005\n",
      "iteration: 11000 loss: 0.0086 lr: 0.02\n",
      "iteration: 12000 loss: 0.0076 lr: 0.02\n",
      "iteration: 13000 loss: 0.0067 lr: 0.02\n",
      "iteration: 14000 loss: 0.0067 lr: 0.02\n",
      "iteration: 15000 loss: 0.0063 lr: 0.02\n",
      "iteration: 16000 loss: 0.0059 lr: 0.02\n",
      "iteration: 17000 loss: 0.0058 lr: 0.02\n",
      "iteration: 18000 loss: 0.0057 lr: 0.02\n",
      "iteration: 19000 loss: 0.0055 lr: 0.02\n",
      "iteration: 20000 loss: 0.0055 lr: 0.02\n",
      "iteration: 21000 loss: 0.0054 lr: 0.02\n",
      "iteration: 22000 loss: 0.0054 lr: 0.02\n",
      "iteration: 23000 loss: 0.0051 lr: 0.02\n",
      "iteration: 24000 loss: 0.0051 lr: 0.02\n",
      "iteration: 25000 loss: 0.0051 lr: 0.02\n",
      "iteration: 26000 loss: 0.0051 lr: 0.02\n",
      "iteration: 27000 loss: 0.0049 lr: 0.02\n",
      "iteration: 28000 loss: 0.0048 lr: 0.02\n",
      "iteration: 29000 loss: 0.0047 lr: 0.02\n",
      "iteration: 30000 loss: 0.0047 lr: 0.02\n",
      "iteration: 31000 loss: 0.0048 lr: 0.02\n",
      "iteration: 32000 loss: 0.0047 lr: 0.02\n",
      "iteration: 33000 loss: 0.0047 lr: 0.02\n",
      "iteration: 34000 loss: 0.0046 lr: 0.02\n",
      "iteration: 35000 loss: 0.0046 lr: 0.02\n",
      "iteration: 36000 loss: 0.0044 lr: 0.02\n",
      "iteration: 37000 loss: 0.0043 lr: 0.02\n",
      "iteration: 38000 loss: 0.0044 lr: 0.02\n",
      "iteration: 39000 loss: 0.0041 lr: 0.02\n",
      "iteration: 40000 loss: 0.0041 lr: 0.02\n",
      "iteration: 41000 loss: 0.0040 lr: 0.02\n",
      "iteration: 42000 loss: 0.0041 lr: 0.02\n",
      "iteration: 43000 loss: 0.0040 lr: 0.02\n",
      "iteration: 44000 loss: 0.0040 lr: 0.02\n",
      "iteration: 45000 loss: 0.0038 lr: 0.02\n",
      "iteration: 46000 loss: 0.0037 lr: 0.02\n",
      "iteration: 47000 loss: 0.0038 lr: 0.02\n",
      "iteration: 48000 loss: 0.0038 lr: 0.02\n",
      "iteration: 49000 loss: 0.0038 lr: 0.02\n",
      "iteration: 50000 loss: 0.0038 lr: 0.02\n",
      "iteration: 51000 loss: 0.0035 lr: 0.02\n",
      "iteration: 52000 loss: 0.0037 lr: 0.02\n",
      "iteration: 53000 loss: 0.0037 lr: 0.02\n",
      "iteration: 54000 loss: 0.0035 lr: 0.02\n",
      "iteration: 55000 loss: 0.0036 lr: 0.02\n",
      "iteration: 56000 loss: 0.0035 lr: 0.02\n",
      "iteration: 57000 loss: 0.0035 lr: 0.02\n",
      "iteration: 58000 loss: 0.0034 lr: 0.02\n",
      "iteration: 59000 loss: 0.0034 lr: 0.02\n",
      "iteration: 60000 loss: 0.0033 lr: 0.02\n",
      "iteration: 61000 loss: 0.0033 lr: 0.02\n",
      "iteration: 62000 loss: 0.0033 lr: 0.02\n",
      "iteration: 63000 loss: 0.0033 lr: 0.02\n",
      "iteration: 64000 loss: 0.0032 lr: 0.02\n",
      "iteration: 65000 loss: 0.0033 lr: 0.02\n",
      "iteration: 66000 loss: 0.0032 lr: 0.02\n",
      "iteration: 67000 loss: 0.0031 lr: 0.02\n",
      "iteration: 68000 loss: 0.0030 lr: 0.02\n",
      "iteration: 69000 loss: 0.0030 lr: 0.02\n",
      "iteration: 70000 loss: 0.0031 lr: 0.02\n",
      "iteration: 71000 loss: 0.0031 lr: 0.02\n",
      "iteration: 72000 loss: 0.0029 lr: 0.02\n",
      "iteration: 73000 loss: 0.0029 lr: 0.02\n",
      "iteration: 74000 loss: 0.0028 lr: 0.02\n",
      "iteration: 75000 loss: 0.0027 lr: 0.02\n",
      "iteration: 76000 loss: 0.0027 lr: 0.02\n",
      "iteration: 77000 loss: 0.0028 lr: 0.02\n",
      "iteration: 78000 loss: 0.0027 lr: 0.02\n",
      "iteration: 79000 loss: 0.0027 lr: 0.02\n",
      "iteration: 80000 loss: 0.0026 lr: 0.02\n",
      "iteration: 81000 loss: 0.0025 lr: 0.02\n",
      "iteration: 82000 loss: 0.0026 lr: 0.02\n",
      "iteration: 83000 loss: 0.0025 lr: 0.02\n",
      "iteration: 84000 loss: 0.0026 lr: 0.02\n",
      "iteration: 85000 loss: 0.0025 lr: 0.02\n",
      "iteration: 86000 loss: 0.0025 lr: 0.02\n",
      "iteration: 87000 loss: 0.0025 lr: 0.02\n",
      "iteration: 88000 loss: 0.0025 lr: 0.02\n",
      "iteration: 89000 loss: 0.0025 lr: 0.02\n",
      "iteration: 90000 loss: 0.0024 lr: 0.02\n",
      "iteration: 91000 loss: 0.0024 lr: 0.02\n",
      "iteration: 92000 loss: 0.0024 lr: 0.02\n",
      "iteration: 93000 loss: 0.0025 lr: 0.02\n",
      "iteration: 94000 loss: 0.0024 lr: 0.02\n",
      "iteration: 95000 loss: 0.0024 lr: 0.02\n",
      "iteration: 96000 loss: 0.0024 lr: 0.02\n",
      "iteration: 97000 loss: 0.0023 lr: 0.02\n",
      "iteration: 98000 loss: 0.0023 lr: 0.02\n",
      "iteration: 99000 loss: 0.0024 lr: 0.02\n",
      "iteration: 100000 loss: 0.0023 lr: 0.02\n",
      "iteration: 101000 loss: 0.0023 lr: 0.02\n",
      "iteration: 102000 loss: 0.0023 lr: 0.02\n",
      "iteration: 103000 loss: 0.0022 lr: 0.02\n",
      "iteration: 104000 loss: 0.0024 lr: 0.02\n",
      "iteration: 105000 loss: 0.0022 lr: 0.02\n",
      "iteration: 106000 loss: 0.0022 lr: 0.02\n",
      "iteration: 107000 loss: 0.0024 lr: 0.02\n",
      "iteration: 108000 loss: 0.0023 lr: 0.02\n",
      "iteration: 109000 loss: 0.0023 lr: 0.02\n",
      "iteration: 110000 loss: 0.0022 lr: 0.02\n",
      "iteration: 111000 loss: 0.0022 lr: 0.02\n",
      "iteration: 112000 loss: 0.0022 lr: 0.02\n",
      "iteration: 113000 loss: 0.0022 lr: 0.02\n",
      "iteration: 114000 loss: 0.0024 lr: 0.02\n",
      "iteration: 115000 loss: 0.0022 lr: 0.02\n",
      "iteration: 116000 loss: 0.0022 lr: 0.02\n",
      "iteration: 117000 loss: 0.0022 lr: 0.02\n",
      "iteration: 118000 loss: 0.0022 lr: 0.02\n",
      "iteration: 119000 loss: 0.0022 lr: 0.02\n",
      "iteration: 120000 loss: 0.0021 lr: 0.02\n",
      "iteration: 121000 loss: 0.0021 lr: 0.02\n",
      "iteration: 122000 loss: 0.0021 lr: 0.02\n",
      "iteration: 123000 loss: 0.0022 lr: 0.02\n",
      "iteration: 124000 loss: 0.0021 lr: 0.02\n",
      "iteration: 125000 loss: 0.0022 lr: 0.02\n",
      "iteration: 126000 loss: 0.0021 lr: 0.02\n",
      "iteration: 127000 loss: 0.0021 lr: 0.02\n",
      "iteration: 128000 loss: 0.0021 lr: 0.02\n",
      "iteration: 129000 loss: 0.0021 lr: 0.02\n",
      "iteration: 130000 loss: 0.0021 lr: 0.02\n",
      "iteration: 131000 loss: 0.0020 lr: 0.02\n",
      "iteration: 132000 loss: 0.0021 lr: 0.02\n",
      "iteration: 133000 loss: 0.0021 lr: 0.02\n",
      "iteration: 134000 loss: 0.0021 lr: 0.02\n",
      "iteration: 135000 loss: 0.0021 lr: 0.02\n",
      "iteration: 136000 loss: 0.0021 lr: 0.02\n",
      "iteration: 137000 loss: 0.0021 lr: 0.02\n",
      "iteration: 138000 loss: 0.0020 lr: 0.02\n",
      "iteration: 139000 loss: 0.0020 lr: 0.02\n",
      "iteration: 140000 loss: 0.0022 lr: 0.02\n",
      "iteration: 141000 loss: 0.0020 lr: 0.02\n",
      "iteration: 142000 loss: 0.0020 lr: 0.02\n",
      "iteration: 143000 loss: 0.0020 lr: 0.02\n",
      "iteration: 144000 loss: 0.0020 lr: 0.02\n",
      "iteration: 145000 loss: 0.0020 lr: 0.02\n",
      "iteration: 146000 loss: 0.0022 lr: 0.02\n",
      "iteration: 147000 loss: 0.0020 lr: 0.02\n",
      "iteration: 148000 loss: 0.0020 lr: 0.02\n",
      "iteration: 149000 loss: 0.0020 lr: 0.02\n",
      "iteration: 150000 loss: 0.0020 lr: 0.02\n",
      "iteration: 151000 loss: 0.0021 lr: 0.02\n",
      "iteration: 152000 loss: 0.0019 lr: 0.02\n",
      "iteration: 153000 loss: 0.0019 lr: 0.02\n",
      "iteration: 154000 loss: 0.0019 lr: 0.02\n",
      "iteration: 155000 loss: 0.0019 lr: 0.02\n",
      "iteration: 156000 loss: 0.0021 lr: 0.02\n",
      "iteration: 157000 loss: 0.0020 lr: 0.02\n",
      "iteration: 158000 loss: 0.0019 lr: 0.02\n",
      "iteration: 159000 loss: 0.0018 lr: 0.02\n",
      "iteration: 160000 loss: 0.0018 lr: 0.02\n",
      "iteration: 161000 loss: 0.0019 lr: 0.02\n",
      "iteration: 162000 loss: 0.0019 lr: 0.02\n",
      "iteration: 163000 loss: 0.0019 lr: 0.02\n",
      "iteration: 164000 loss: 0.0018 lr: 0.02\n",
      "iteration: 165000 loss: 0.0019 lr: 0.02\n",
      "iteration: 166000 loss: 0.0018 lr: 0.02\n",
      "iteration: 167000 loss: 0.0019 lr: 0.02\n",
      "iteration: 168000 loss: 0.0019 lr: 0.02\n",
      "iteration: 169000 loss: 0.0018 lr: 0.02\n",
      "iteration: 170000 loss: 0.0018 lr: 0.02\n",
      "iteration: 171000 loss: 0.0018 lr: 0.02\n",
      "iteration: 172000 loss: 0.0018 lr: 0.02\n",
      "iteration: 173000 loss: 0.0017 lr: 0.02\n",
      "iteration: 174000 loss: 0.0019 lr: 0.02\n",
      "iteration: 175000 loss: 0.0019 lr: 0.02\n",
      "iteration: 176000 loss: 0.0018 lr: 0.02\n",
      "iteration: 177000 loss: 0.0019 lr: 0.02\n",
      "iteration: 178000 loss: 0.0019 lr: 0.02\n",
      "iteration: 179000 loss: 0.0017 lr: 0.02\n",
      "iteration: 180000 loss: 0.0019 lr: 0.02\n",
      "iteration: 181000 loss: 0.0019 lr: 0.02\n",
      "iteration: 182000 loss: 0.0019 lr: 0.02\n",
      "iteration: 183000 loss: 0.0018 lr: 0.02\n",
      "iteration: 184000 loss: 0.0018 lr: 0.02\n",
      "iteration: 185000 loss: 0.0018 lr: 0.02\n",
      "iteration: 186000 loss: 0.0018 lr: 0.02\n",
      "iteration: 187000 loss: 0.0017 lr: 0.02\n",
      "iteration: 188000 loss: 0.0018 lr: 0.02\n",
      "iteration: 189000 loss: 0.0018 lr: 0.02\n",
      "iteration: 190000 loss: 0.0018 lr: 0.02\n",
      "iteration: 191000 loss: 0.0018 lr: 0.02\n",
      "iteration: 192000 loss: 0.0018 lr: 0.02\n",
      "iteration: 193000 loss: 0.0018 lr: 0.02\n",
      "iteration: 194000 loss: 0.0018 lr: 0.02\n",
      "iteration: 195000 loss: 0.0017 lr: 0.02\n",
      "iteration: 196000 loss: 0.0017 lr: 0.02\n",
      "iteration: 197000 loss: 0.0018 lr: 0.02\n",
      "iteration: 198000 loss: 0.0017 lr: 0.02\n",
      "iteration: 199000 loss: 0.0017 lr: 0.02\n",
      "iteration: 200000 loss: 0.0017 lr: 0.02\n",
      "iteration: 201000 loss: 0.0017 lr: 0.02\n",
      "iteration: 202000 loss: 0.0017 lr: 0.02\n",
      "iteration: 203000 loss: 0.0017 lr: 0.02\n",
      "iteration: 204000 loss: 0.0017 lr: 0.02\n",
      "iteration: 205000 loss: 0.0017 lr: 0.02\n",
      "iteration: 206000 loss: 0.0017 lr: 0.02\n",
      "iteration: 207000 loss: 0.0017 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 208000 loss: 0.0017 lr: 0.02\n",
      "iteration: 209000 loss: 0.0017 lr: 0.02\n",
      "iteration: 210000 loss: 0.0017 lr: 0.02\n",
      "iteration: 211000 loss: 0.0018 lr: 0.02\n",
      "iteration: 212000 loss: 0.0016 lr: 0.02\n",
      "iteration: 213000 loss: 0.0017 lr: 0.02\n",
      "iteration: 214000 loss: 0.0018 lr: 0.02\n",
      "iteration: 215000 loss: 0.0017 lr: 0.02\n",
      "iteration: 216000 loss: 0.0018 lr: 0.02\n",
      "iteration: 217000 loss: 0.0017 lr: 0.02\n",
      "iteration: 218000 loss: 0.0017 lr: 0.02\n",
      "iteration: 219000 loss: 0.0017 lr: 0.02\n",
      "iteration: 220000 loss: 0.0017 lr: 0.02\n",
      "iteration: 221000 loss: 0.0017 lr: 0.02\n",
      "iteration: 222000 loss: 0.0018 lr: 0.02\n",
      "iteration: 223000 loss: 0.0017 lr: 0.02\n",
      "iteration: 224000 loss: 0.0016 lr: 0.02\n",
      "iteration: 225000 loss: 0.0018 lr: 0.02\n",
      "iteration: 226000 loss: 0.0017 lr: 0.02\n",
      "iteration: 227000 loss: 0.0017 lr: 0.02\n",
      "iteration: 228000 loss: 0.0016 lr: 0.02\n",
      "iteration: 229000 loss: 0.0017 lr: 0.02\n",
      "iteration: 230000 loss: 0.0017 lr: 0.02\n",
      "iteration: 231000 loss: 0.0017 lr: 0.02\n",
      "iteration: 232000 loss: 0.0017 lr: 0.02\n",
      "iteration: 233000 loss: 0.0017 lr: 0.02\n",
      "iteration: 234000 loss: 0.0016 lr: 0.02\n",
      "iteration: 235000 loss: 0.0016 lr: 0.02\n",
      "iteration: 236000 loss: 0.0015 lr: 0.02\n",
      "iteration: 237000 loss: 0.0016 lr: 0.02\n",
      "iteration: 238000 loss: 0.0016 lr: 0.02\n",
      "iteration: 239000 loss: 0.0016 lr: 0.02\n",
      "iteration: 240000 loss: 0.0017 lr: 0.02\n",
      "iteration: 241000 loss: 0.0016 lr: 0.02\n",
      "iteration: 242000 loss: 0.0016 lr: 0.02\n",
      "iteration: 243000 loss: 0.0016 lr: 0.02\n",
      "iteration: 244000 loss: 0.0016 lr: 0.02\n",
      "iteration: 245000 loss: 0.0016 lr: 0.02\n",
      "iteration: 246000 loss: 0.0016 lr: 0.02\n",
      "iteration: 247000 loss: 0.0016 lr: 0.02\n",
      "iteration: 248000 loss: 0.0015 lr: 0.02\n",
      "iteration: 249000 loss: 0.0016 lr: 0.02\n",
      "iteration: 250000 loss: 0.0015 lr: 0.02\n",
      "iteration: 251000 loss: 0.0017 lr: 0.02\n",
      "iteration: 252000 loss: 0.0015 lr: 0.02\n",
      "iteration: 253000 loss: 0.0016 lr: 0.02\n",
      "iteration: 254000 loss: 0.0016 lr: 0.02\n",
      "iteration: 255000 loss: 0.0016 lr: 0.02\n",
      "iteration: 256000 loss: 0.0015 lr: 0.02\n",
      "iteration: 257000 loss: 0.0016 lr: 0.02\n",
      "iteration: 258000 loss: 0.0016 lr: 0.02\n",
      "iteration: 259000 loss: 0.0015 lr: 0.02\n",
      "iteration: 260000 loss: 0.0016 lr: 0.02\n",
      "iteration: 261000 loss: 0.0016 lr: 0.02\n",
      "iteration: 262000 loss: 0.0016 lr: 0.02\n",
      "iteration: 263000 loss: 0.0015 lr: 0.02\n",
      "iteration: 264000 loss: 0.0015 lr: 0.02\n",
      "iteration: 265000 loss: 0.0016 lr: 0.02\n",
      "iteration: 266000 loss: 0.0015 lr: 0.02\n",
      "iteration: 267000 loss: 0.0015 lr: 0.02\n",
      "iteration: 268000 loss: 0.0015 lr: 0.02\n",
      "iteration: 269000 loss: 0.0016 lr: 0.02\n",
      "iteration: 270000 loss: 0.0014 lr: 0.02\n",
      "iteration: 271000 loss: 0.0015 lr: 0.02\n",
      "iteration: 272000 loss: 0.0016 lr: 0.02\n",
      "iteration: 273000 loss: 0.0016 lr: 0.02\n",
      "iteration: 274000 loss: 0.0016 lr: 0.02\n",
      "iteration: 275000 loss: 0.0015 lr: 0.02\n",
      "iteration: 276000 loss: 0.0015 lr: 0.02\n",
      "iteration: 277000 loss: 0.0015 lr: 0.02\n",
      "iteration: 278000 loss: 0.0015 lr: 0.02\n",
      "iteration: 279000 loss: 0.0016 lr: 0.02\n",
      "iteration: 280000 loss: 0.0015 lr: 0.02\n",
      "iteration: 281000 loss: 0.0016 lr: 0.02\n",
      "iteration: 282000 loss: 0.0016 lr: 0.02\n",
      "iteration: 283000 loss: 0.0016 lr: 0.02\n",
      "iteration: 284000 loss: 0.0015 lr: 0.02\n",
      "iteration: 285000 loss: 0.0015 lr: 0.02\n",
      "iteration: 286000 loss: 0.0015 lr: 0.02\n",
      "iteration: 287000 loss: 0.0015 lr: 0.02\n",
      "iteration: 288000 loss: 0.0015 lr: 0.02\n",
      "iteration: 289000 loss: 0.0015 lr: 0.02\n",
      "iteration: 290000 loss: 0.0015 lr: 0.02\n",
      "iteration: 291000 loss: 0.0016 lr: 0.02\n",
      "iteration: 292000 loss: 0.0015 lr: 0.02\n",
      "iteration: 293000 loss: 0.0016 lr: 0.02\n",
      "iteration: 294000 loss: 0.0015 lr: 0.02\n",
      "iteration: 295000 loss: 0.0015 lr: 0.02\n",
      "iteration: 296000 loss: 0.0015 lr: 0.02\n",
      "iteration: 297000 loss: 0.0015 lr: 0.02\n",
      "iteration: 298000 loss: 0.0015 lr: 0.02\n",
      "iteration: 299000 loss: 0.0015 lr: 0.02\n",
      "iteration: 300000 loss: 0.0014 lr: 0.02\n",
      "iteration: 301000 loss: 0.0016 lr: 0.02\n",
      "iteration: 302000 loss: 0.0015 lr: 0.02\n",
      "iteration: 303000 loss: 0.0014 lr: 0.02\n",
      "iteration: 304000 loss: 0.0014 lr: 0.02\n",
      "iteration: 305000 loss: 0.0014 lr: 0.02\n",
      "iteration: 306000 loss: 0.0015 lr: 0.02\n",
      "iteration: 307000 loss: 0.0014 lr: 0.02\n",
      "iteration: 308000 loss: 0.0016 lr: 0.02\n",
      "iteration: 309000 loss: 0.0015 lr: 0.02\n",
      "iteration: 310000 loss: 0.0014 lr: 0.02\n",
      "iteration: 311000 loss: 0.0016 lr: 0.02\n",
      "iteration: 312000 loss: 0.0014 lr: 0.02\n",
      "iteration: 313000 loss: 0.0015 lr: 0.02\n",
      "iteration: 314000 loss: 0.0015 lr: 0.02\n",
      "iteration: 315000 loss: 0.0015 lr: 0.02\n",
      "iteration: 316000 loss: 0.0014 lr: 0.02\n",
      "iteration: 317000 loss: 0.0015 lr: 0.02\n",
      "iteration: 318000 loss: 0.0014 lr: 0.02\n",
      "iteration: 319000 loss: 0.0015 lr: 0.02\n",
      "iteration: 320000 loss: 0.0014 lr: 0.02\n",
      "iteration: 321000 loss: 0.0015 lr: 0.02\n",
      "iteration: 322000 loss: 0.0014 lr: 0.02\n",
      "iteration: 323000 loss: 0.0015 lr: 0.02\n",
      "iteration: 324000 loss: 0.0014 lr: 0.02\n",
      "iteration: 325000 loss: 0.0015 lr: 0.02\n",
      "iteration: 326000 loss: 0.0014 lr: 0.02\n",
      "iteration: 327000 loss: 0.0015 lr: 0.02\n",
      "iteration: 328000 loss: 0.0014 lr: 0.02\n",
      "iteration: 329000 loss: 0.0014 lr: 0.02\n",
      "iteration: 330000 loss: 0.0014 lr: 0.02\n",
      "iteration: 331000 loss: 0.0014 lr: 0.02\n",
      "iteration: 332000 loss: 0.0014 lr: 0.02\n",
      "iteration: 333000 loss: 0.0015 lr: 0.02\n",
      "iteration: 334000 loss: 0.0015 lr: 0.02\n",
      "iteration: 335000 loss: 0.0014 lr: 0.02\n",
      "iteration: 336000 loss: 0.0014 lr: 0.02\n",
      "iteration: 337000 loss: 0.0014 lr: 0.02\n",
      "iteration: 338000 loss: 0.0014 lr: 0.02\n",
      "iteration: 339000 loss: 0.0014 lr: 0.02\n",
      "iteration: 340000 loss: 0.0013 lr: 0.02\n",
      "iteration: 341000 loss: 0.0014 lr: 0.02\n",
      "iteration: 342000 loss: 0.0014 lr: 0.02\n",
      "iteration: 343000 loss: 0.0014 lr: 0.02\n",
      "iteration: 344000 loss: 0.0014 lr: 0.02\n",
      "iteration: 345000 loss: 0.0015 lr: 0.02\n",
      "iteration: 346000 loss: 0.0013 lr: 0.02\n",
      "iteration: 347000 loss: 0.0014 lr: 0.02\n",
      "iteration: 348000 loss: 0.0014 lr: 0.02\n",
      "iteration: 349000 loss: 0.0014 lr: 0.02\n",
      "iteration: 350000 loss: 0.0014 lr: 0.02\n",
      "iteration: 351000 loss: 0.0014 lr: 0.02\n",
      "iteration: 352000 loss: 0.0014 lr: 0.02\n",
      "iteration: 353000 loss: 0.0014 lr: 0.02\n",
      "iteration: 354000 loss: 0.0014 lr: 0.02\n",
      "iteration: 355000 loss: 0.0014 lr: 0.02\n",
      "iteration: 356000 loss: 0.0014 lr: 0.02\n",
      "iteration: 357000 loss: 0.0014 lr: 0.02\n",
      "iteration: 358000 loss: 0.0014 lr: 0.02\n",
      "iteration: 359000 loss: 0.0014 lr: 0.02\n",
      "iteration: 360000 loss: 0.0014 lr: 0.02\n",
      "iteration: 361000 loss: 0.0014 lr: 0.02\n",
      "iteration: 362000 loss: 0.0015 lr: 0.02\n",
      "iteration: 363000 loss: 0.0013 lr: 0.02\n",
      "iteration: 364000 loss: 0.0014 lr: 0.02\n",
      "iteration: 365000 loss: 0.0014 lr: 0.02\n",
      "iteration: 366000 loss: 0.0013 lr: 0.02\n",
      "iteration: 367000 loss: 0.0013 lr: 0.02\n",
      "iteration: 368000 loss: 0.0013 lr: 0.02\n",
      "iteration: 369000 loss: 0.0014 lr: 0.02\n",
      "iteration: 370000 loss: 0.0014 lr: 0.02\n",
      "iteration: 371000 loss: 0.0014 lr: 0.02\n",
      "iteration: 372000 loss: 0.0014 lr: 0.02\n",
      "iteration: 373000 loss: 0.0014 lr: 0.02\n",
      "iteration: 374000 loss: 0.0014 lr: 0.02\n",
      "iteration: 375000 loss: 0.0014 lr: 0.02\n",
      "iteration: 376000 loss: 0.0014 lr: 0.02\n",
      "iteration: 377000 loss: 0.0014 lr: 0.02\n",
      "iteration: 378000 loss: 0.0014 lr: 0.02\n",
      "iteration: 379000 loss: 0.0014 lr: 0.02\n",
      "iteration: 380000 loss: 0.0014 lr: 0.02\n",
      "iteration: 381000 loss: 0.0013 lr: 0.02\n",
      "iteration: 382000 loss: 0.0013 lr: 0.02\n",
      "iteration: 383000 loss: 0.0014 lr: 0.02\n",
      "iteration: 384000 loss: 0.0013 lr: 0.02\n",
      "iteration: 385000 loss: 0.0014 lr: 0.02\n",
      "iteration: 386000 loss: 0.0014 lr: 0.02\n",
      "iteration: 387000 loss: 0.0014 lr: 0.02\n",
      "iteration: 388000 loss: 0.0013 lr: 0.02\n",
      "iteration: 389000 loss: 0.0013 lr: 0.02\n",
      "iteration: 390000 loss: 0.0014 lr: 0.02\n",
      "iteration: 391000 loss: 0.0013 lr: 0.02\n",
      "iteration: 392000 loss: 0.0014 lr: 0.02\n",
      "iteration: 393000 loss: 0.0014 lr: 0.02\n",
      "iteration: 394000 loss: 0.0014 lr: 0.02\n",
      "iteration: 395000 loss: 0.0014 lr: 0.02\n",
      "iteration: 396000 loss: 0.0014 lr: 0.02\n",
      "iteration: 397000 loss: 0.0013 lr: 0.02\n",
      "iteration: 398000 loss: 0.0013 lr: 0.02\n",
      "iteration: 399000 loss: 0.0013 lr: 0.02\n",
      "iteration: 400000 loss: 0.0013 lr: 0.02\n",
      "iteration: 401000 loss: 0.0013 lr: 0.02\n",
      "iteration: 402000 loss: 0.0013 lr: 0.02\n",
      "iteration: 403000 loss: 0.0013 lr: 0.02\n",
      "iteration: 404000 loss: 0.0014 lr: 0.02\n",
      "iteration: 405000 loss: 0.0013 lr: 0.02\n",
      "iteration: 406000 loss: 0.0013 lr: 0.02\n",
      "iteration: 407000 loss: 0.0013 lr: 0.02\n",
      "iteration: 408000 loss: 0.0013 lr: 0.02\n",
      "iteration: 409000 loss: 0.0014 lr: 0.02\n",
      "iteration: 410000 loss: 0.0014 lr: 0.02\n",
      "iteration: 411000 loss: 0.0013 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 412000 loss: 0.0013 lr: 0.02\n",
      "iteration: 413000 loss: 0.0014 lr: 0.02\n",
      "iteration: 414000 loss: 0.0013 lr: 0.02\n",
      "iteration: 415000 loss: 0.0013 lr: 0.02\n",
      "iteration: 416000 loss: 0.0013 lr: 0.02\n",
      "iteration: 417000 loss: 0.0014 lr: 0.02\n",
      "iteration: 418000 loss: 0.0013 lr: 0.02\n",
      "iteration: 419000 loss: 0.0013 lr: 0.02\n",
      "iteration: 420000 loss: 0.0013 lr: 0.02\n",
      "iteration: 421000 loss: 0.0013 lr: 0.02\n",
      "iteration: 422000 loss: 0.0013 lr: 0.02\n",
      "iteration: 423000 loss: 0.0013 lr: 0.02\n",
      "iteration: 424000 loss: 0.0013 lr: 0.02\n",
      "iteration: 425000 loss: 0.0013 lr: 0.02\n",
      "iteration: 426000 loss: 0.0013 lr: 0.02\n",
      "iteration: 427000 loss: 0.0013 lr: 0.02\n",
      "iteration: 428000 loss: 0.0012 lr: 0.02\n",
      "iteration: 429000 loss: 0.0012 lr: 0.02\n",
      "iteration: 430000 loss: 0.0013 lr: 0.02\n",
      "iteration: 431000 loss: 0.0011 lr: 0.002\n",
      "iteration: 432000 loss: 0.0010 lr: 0.002\n",
      "iteration: 433000 loss: 0.0010 lr: 0.002\n",
      "iteration: 434000 loss: 0.0010 lr: 0.002\n",
      "iteration: 435000 loss: 0.0009 lr: 0.002\n",
      "iteration: 436000 loss: 0.0010 lr: 0.002\n",
      "iteration: 437000 loss: 0.0009 lr: 0.002\n",
      "iteration: 438000 loss: 0.0009 lr: 0.002\n",
      "iteration: 439000 loss: 0.0010 lr: 0.002\n",
      "iteration: 440000 loss: 0.0009 lr: 0.002\n",
      "iteration: 441000 loss: 0.0009 lr: 0.002\n",
      "iteration: 442000 loss: 0.0009 lr: 0.002\n",
      "iteration: 443000 loss: 0.0009 lr: 0.002\n",
      "iteration: 444000 loss: 0.0010 lr: 0.002\n",
      "iteration: 445000 loss: 0.0009 lr: 0.002\n",
      "iteration: 446000 loss: 0.0009 lr: 0.002\n",
      "iteration: 447000 loss: 0.0009 lr: 0.002\n",
      "iteration: 448000 loss: 0.0009 lr: 0.002\n",
      "iteration: 449000 loss: 0.0009 lr: 0.002\n",
      "iteration: 450000 loss: 0.0009 lr: 0.002\n",
      "iteration: 451000 loss: 0.0009 lr: 0.002\n",
      "iteration: 452000 loss: 0.0009 lr: 0.002\n",
      "iteration: 453000 loss: 0.0009 lr: 0.002\n",
      "iteration: 454000 loss: 0.0009 lr: 0.002\n",
      "iteration: 455000 loss: 0.0009 lr: 0.002\n",
      "iteration: 456000 loss: 0.0009 lr: 0.002\n",
      "iteration: 457000 loss: 0.0010 lr: 0.002\n",
      "iteration: 458000 loss: 0.0009 lr: 0.002\n",
      "iteration: 459000 loss: 0.0009 lr: 0.002\n",
      "iteration: 460000 loss: 0.0009 lr: 0.002\n",
      "iteration: 461000 loss: 0.0009 lr: 0.002\n",
      "iteration: 462000 loss: 0.0009 lr: 0.002\n",
      "iteration: 463000 loss: 0.0009 lr: 0.002\n",
      "iteration: 464000 loss: 0.0009 lr: 0.002\n",
      "iteration: 465000 loss: 0.0009 lr: 0.002\n",
      "iteration: 466000 loss: 0.0009 lr: 0.002\n",
      "iteration: 467000 loss: 0.0008 lr: 0.002\n",
      "iteration: 468000 loss: 0.0009 lr: 0.002\n",
      "iteration: 469000 loss: 0.0009 lr: 0.002\n",
      "iteration: 470000 loss: 0.0009 lr: 0.002\n",
      "iteration: 471000 loss: 0.0009 lr: 0.002\n",
      "iteration: 472000 loss: 0.0008 lr: 0.002\n",
      "iteration: 473000 loss: 0.0009 lr: 0.002\n",
      "iteration: 474000 loss: 0.0009 lr: 0.002\n",
      "iteration: 475000 loss: 0.0009 lr: 0.002\n",
      "iteration: 476000 loss: 0.0009 lr: 0.002\n",
      "iteration: 477000 loss: 0.0009 lr: 0.002\n",
      "iteration: 478000 loss: 0.0009 lr: 0.002\n",
      "iteration: 479000 loss: 0.0009 lr: 0.002\n",
      "iteration: 480000 loss: 0.0008 lr: 0.002\n",
      "iteration: 481000 loss: 0.0009 lr: 0.002\n",
      "iteration: 482000 loss: 0.0008 lr: 0.002\n",
      "iteration: 483000 loss: 0.0009 lr: 0.002\n",
      "iteration: 484000 loss: 0.0009 lr: 0.002\n",
      "iteration: 485000 loss: 0.0008 lr: 0.002\n",
      "iteration: 486000 loss: 0.0009 lr: 0.002\n",
      "iteration: 487000 loss: 0.0008 lr: 0.002\n",
      "iteration: 488000 loss: 0.0008 lr: 0.002\n",
      "iteration: 489000 loss: 0.0008 lr: 0.002\n",
      "iteration: 490000 loss: 0.0008 lr: 0.002\n",
      "iteration: 491000 loss: 0.0008 lr: 0.002\n",
      "iteration: 492000 loss: 0.0009 lr: 0.002\n",
      "iteration: 493000 loss: 0.0008 lr: 0.002\n",
      "iteration: 494000 loss: 0.0008 lr: 0.002\n",
      "iteration: 495000 loss: 0.0009 lr: 0.002\n",
      "iteration: 496000 loss: 0.0008 lr: 0.002\n",
      "iteration: 497000 loss: 0.0008 lr: 0.002\n",
      "iteration: 498000 loss: 0.0008 lr: 0.002\n",
      "iteration: 499000 loss: 0.0008 lr: 0.002\n",
      "iteration: 500000 loss: 0.0008 lr: 0.002\n",
      "iteration: 501000 loss: 0.0009 lr: 0.002\n",
      "iteration: 502000 loss: 0.0008 lr: 0.002\n",
      "iteration: 503000 loss: 0.0009 lr: 0.002\n",
      "iteration: 504000 loss: 0.0008 lr: 0.002\n",
      "iteration: 505000 loss: 0.0009 lr: 0.002\n",
      "iteration: 506000 loss: 0.0008 lr: 0.002\n",
      "iteration: 507000 loss: 0.0008 lr: 0.002\n",
      "iteration: 508000 loss: 0.0008 lr: 0.002\n",
      "iteration: 509000 loss: 0.0008 lr: 0.002\n",
      "iteration: 510000 loss: 0.0008 lr: 0.002\n",
      "iteration: 511000 loss: 0.0008 lr: 0.002\n",
      "iteration: 512000 loss: 0.0008 lr: 0.002\n",
      "iteration: 513000 loss: 0.0008 lr: 0.002\n",
      "iteration: 514000 loss: 0.0008 lr: 0.002\n",
      "iteration: 515000 loss: 0.0008 lr: 0.002\n",
      "iteration: 516000 loss: 0.0008 lr: 0.002\n",
      "iteration: 517000 loss: 0.0008 lr: 0.002\n",
      "iteration: 518000 loss: 0.0008 lr: 0.002\n",
      "iteration: 519000 loss: 0.0008 lr: 0.002\n",
      "iteration: 520000 loss: 0.0008 lr: 0.002\n",
      "iteration: 521000 loss: 0.0009 lr: 0.002\n",
      "iteration: 522000 loss: 0.0008 lr: 0.002\n",
      "iteration: 523000 loss: 0.0008 lr: 0.002\n",
      "iteration: 524000 loss: 0.0008 lr: 0.002\n",
      "iteration: 525000 loss: 0.0008 lr: 0.002\n",
      "iteration: 526000 loss: 0.0009 lr: 0.002\n",
      "iteration: 527000 loss: 0.0008 lr: 0.002\n",
      "iteration: 528000 loss: 0.0008 lr: 0.002\n",
      "iteration: 529000 loss: 0.0008 lr: 0.002\n",
      "iteration: 530000 loss: 0.0008 lr: 0.002\n",
      "iteration: 531000 loss: 0.0008 lr: 0.002\n",
      "iteration: 532000 loss: 0.0008 lr: 0.002\n",
      "iteration: 533000 loss: 0.0009 lr: 0.002\n",
      "iteration: 534000 loss: 0.0008 lr: 0.002\n",
      "iteration: 535000 loss: 0.0008 lr: 0.002\n",
      "iteration: 536000 loss: 0.0008 lr: 0.002\n",
      "iteration: 537000 loss: 0.0008 lr: 0.002\n",
      "iteration: 538000 loss: 0.0008 lr: 0.002\n",
      "iteration: 539000 loss: 0.0008 lr: 0.002\n",
      "iteration: 540000 loss: 0.0008 lr: 0.002\n",
      "iteration: 541000 loss: 0.0008 lr: 0.002\n",
      "iteration: 542000 loss: 0.0008 lr: 0.002\n",
      "iteration: 543000 loss: 0.0008 lr: 0.002\n",
      "iteration: 544000 loss: 0.0008 lr: 0.002\n",
      "iteration: 545000 loss: 0.0008 lr: 0.002\n",
      "iteration: 546000 loss: 0.0008 lr: 0.002\n",
      "iteration: 547000 loss: 0.0008 lr: 0.002\n",
      "iteration: 548000 loss: 0.0008 lr: 0.002\n",
      "iteration: 549000 loss: 0.0008 lr: 0.002\n",
      "iteration: 550000 loss: 0.0008 lr: 0.002\n",
      "iteration: 551000 loss: 0.0008 lr: 0.002\n",
      "iteration: 552000 loss: 0.0008 lr: 0.002\n",
      "iteration: 553000 loss: 0.0008 lr: 0.002\n",
      "iteration: 554000 loss: 0.0008 lr: 0.002\n",
      "iteration: 555000 loss: 0.0008 lr: 0.002\n",
      "iteration: 556000 loss: 0.0008 lr: 0.002\n",
      "iteration: 557000 loss: 0.0009 lr: 0.002\n",
      "iteration: 558000 loss: 0.0008 lr: 0.002\n",
      "iteration: 559000 loss: 0.0008 lr: 0.002\n",
      "iteration: 560000 loss: 0.0008 lr: 0.002\n",
      "iteration: 561000 loss: 0.0008 lr: 0.002\n",
      "iteration: 562000 loss: 0.0008 lr: 0.002\n",
      "iteration: 563000 loss: 0.0008 lr: 0.002\n",
      "iteration: 564000 loss: 0.0008 lr: 0.002\n",
      "iteration: 565000 loss: 0.0008 lr: 0.002\n",
      "iteration: 566000 loss: 0.0008 lr: 0.002\n",
      "iteration: 567000 loss: 0.0008 lr: 0.002\n",
      "iteration: 568000 loss: 0.0008 lr: 0.002\n",
      "iteration: 569000 loss: 0.0008 lr: 0.002\n",
      "iteration: 570000 loss: 0.0008 lr: 0.002\n",
      "iteration: 571000 loss: 0.0008 lr: 0.002\n",
      "iteration: 572000 loss: 0.0008 lr: 0.002\n",
      "iteration: 573000 loss: 0.0009 lr: 0.002\n",
      "iteration: 574000 loss: 0.0008 lr: 0.002\n",
      "iteration: 575000 loss: 0.0008 lr: 0.002\n",
      "iteration: 576000 loss: 0.0008 lr: 0.002\n",
      "iteration: 577000 loss: 0.0008 lr: 0.002\n",
      "iteration: 578000 loss: 0.0008 lr: 0.002\n",
      "iteration: 579000 loss: 0.0008 lr: 0.002\n",
      "iteration: 580000 loss: 0.0008 lr: 0.002\n",
      "iteration: 581000 loss: 0.0008 lr: 0.002\n",
      "iteration: 582000 loss: 0.0008 lr: 0.002\n",
      "iteration: 583000 loss: 0.0008 lr: 0.002\n",
      "iteration: 584000 loss: 0.0008 lr: 0.002\n",
      "iteration: 585000 loss: 0.0008 lr: 0.002\n",
      "iteration: 586000 loss: 0.0008 lr: 0.002\n",
      "iteration: 587000 loss: 0.0009 lr: 0.002\n",
      "iteration: 588000 loss: 0.0008 lr: 0.002\n",
      "iteration: 589000 loss: 0.0008 lr: 0.002\n",
      "iteration: 590000 loss: 0.0008 lr: 0.002\n",
      "iteration: 591000 loss: 0.0008 lr: 0.002\n",
      "iteration: 592000 loss: 0.0008 lr: 0.002\n",
      "iteration: 593000 loss: 0.0008 lr: 0.002\n",
      "iteration: 594000 loss: 0.0008 lr: 0.002\n",
      "iteration: 595000 loss: 0.0008 lr: 0.002\n",
      "iteration: 596000 loss: 0.0008 lr: 0.002\n",
      "iteration: 597000 loss: 0.0008 lr: 0.002\n",
      "iteration: 598000 loss: 0.0008 lr: 0.002\n",
      "iteration: 599000 loss: 0.0008 lr: 0.002\n",
      "iteration: 600000 loss: 0.0008 lr: 0.002\n",
      "iteration: 601000 loss: 0.0008 lr: 0.002\n",
      "iteration: 602000 loss: 0.0008 lr: 0.002\n",
      "iteration: 603000 loss: 0.0008 lr: 0.002\n",
      "iteration: 604000 loss: 0.0008 lr: 0.002\n",
      "iteration: 605000 loss: 0.0008 lr: 0.002\n",
      "iteration: 606000 loss: 0.0008 lr: 0.002\n",
      "iteration: 607000 loss: 0.0008 lr: 0.002\n",
      "iteration: 608000 loss: 0.0008 lr: 0.002\n",
      "iteration: 609000 loss: 0.0008 lr: 0.002\n",
      "iteration: 610000 loss: 0.0008 lr: 0.002\n",
      "iteration: 611000 loss: 0.0007 lr: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 612000 loss: 0.0008 lr: 0.002\n",
      "iteration: 613000 loss: 0.0008 lr: 0.002\n",
      "iteration: 614000 loss: 0.0008 lr: 0.002\n",
      "iteration: 615000 loss: 0.0008 lr: 0.002\n",
      "iteration: 616000 loss: 0.0008 lr: 0.002\n",
      "iteration: 617000 loss: 0.0007 lr: 0.002\n",
      "iteration: 618000 loss: 0.0008 lr: 0.002\n",
      "iteration: 619000 loss: 0.0008 lr: 0.002\n",
      "iteration: 620000 loss: 0.0008 lr: 0.002\n",
      "iteration: 621000 loss: 0.0008 lr: 0.002\n",
      "iteration: 622000 loss: 0.0008 lr: 0.002\n",
      "iteration: 623000 loss: 0.0008 lr: 0.002\n",
      "iteration: 624000 loss: 0.0008 lr: 0.002\n",
      "iteration: 625000 loss: 0.0008 lr: 0.002\n",
      "iteration: 626000 loss: 0.0008 lr: 0.002\n",
      "iteration: 627000 loss: 0.0008 lr: 0.002\n",
      "iteration: 628000 loss: 0.0008 lr: 0.002\n",
      "iteration: 629000 loss: 0.0008 lr: 0.002\n",
      "iteration: 630000 loss: 0.0008 lr: 0.002\n",
      "iteration: 631000 loss: 0.0008 lr: 0.002\n",
      "iteration: 632000 loss: 0.0008 lr: 0.002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8253cc711f6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m                 \u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m             )  # pass on path and file name for pose_cfg.yaml!\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[0;32m    252\u001b[0m         [_, loss_val, summary] = sess.run(\n\u001b[0;32m    253\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_summaries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcurrent_lr\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m         )\n\u001b[0;32m    256\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file,shuffle=1,displayiters=1000,saveiters=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13/evaluation-results/  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['w1', 'w2', 'w3', 'w4'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar30shiwkerSep13\\\\ar30shiwker_Arash95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Tennessee\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar30shiwkerSep13\\\\Documentation_data-ar30shiwker_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'F:\\\\videos\\\\Ar30motor\\\\2021_08_03_184113\\\\ar30shiwker-Arash-2021-09-13',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'F:\\\\videos\\\\Ar30motor\\\\2021_08_03_184113\\\\ar30shiwker-Arash-2021-09-13\\\\dlc-models\\\\iteration-0\\\\ar30shiwkerSep13-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\videos\\Ar30motor\\2021_08_03_184113\\ar30shiwker-Arash-2021-09-13\\evaluation-results\\iteration-0\\ar30shiwkerSep13-trainset95shuffle1  already exists!\n",
      "Running  DLC_resnet50_ar30shiwkerSep13shuffle1_632000  with # of trainingiterations: 632000\n",
      "Initializing ResNet\n",
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [00:02, 49.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-632000\n",
      "Results for 632000  training iterations: 95 1 train error: 1.34 pixels. Test error: 2.25  pixels.\n",
      "With pcutoff of 0.6  train error: 1.34 pixels. Test error: 2.25 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file,Shuffles=[1], plotting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [],
   "source": [
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_R-Arash-2020-02-28\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml';\n",
    "#path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19-Arash-2020-03-26\\\\config.yaml'\n",
    "#path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19LR_R-Arash-2020-04-30\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\videos\\\\ar21\\\\2020-07-06\\\\ar21_07_06_20Face2-Arash-2020-07-07\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face3-Arash-2020-09-16\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face3-Arash-2020-09-16\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\videos\\\\ar32\\\\2020_10_09\\\\ar32_10_09_20Face3-Arash-2020-10-10\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\videos\\\\ar30\\\\ar30_10_11_04-Arash-2020-11-05\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\videos\\\\ar32\\\\ar32_10_11_24-Arash-2020-11-25\\\\config.yaml';\n",
    "\n",
    "import os\n",
    "#path_config_file = 'D:\\\\notebook\\\\ar30_10_10_14spouts-Arash-2020-10-24\\\\config.yaml';\n",
    "Mainfolder = 'E:\\\\movies\\\\ar2breathing\\\\10_06_19'\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019'\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19'\n",
    "Mainfolder = 'E:\\\\movies\\\\MUSCIMOL\\\\ar19tear19salin\\\\10_08_19'\n",
    "Mainfolder = 'D:\\\\videos\\\\ar32\\\\2020_11_24'\n",
    "Mainfolder = 'D:\\\\Sidevideos\\\\ar30motor\\\\2021_07_09'\n",
    "Mainfolder = 'D:\\\\Sidevideos\\\\ar32motor\\\\2021_08_02'\n",
    "\n",
    "\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('R.avi') and not f.endswith('L.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.mp4') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "\n",
    "#path_config_file = 'F:\\\\ar19muscimol500ug500nlrightside\\\\10_10_19\\\\ar19_10102019-Fassihi-2019-11-12\\\\config.yaml';\n",
    "\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml'\n",
    "##text_files = ['']\n",
    "#text_files = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\20-18-27.avi'\n",
    "\n",
    "print(text_files)\n",
    "#deeplabcut.analyze_videos(path_config_file,text_files[1:len(text_files)],shuffle=1, save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,text_files[3],shuffle=1, save_as_csv=True)\n",
    "deeplabcut.analyze_videos(path_config_file,text_files,shuffle=1, save_as_csv=True)\n",
    "deeplabcut.filterpredictions(path_config_file,text_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track non tracked files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track non tracked files \n",
    "import os\n",
    "path_config_file = 'F:\\\\ar2breathing\\\\10_06_19\\\\ar2_10062019_ii-Fassihi-2019-10-07\\\\config.yaml';\n",
    "\n",
    "Mainfolder = 'Y:\\\\movies_Rat_SC_project\\\\ar2breathing\\\\10_06_19'\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('breathing.avi')]\n",
    "text_files2 = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('L.avi') ]\n",
    "#print(text_files)\n",
    "#%whos\n",
    "\n",
    "text_files3 = [f.replace(\"L.\", \".\") for f in text_files2 ]\n",
    "one_not_two = set(text_files) - set(text_files3)\n",
    "one_not_two = 'Y:\\\\movies_Rat_SC_project\\\\ar2breathing\\\\10_06_19\\\\22-25-05.avi'\n",
    "print(one_not_two)\n",
    "deeplabcut.analyze_videos(path_config_file,one_not_two,shuffle=1, save_as_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track Tracklets and then filter for multiple animals (maybe whiskers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mainfolder = 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\'\n",
    "import os\n",
    "\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "print(text_files)\n",
    "deeplabcut.convert_detections2tracklets(path_config_file, text_files, videotype='avi',\n",
    "                                                    shuffle=1, trainingsetindex=0, track_method='skeleton')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.refine_tracklets(path_config_file, pickle_or_h5_file, videofile_path, min_swap_len=2, min_tracklet_len=2, trail_len=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter the results using median model\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "deeplabcut.filterpredictions(path_config_file,text_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.plot_trajectories(path_config_file,text_files,filtered = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first we create a vector of destination file names\n",
    "import os \n",
    "\n",
    "dirname = os.path.dirname(text_files[1]) \n",
    "\n",
    "thesenames= [os.path.basename(f)  for f in text_files] \n",
    "text_files2 = [os.path.join( os.path.join(os.path.dirname(text_files[1]),'labled'),f) for f in thesenames ]  \n",
    "\n",
    "#os.mkdir\n",
    "if not (os.path.isdir(os.path.join(os.path.dirname(text_files[1]),'labled'))):\n",
    " os.mkdir(os.path.join(os.path.dirname(text_files[1]),'labled'))\n",
    "# Print the directory name   \n",
    "print(text_files2[1]) \n",
    "for f in text_files:\n",
    "\n",
    "#deeplabcut.create_labeled_video(path_config_file,videofile,save_frames=True) # my_new_list was created in prevouse cell as all videos in the folder \n",
    "#deeplabcut.create_labeled_video(path_config_file,[text_files[0],text_files2[0]],save_frames=True)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [This is important step actually]\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. Make sure to provide the correct value of the \"iterations\" as it will be used to create the unique directory where the extracted frames will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video=['D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\analyzed\\\\18-37-27.avi']\n",
    "#video=['D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\17-33-50video.mp4']\n",
    "#video=['D:\\\\Dropbox\\\\ar17\\\\02_25_19\\\\22-37-23.avi']\n",
    "video = ['D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\11-09-14.avi']\n",
    "video = ['D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-19-45.avi','D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-31-05.avi','D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-30-40.avi']\n",
    "#15-17-08v\n",
    "video = ['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-27-18.avi','D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-47.avi']\n",
    "video = ['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-26video.mp4']\n",
    "video = ['E:\\\\movies\\\\ar2breathing\\\\10_06_19\\\\21-57-55L.avi']\n",
    "video = text_files[0]\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml';\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019-Fassihi-2019-03-12\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19\\\\sc_ar14_06182019-Fassihi-2019-06-19\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "print(path_config_file)\n",
    "\n",
    "#deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',p_bound=.6)\n",
    "#deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',comparisonbodyparts =  ['nose','snout'],p_bound=.6)\n",
    "deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',p_bound=.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [],
   "source": [
    "\n",
    "path_config_file = 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19\\\\sc_ar19_02072019-Fassihi4-2019-02-13\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "import os\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19'\n",
    "\n",
    "\n",
    "f = os.listdir(Mainfolder)\n",
    "text_files = [f for f in os.listdir(Mainfolder) if f.endswith('.avi')]\n",
    "\n",
    "\n",
    "my_list = text_files\n",
    "thisApen = Mainfolder+'kir'\n",
    "thisApen = thisApen.replace(\"kir\", \"\\\\\")\n",
    "string = thisApen\n",
    "my_new_list = [ string + x for x in my_list]\n",
    "\n",
    "deeplabcut.extract_outlier_frames(path_config_file,my_new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [],
   "source": [
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "#import matplotlib\n",
    "#print(matplotlib.__version__)\n",
    "%gui wx\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019-Fassihi-2019-03-12\\\\config.yaml'\n",
    "#print(path_config_file)\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [],
   "source": [
    "#Once all folders are relabeled, check them and advance. See how to check labels, above!\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refine labels, append these frames to the original dataset to create a new iteration of training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_of_ints = list(range(2))\n",
    "print(list_of_ints)\n",
    "deeplabcut.create_training_dataset(path_config_file,Shuffles= list_of_ints) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos (optional)\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook #for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,my_new_list)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
