{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# Arash SC create a project for head position\n",
    "\n",
    "\n",
    "\n",
    "This notebook demonstrates the necessary steps to use python and DeepLabCut for creating and analysins videos from orientation \n",
    "experiment \n",
    "\n",
    "This notebook illustrates how to:\n",
    " \n",
    "- make a movie from images \n",
    "- create a project\n",
    "- extract training frames\n",
    "- label the frames\n",
    "- plot the labeled images (optional)\n",
    "- create a training set\n",
    "- train a network\n",
    "- evaluate a network\n",
    "- analyze a novel video\n",
    "- create an automatically labeled video (optional)\n",
    "- Go to Matlab \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Create a new project\n",
    "\n",
    "It is always good idea to keep the projects seperate. This function creates a new project with subdirectories and a basic configuration file in the user defined directory otherwise the project is created in the current working directory.\n",
    "\n",
    "You can always add new videos to the project at any stage of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [],
   "source": [
    "import deeplabcut\n",
    "## https://github.com/AlexEMG/DeepLabCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\videos\\\\ar19\\\\2020_09_14_ 214738\\\\1.avi', 'D:\\\\videos\\\\ar19\\\\2020_09_14_ 214738\\\\7.avi']\n",
      "Created \"D:\\Dropbox\\Notebook\\ar19_09_15_20Face2-Arash-2020-09-15\\videos\"\n",
      "Created \"D:\\Dropbox\\Notebook\\ar19_09_15_20Face2-Arash-2020-09-15\\labeled-data\"\n",
      "Created \"D:\\Dropbox\\Notebook\\ar19_09_15_20Face2-Arash-2020-09-15\\training-datasets\"\n",
      "Created \"D:\\Dropbox\\Notebook\\ar19_09_15_20Face2-Arash-2020-09-15\\dlc-models\"\n",
      "Copying the videos\n",
      "D:\\Dropbox\\Notebook\\ar19_09_15_20Face2-Arash-2020-09-15\\videos\\1.avi\n",
      "D:\\Dropbox\\Notebook\\ar19_09_15_20Face2-Arash-2020-09-15\\videos\\7.avi\n",
      "Generated \"D:\\Dropbox\\Notebook\\ar19_09_15_20Face2-Arash-2020-09-15\\config.yaml\"\n",
      "\n",
      "A new project with name ar19_09_15_20Face2-Arash-2020-09-15 is created at D:\\Dropbox\\Notebook and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face2-Arash-2020-09-15\\\\config.yaml'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task='ar21_07_06_20LR_R' # Enter the name of your experiment Task\n",
    "task='ar19_09_15_20Face2' \n",
    "\n",
    "experimenter='Arash' # Enter the name of the experimenter\n",
    "Mainfolder =  'D:\\\\videos\\\\AR19distance\\\\2020_09_14_ 215321'; # Enter the name of the folder with images folders inside \n",
    "Mainfolder = 'D:\\\\videos\\\\ar19\\\\2020_09_14_ 214738\\\\';\n",
    "\n",
    "filenames = ['1.avi','7.avi']; # Enter the name of the files you want to train\n",
    "video = [str(Mainfolder)+str(f) for f in filenames]; # add path to each file\n",
    "print(video)\n",
    "#deeplabcut.create_new_project(task,experimenter,video, working_directory=Mainfolder,copy_videos=False) #change the working directory to where you want the folders created.\n",
    "deeplabcut.create_new_project(task,experimenter, video,copy_videos=True, multianimal=False)\n",
    "#deeplabcut.create_new_project(task,experimenter, video,copy_videos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yXW0bx1oEJA"
   },
   "source": [
    "## Extract frames from videos \n",
    "A key point for a successful feature detector is to select diverse frames, which are typical for the behavior you study that should be labeled.\n",
    "\n",
    "This function selects N frames either uniformly sampled from a particular video (or folder) (algo=='uniform'). Note: this might not yield diverse frames, if the behavior is sparsely distributed (consider using kmeans), and/or select frames manually etc.\n",
    "\n",
    "Also make sure to get select data from different (behavioral) sessions and different animals if those vary substantially (to train an invariant feature detector).\n",
    "\n",
    "Individual images should not be too big (i.e. < 850 x 850 pixel). Although this can be taken care of later as well, it is advisable to crop the frames, to remove unnecessary parts of the frame as much as possible.\n",
    "\n",
    "Always check the output of cropping. If you are happy with the results proceed to labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1ulumCuoEJC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Do you want to extract (perhaps additional) frames for video: D:\\Dropbox\\Notebook\\ar19_09_15_20Face2-Arash-2020-09-15\\videos\\1.avi ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 7.5  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: D:\\Dropbox\\Notebook\\ar19_09_15_20Face2-Arash-2020-09-15\\videos\\7.avi ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 7.5  seconds.\n",
      "Frames were successfully extracted.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face2-Arash-2020-09-15\\\\config.yaml';\n",
    "#Enter the path of the config file that was just created from the above step (check the folder)\n",
    "deeplabcut.extract_frames(path_config_file,'automatic','uniform',crop=False) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n",
    "#deeplabcut.extract_frames(path_config_file,'automatic','uniform',crop=True, checkcropping=True) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n",
    "#You can change the cropping to false, then delete the checkcropping part!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the config path and load deeplabcut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the Path config file path\n",
    "path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19LR_R-Arash-2020-04-30\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar21\\\\2020-07-06\\\\ar21_07_06_20Face2-Arash-2020-07-07\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar21_08_06_20Face4-Arash-2020-07-15\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face2-Arash-2020-09-15\\\\config.yaml';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gjn6ZDonoEJH"
   },
   "source": [
    "## Label the extracted frames\n",
    "Only videos in the config file can be used to extract the frames. Extracted labels for each video are stored in the project directory under the subdirectory **'labeled-data'**. Each subdirectory is named after the name of the video. The toolbox has a labeling toolbox which could be used for labeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyROSOiEoEJI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "%gui wx\n",
    "\n",
    "deeplabcut.label_frames(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vim95ZvkPSeN"
   },
   "source": [
    "**Check the labels**\n",
    "\n",
    "Checking if the labels were created and stored correctly is beneficial for training, since labeling is one of the most critical parts for creating the training dataset. The DeepLabCut toolbox provides a function `check\\_labels'  to do so. It is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwvgPJouPP2O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Arash.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:03<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder: Build your skeleton connections before you create a training set!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\ipykernel\\eventloops.py\u001b[0m in \u001b[0;36mon_timer\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mdef\u001b[0m \u001b[0mon_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<deeplabcut.utils.skeleton.SkeletonBuilder at 0x280e6bc3128>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.SkeletonBuilder(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "of87fOjgPqzH"
   },
   "source": [
    "If the labels need adjusted, you can use the refinement GUI to move them around! Check that out below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "This function generates the training data information for DeepCut (which requires a mat file) based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles. \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([20, 11, 31, 10, 38, 29,  6, 17, 28,  1, 15,  3, 30, 21, 39, 12, 22,\n",
       "          27,  8, 16, 19, 25,  2,  4, 18, 33,  0, 36,  9, 13, 34, 26,  5, 24,\n",
       "          23, 32, 35, 14]), array([ 7, 37])))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training  \n",
    "### If yu want to use your GPU, you need to exit here and either work from the Docker container, your own TensorFlow installation in an Anaconda env\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['nose', 'snout', 'eye1', 'eye2'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar19_09_15_20Face2Sep15\\\\ar19_09_15_20Face2_Arash95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Tennessee\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar19_09_15_20Face2Sep15\\\\Documentation_data-ar19_09_15_20Face2_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face2-Arash-2020-09-15',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face2-Arash-2020-09-15\\\\dlc-models\\\\iteration-0\\\\ar19_09_15_20Face2Sep15-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching batchsize to 1, as default/tensorpack/deterministic loaders do not support batches >1. Use imgaug loader.\n",
      "Starting with standard pose-dataset loader.\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Display_iters overwritten as 1000\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face2-Arash-2020-09-15\\\\dlc-models\\\\iteration-0\\\\ar19_09_15_20Face2Sep15-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'weigh_only_present_joints': False, 'pairwise_huber_loss': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['nose', 'snout', 'eye1', 'eye2'], 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar19_09_15_20Face2Sep15\\\\ar19_09_15_20Face2_Arash95shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\Tennessee\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar19_09_15_20Face2Sep15\\\\Documentation_data-ar19_09_15_20Face2_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': 'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face2-Arash-2020-09-15', 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000 loss: 0.0187 lr: 0.005\n"
     ]
    },
    {
     "ename": "PermissionDeniedError",
     "evalue": "Failed to delete a file: D:\\Dropbox\\Notebook\\ar19_09_15_20Face2-Arash-2020-09-15\\dlc-models\\iteration-0\\ar19_09_15_20Face2Sep15-trainset95shuffle1\\train\\snapshot-1000.meta.tmp980bf944b2de41d795f738070ccc7f4b; Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36matomic_write_string_to_file\u001b[1;34m(filename, contents, overwrite)\u001b[0m\n\u001b[0;32m    546\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m     \u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrename\u001b[1;34m(oldname, newname, overwrite)\u001b[0m\n\u001b[0;32m    507\u001b[0m   \"\"\"\n\u001b[1;32m--> 508\u001b[1;33m   \u001b[0mrename_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moldname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrename_v2\u001b[1;34m(src, dst, overwrite)\u001b[0m\n\u001b[0;32m    525\u001b[0m     pywrap_tensorflow.RenameFile(\n\u001b[1;32m--> 526\u001b[1;33m         compat.as_bytes(src), compat.as_bytes(dst), overwrite, status)\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Failed to rename: D:\\Dropbox\\Notebook\\ar19_09_15_20Face2-Arash-2020-09-15\\dlc-models\\iteration-0\\ar19_09_15_20Face2Sep15-trainset95shuffle1\\train\\snapshot-1000.meta.tmp980bf944b2de41d795f738070ccc7f4b to: D:\\Dropbox\\Notebook\\ar19_09_15_20Face2-Arash-2020-09-15\\dlc-models\\iteration-0\\ar19_09_15_20Face2Sep15-trainset95shuffle1\\train\\snapshot-1000.meta : The process cannot access the file because it is being used by another process.\r\n; Broken pipe",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8253cc711f6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m                 \u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m             )  # pass on path and file name for pose_cfg.yaml!\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msave_iters\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mit\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mit\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnapshot_prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[0mlrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[0;32m   1194\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m           self.export_meta_graph(\n\u001b[1;32m-> 1196\u001b[1;33m               meta_graph_filename, strip_default_attrs=strip_default_attrs)\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[1;34m(self, filename, collection_list, as_text, export_scope, clear_devices, clear_extraneous_savers, strip_default_attrs)\u001b[0m\n\u001b[0;32m   1239\u001b[0m         \u001b[0mclear_devices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclear_devices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \u001b[0mclear_extraneous_savers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclear_extraneous_savers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1241\u001b[1;33m         strip_default_attrs=strip_default_attrs)\n\u001b[0m\u001b[0;32m   1242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[1;34m(filename, meta_info_def, graph_def, saver_def, collection_list, as_text, graph, export_scope, clear_devices, clear_extraneous_savers, strip_default_attrs, **kwargs)\u001b[0m\n\u001b[0;32m   1559\u001b[0m       \u001b[0mclear_extraneous_savers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclear_extraneous_savers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1560\u001b[0m       \u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1561\u001b[1;33m       **kwargs)\n\u001b[0m\u001b[0;32m   1562\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\u001b[0m in \u001b[0;36mexport_scoped_meta_graph\u001b[1;34m(filename, graph_def, graph, export_scope, as_text, unbound_inputs_col_name, clear_devices, saver_def, clear_extraneous_savers, strip_default_attrs, **kwargs)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m         as_text=as_text)\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mscoped_meta_graph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\graph_io.py\u001b[0m in \u001b[0;36mwrite_graph\u001b[1;34m(graph_or_graph_def, logdir, name, as_text)\u001b[0m\n\u001b[0;32m     71\u001b[0m                                         text_format.MessageToString(graph_def))\n\u001b[0;32m     72\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matomic_write_string_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36matomic_write_string_to_file\u001b[1;34m(filename, contents, overwrite)\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m     \u001b[0mdelete_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m     \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mdelete_file\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[0mNotFoundError\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mdoes\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m   \"\"\"\n\u001b[1;32m--> 294\u001b[1;33m   \u001b[0mdelete_file_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mdelete_file_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    307\u001b[0m   \"\"\"\n\u001b[0;32m    308\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeleteFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionDeniedError\u001b[0m: Failed to delete a file: D:\\Dropbox\\Notebook\\ar19_09_15_20Face2-Arash-2020-09-15\\dlc-models\\iteration-0\\ar19_09_15_20Face2Sep15-trainset95shuffle1\\train\\snapshot-1000.meta.tmp980bf944b2de41d795f738070ccc7f4b; Permission denied"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file,shuffle=1,displayiters=1000,saveiters=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20Face4Jul15\\\\ar21_08_06_20Face4_Arash95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Tennessee\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20Face4Jul15\\\\Documentation_data-ar21_08_06_20Face4_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\Dropbox\\\\Notebook\\\\ar21_08_06_20Face4-Arash-2020-07-15',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\Dropbox\\\\Notebook\\\\ar21_08_06_20Face4-Arash-2020-07-15\\\\dlc-models\\\\iteration-0\\\\ar21_08_06_20Face4Jul15-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_resnet50_ar21_08_06_20Face4Jul15shuffle1_131000  with # of trainingiterations: 131000\n",
      "Initializing ResNet\n",
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:02, 19.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-131000\n",
      "Results for 131000  training iterations: 95 1 train error: 1.99 pixels. Test error: 5.24  pixels.\n",
      "With pcutoff of 0.6  train error: 1.99 pixels. Test error: 5.24 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file,Shuffles=[1], plotting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\videos\\\\ar21\\\\2020_07_08\\\\1.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\10.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\11.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\12.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\13.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\14.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\15.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\16.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\17.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\18.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\19.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\2.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\20.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\21.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\22.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\23.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\24.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\25.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\26.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\27.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\28.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\29.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\3.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\30.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\31.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\32.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\33.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\34.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\35.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\36.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\37.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\38.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\39.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\4.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\40.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\41.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\42.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\43.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\44.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\45.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\46.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\47.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\48.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\49.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\5.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\50.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\51.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\52.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\6.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\7.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\8.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\9.avi']\n",
      "Using snapshot-821000 for model D:\\videos\\ar21\\2020-07-06\\ar21_07_06_20Face2-Arash-2020-07-07\\dlc-models\\iteration-0\\ar21_07_06_20Face2Jul7-trainset95shuffle1\n",
      "Initializing ResNet\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\1.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\1.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:14, 33.27it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:14, 29.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\10.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\10.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:10, 33.19it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:10, 37.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\11.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\11.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:10, 33.10it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:10, 37.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\12.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\12.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 32.81it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 37.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\13.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\13.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 32.92it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 37.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\14.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\14.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 32.82it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 36.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\15.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\15.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 32.55it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 36.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\16.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\16.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.58it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\17.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\17.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.83it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\18.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\18.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 32.25it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 36.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\19.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\19.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.41it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\2.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\2.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.53it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\20.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\20.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.75it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\21.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\21.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 23.13it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\22.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\22.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.58it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\23.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\23.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.56it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\24.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\24.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.53it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\25.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\25.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.61it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\26.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\26.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.62it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\27.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\27.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.61it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\28.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\28.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 30.85it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 34.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\29.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\29.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.41it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\3.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\3.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.50it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\30.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\30.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.38it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\31.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\31.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 29.61it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\32.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\32.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.25it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\33.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\33.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.37it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\34.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\34.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.83it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\35.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\35.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.01it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\36.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\36.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.89it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\37.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\37.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.00it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\38.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\38.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.88it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\39.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\39.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.71it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\4.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\4.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.44it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\40.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\40.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.65it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\41.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\41.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.15it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\42.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\42.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.31it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 34.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\43.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\43.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.27it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\44.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\44.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.42it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 34.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\45.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\45.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.39it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\46.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\46.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.59it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\47.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\47.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.99it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\48.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\48.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.83it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\49.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\49.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.76it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\5.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\5.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.76it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\50.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\50.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.37it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\51.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\51.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.59it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\52.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\52.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.95it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\6.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\6.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.52it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\7.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\7.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.28it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\8.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\8.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.68it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\9.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\9.avi\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.03it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_ar21_07_06_20Face2Jul7shuffle1_821000'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_R-Arash-2020-02-28\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml';\n",
    "#path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19-Arash-2020-03-26\\\\config.yaml'\n",
    "path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19LR_R-Arash-2020-04-30\\\\config.yaml'\n",
    "path_config_file = 'D:\\\\videos\\\\ar21\\\\2020-07-06\\\\ar21_07_06_20Face2-Arash-2020-07-07\\\\config.yaml';\n",
    "\n",
    "import os\n",
    "\n",
    "Mainfolder = 'E:\\\\movies\\\\ar2breathing\\\\10_06_19'\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019'\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19'\n",
    "Mainfolder = 'E:\\\\movies\\\\MUSCIMOL\\\\ar19tear19salin\\\\10_08_19'\n",
    "Mainfolder = 'D:\\\\videos\\\\ar21\\\\2020_07_08'\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('R.avi') and not f.endswith('L.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.mp4') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "\n",
    "#path_config_file = 'F:\\\\ar19muscimol500ug500nlrightside\\\\10_10_19\\\\ar19_10102019-Fassihi-2019-11-12\\\\config.yaml';\n",
    "\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml'\n",
    "##text_files = ['']\n",
    "#text_files = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\20-18-27.avi'\n",
    "\n",
    "print(text_files)\n",
    "#deeplabcut.analyze_videos(path_config_file,text_files[1:len(text_files)],shuffle=1, save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,text_files[3],shuffle=1, save_as_csv=True)\n",
    "deeplabcut.analyze_videos(path_config_file,text_files,shuffle=1, save_as_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track non tracked files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track non tracked files \n",
    "import os\n",
    "path_config_file = 'F:\\\\ar2breathing\\\\10_06_19\\\\ar2_10062019_ii-Fassihi-2019-10-07\\\\config.yaml';\n",
    "\n",
    "Mainfolder = 'Y:\\\\movies_Rat_SC_project\\\\ar2breathing\\\\10_06_19'\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('breathing.avi')]\n",
    "text_files2 = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('L.avi') ]\n",
    "#print(text_files)\n",
    "#%whos\n",
    "\n",
    "text_files3 = [f.replace(\"L.\", \".\") for f in text_files2 ]\n",
    "one_not_two = set(text_files) - set(text_files3)\n",
    "one_not_two = 'Y:\\\\movies_Rat_SC_project\\\\ar2breathing\\\\10_06_19\\\\22-25-05.avi'\n",
    "print(one_not_two)\n",
    "deeplabcut.analyze_videos(path_config_file,one_not_two,shuffle=1, save_as_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track Tracklets and then filter for multiple animals (maybe whiskers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mainfolder = 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\'\n",
    "import os\n",
    "\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "print(text_files)\n",
    "deeplabcut.convert_detections2tracklets(path_config_file, text_files, videotype='avi',\n",
    "                                                    shuffle=1, trainingsetindex=0, track_method='skeleton')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.refine_tracklets(path_config_file, pickle_or_h5_file, videofile_path, min_swap_len=2, min_tracklet_len=2, trail_len=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter the results using median model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.filterpredictions(path_config_file,text_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.plot_trajectories(path_config_file,text_files,filtered = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\videos\\ar21\\2020_07_08\\labled\\10.avi\n"
     ]
    }
   ],
   "source": [
    "# first we create a vector of destination file names\n",
    "import os \n",
    "\n",
    "dirname = os.path.dirname(text_files[1]) \n",
    "\n",
    "thesenames= [os.path.basename(f)  for f in text_files] \n",
    "text_files2 = [os.path.join( os.path.join(os.path.dirname(text_files[1]),'labled'),f) for f in thesenames ]  \n",
    "\n",
    "#os.mkdir\n",
    "if not (os.path.isdir(os.path.join(os.path.dirname(text_files[1]),'labled'))):\n",
    " os.mkdir(os.path.join(os.path.dirname(text_files[1]),'labled'))\n",
    "# Print the directory name   \n",
    "print(text_files2[1]) \n",
    "for f in text_files:\n",
    "\n",
    "#deeplabcut.create_labeled_video(path_config_file,videofile,save_frames=True) # my_new_list was created in prevouse cell as all videos in the folder \n",
    "#deeplabcut.create_labeled_video(path_config_file,[text_files[0],text_files2[0]],save_frames=True)\n",
    " deeplabcut.create_labeled_video(path_config_file,f,save_frames=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [This is important step actually]\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. Make sure to provide the correct value of the \"iterations\" as it will be used to create the unique directory where the extracted frames will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\videos\\ar21\\2020-07-06\\ar21_07_06_20Face2-Arash-2020-07-07\\config.yaml\n",
      "Method  uncertain  found  0  putative outlier frames.\n",
      "Do you want to proceed with extracting  25  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "yes/nono\n",
      "Nothing extracted, please change the parameters and start again...\n"
     ]
    }
   ],
   "source": [
    "#video=['D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\analyzed\\\\18-37-27.avi']\n",
    "#video=['D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\17-33-50video.mp4']\n",
    "#video=['D:\\\\Dropbox\\\\ar17\\\\02_25_19\\\\22-37-23.avi']\n",
    "video = ['D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\11-09-14.avi']\n",
    "video = ['D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-19-45.avi','D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-31-05.avi','D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-30-40.avi']\n",
    "#15-17-08v\n",
    "video = ['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-27-18.avi','D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-47.avi']\n",
    "video = ['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-26video.mp4']\n",
    "video = ['E:\\\\movies\\\\ar2breathing\\\\10_06_19\\\\21-57-55L.avi']\n",
    "video = text_files[0]\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml';\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019-Fassihi-2019-03-12\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19\\\\sc_ar14_06182019-Fassihi-2019-06-19\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "print(path_config_file)\n",
    "\n",
    "#deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',p_bound=.6)\n",
    "#deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',comparisonbodyparts =  ['nose','snout'],p_bound=.6)\n",
    "deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',p_bound=.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\movies_Rat_SC_project\\ar20\\06_20_19\\17-30-40avi\n"
     ]
    }
   ],
   "source": [
    "print(video[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b91127c43abf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMainfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtext_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMainfolder\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.avi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19'"
     ]
    }
   ],
   "source": [
    "\n",
    "path_config_file = 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19\\\\sc_ar19_02072019-Fassihi4-2019-02-13\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "import os\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19'\n",
    "\n",
    "\n",
    "f = os.listdir(Mainfolder)\n",
    "text_files = [f for f in os.listdir(Mainfolder) if f.endswith('.avi')]\n",
    "\n",
    "\n",
    "my_list = text_files\n",
    "thisApen = Mainfolder+'kir'\n",
    "thisApen = thisApen.replace(\"kir\", \"\\\\\")\n",
    "string = thisApen\n",
    "my_new_list = [ string + x for x in my_list]\n",
    "\n",
    "deeplabcut.extract_outlier_frames(path_config_file,my_new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot activate multiple GUI eventloops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows\n",
      "Checking labels if they are outside the image\n",
      "Checking labels if they are outside the image\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "On level 0, label max (1) >= length of level  (1). NOTE: this index is in an inconsistent state",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\refinement.py\u001b[0m in \u001b[0;36msaveDataSet\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMainFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhumanscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'likelihood'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36mset_levels\u001b[1;34m(self, levels, level, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0midx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset_identity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         idx._set_levels(levels, level=level, validate=True,\n\u001b[1;32m--> 278\u001b[1;33m                         verify_integrity=verify_integrity)\n\u001b[0m\u001b[0;32m    279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36m_set_levels\u001b[1;34m(self, levels, level, copy, validate, verify_integrity)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverify_integrity\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_levels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[1;34m(self, labels, levels)\u001b[0m\n\u001b[0;32m    176\u001b[0m                                  \u001b[1;34m\" level  (%d). NOTE: this index is in an\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                                  \" inconsistent state\" % (i, label.max(),\n\u001b[1;32m--> 178\u001b[1;33m                                                           len(level)))\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: On level 0, label max (1) >= length of level  (1). NOTE: this index is in an inconsistent state"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "#import matplotlib\n",
    "#print(matplotlib.__version__)\n",
    "%gui wx\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019-Fassihi-2019-03-12\\\\config.yaml'\n",
    "#print(path_config_file)\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 2.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "#Once all folders are relabeled, check them and advance. See how to check labels, above!\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refine labels, append these frames to the original dataset to create a new iteration of training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "list_of_ints = list(range(2))\n",
    "print(list_of_ints)\n",
    "deeplabcut.create_training_dataset(path_config_file,Shuffles= list_of_ints) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos (optional)\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook #for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,my_new_list)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
