{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# Arash SC create a project for head position\n",
    "\n",
    "\n",
    "\n",
    "This notebook demonstrates the necessary steps to use python and DeepLabCut for creating and analysins videos from orientation \n",
    "experiment \n",
    "\n",
    "This notebook illustrates how to:\n",
    " \n",
    "- make a movie from images \n",
    "- create a project\n",
    "- extract training frames\n",
    "- label the frames\n",
    "- plot the labeled images (optional)\n",
    "- create a training set\n",
    "- train a network\n",
    "- evaluate a network\n",
    "- analyze a novel video\n",
    "- create an automatically labeled video (optional)\n",
    "- Go to Matlab \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Create a new project\n",
    "\n",
    "It is always good idea to keep the projects seperate. This function creates a new project with subdirectories and a basic configuration file in the user defined directory otherwise the project is created in the current working directory.\n",
    "\n",
    "You can always add new videos to the project at any stage of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [],
   "source": [
    "import deeplabcut\n",
    "## https://github.com/AlexEMG/DeepLabCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20Face-Arash-2020-07-15\\videos\"\n",
      "Created \"D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20Face-Arash-2020-07-15\\labeled-data\"\n",
      "Created \"D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20Face-Arash-2020-07-15\\training-datasets\"\n",
      "Created \"D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20Face-Arash-2020-07-15\\dlc-models\"\n",
      "Copying the videos\n",
      "Generated \"D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20Face-Arash-2020-07-15\\config.yaml\"\n",
      "\n",
      "A new project with name ar21_08_06_20Face-Arash-2020-07-15 is created at D:\\videos\\ar21\\2020_07_08 and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20Face-Arash-2020-07-15\\\\config.yaml'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task='ar21_07_06_20LR_R' # Enter the name of your experiment Task\n",
    "task='ar21_08_06_20Face2' \n",
    "\n",
    "experimenter='Arash' # Enter the name of the experimenter\n",
    "Mainfolder =  'D:\\\\videos\\\\ar21\\\\2020_07_08'; # Enter the name of the folder with images folders inside \n",
    "filenames = ['4.avi','6.avi','11.avi']; # Enter the name of the files you want to train\n",
    "video = [str(Mainfolder)+str(f) for f in filenames]; # add path to each file\n",
    "deeplabcut.create_new_project(task,experimenter,video, working_directory=Mainfolder,copy_videos=False) #change the working directory to where you want the folders created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yXW0bx1oEJA"
   },
   "source": [
    "## Extract frames from videos \n",
    "A key point for a successful feature detector is to select diverse frames, which are typical for the behavior you study that should be labeled.\n",
    "\n",
    "This function selects N frames either uniformly sampled from a particular video (or folder) (algo=='uniform'). Note: this might not yield diverse frames, if the behavior is sparsely distributed (consider using kmeans), and/or select frames manually etc.\n",
    "\n",
    "Also make sure to get select data from different (behavioral) sessions and different animals if those vary substantially (to train an invariant feature detector).\n",
    "\n",
    "Individual images should not be too big (i.e. < 850 x 850 pixel). Although this can be taken care of later as well, it is advisable to crop the frames, to remove unnecessary parts of the frame as much as possible.\n",
    "\n",
    "Always check the output of cropping. If you are happy with the results proceed to labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1ulumCuoEJC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "\n",
      "Frames were selected.\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "path_config_file = 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20Face-Arash-2020-07-15\\\\config.yaml';\n",
    "\n",
    "#Enter the path of the config file that was just created from the above step (check the folder)\n",
    "deeplabcut.extract_frames(path_config_file,'automatic','uniform',crop=False) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n",
    "#deeplabcut.extract_frames(path_config_file,'automatic','uniform',crop=True, checkcropping=True) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n",
    "#You can change the cropping to false, then delete the checkcropping part!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the config path and load deeplabcut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the Path config file path\n",
    "path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19LR_R-Arash-2020-04-30\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar21\\\\2020-07-06\\\\ar21_07_06_20Face2-Arash-2020-07-07\\\\config.yaml';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gjn6ZDonoEJH"
   },
   "source": [
    "## Label the extracted frames\n",
    "Only videos in the config file can be used to extract the frames. Extracted labels for each video are stored in the project directory under the subdirectory **'labeled-data'**. Each subdirectory is named after the name of the video. The toolbox has a labeling toolbox which could be used for labeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyROSOiEoEJI"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "wrapped C/C++ object of type DirDialog has been deleted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\labeling_toolbox.py\u001b[0m in \u001b[0;36mbrowseDir\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[0mdlg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDestroy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[0mdlg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDestroy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;31m# Enabling the zoom, pan and home buttons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: wrapped C/C++ object of type DirDialog has been deleted"
     ]
    }
   ],
   "source": [
    "%gui wx\n",
    "\n",
    "deeplabcut.label_frames(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vim95ZvkPSeN"
   },
   "source": [
    "**Check the labels**\n",
    "\n",
    "Checking if the labels were created and stored correctly is beneficial for training, since labeling is one of the most critical parts for creating the training dataset. The DeepLabCut toolbox provides a function `check\\_labels'  to do so. It is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwvgPJouPP2O"
   },
   "outputs": [],
   "source": [
    "\n",
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder: Build your skeleton connections before you create a training set!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.SkeletonBuilder(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "of87fOjgPqzH"
   },
   "source": [
    "If the labels need adjusted, you can use the refinement GUI to move them around! Check that out below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "This function generates the training data information for DeepCut (which requires a mat file) based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles. \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training  \n",
    "### If yu want to use your GPU, you need to exit here and either work from the Docker container, your own TensorFlow installation in an Anaconda env\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.train_network(path_config_file,shuffle=1,displayiters=1000,saveiters=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1]],\n",
      " 'all_joints_names': ['nose', 'snout'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_07_06_20Face2Jul7\\\\ar21_07_06_20Face2_Arash95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Tennessee\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_07_06_20Face2Jul7\\\\Documentation_data-ar21_07_06_20Face2_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 2,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\videos\\\\ar21\\\\2020-07-06\\\\ar21_07_06_20Face2-Arash-2020-07-07',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\videos\\\\ar21\\\\2020-07-06\\\\ar21_07_06_20Face2-Arash-2020-07-07\\\\dlc-models\\\\iteration-0\\\\ar21_07_06_20Face2Jul7-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_resnet50_ar21_07_06_20Face2Jul7shuffle1_821000  with # of trainingiterations: 821000\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from D:\\videos\\ar21\\2020-07-06\\ar21_07_06_20Face2-Arash-2020-07-07\\dlc-models\\iteration-0\\ar21_07_06_20Face2Jul7-trainset95shuffle1\\train\\snapshot-821000\n",
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:02, 19.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-821000\n",
      "Results for 821000  training iterations: 95 1 train error: 1.52 pixels. Test error: 2.75  pixels.\n",
      "With pcutoff of 0.1  train error: 1.52 pixels. Test error: 2.75 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file,Shuffles=[1], plotting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\10video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\11video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\12video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\13video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\14video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\15video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\16video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\17video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\18video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\19video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\1video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\20video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\21video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\22video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\23video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\24video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\25video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\26video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\27video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\28video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\29video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\2video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\30video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\31video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\32video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\33video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\34video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\35video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\36video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\37video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\38video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\39video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\3video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\40video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\41video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\42video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\43video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\44video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\45video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\46video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\47video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\48video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\49video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\4video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\50video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\51video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\52video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\5video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\6video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\7video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\8video.mp4', 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805\\\\9video.mp4']\n",
      "Using snapshot-821000 for model D:\\videos\\ar21\\2020-07-06\\ar21_07_06_20Face2-Arash-2020-07-07\\dlc-models\\iteration-0\\ar21_07_06_20Face2Jul7-trainset95shuffle1\n",
      "Initializing ResNet\n",
      "WARNING:tensorflow:From C:\\Users\\Tennessee\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tennessee\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tennessee\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tennessee\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\videos\\ar21\\2020-07-06\\ar21_07_06_20Face2-Arash-2020-07-07\\dlc-models\\iteration-0\\ar21_07_06_20Face2Jul7-trainset95shuffle1\\train\\snapshot-821000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\videos\\ar21\\2020-07-06\\ar21_07_06_20Face2-Arash-2020-07-07\\dlc-models\\iteration-0\\ar21_07_06_20Face2Jul7-trainset95shuffle1\\train\\snapshot-821000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\10video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\10video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:14, 32.07it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:14, 28.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\11video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\11video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:10, 33.12it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:10, 37.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\12video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\12video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:10, 33.14it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:10, 37.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\13video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\13video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:10, 33.08it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:10, 37.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\14video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\14video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 32.91it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 37.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\15video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\15video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 32.88it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 37.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\16video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\16video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 32.75it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 36.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\17video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\17video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 32.65it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 36.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\18video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\18video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 32.47it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 36.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\19video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\19video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 32.38it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 36.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\1video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\1video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.99it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 36.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\20video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\20video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.94it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 36.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\21video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\21video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.63it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\22video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\22video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.87it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\23video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\23video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.60it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\24video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\24video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.67it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\25video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\25video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.60it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\26video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\26video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.45it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\27video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\27video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.74it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\28video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\28video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.53it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\29video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\29video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.65it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\2video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\2video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.50it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\30video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\30video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.56it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\31video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\31video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.47it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\32video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\32video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.47it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\33video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\33video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.41it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\34video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\34video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.81it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\35video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\35video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.58it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\36video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\36video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.15it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\37video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\37video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.02it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\38video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\38video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.06it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\39video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\39video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.02it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 35.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\3video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\3video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.83it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\40video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\40video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 31.09it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\41video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\41video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.84it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\42video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\42video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.96it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\43video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\43video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.82it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\44video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\44video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 28.02it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\45video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\45video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 30.47it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\46video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\46video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 30.37it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 34.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\47video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\47video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.53it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\48video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\48video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 30.44it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\49video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\49video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 30.04it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 34.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\4video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\4video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 29.30it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:11, 34.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\50video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\50video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 30.49it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\51video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\51video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:13, 28.02it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:13, 31.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\52video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\52video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.65it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 32.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\5video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\5video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.28it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\6video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\6video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.42it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\7video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\7video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.54it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\8video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\8video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.54it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08_ 215805\\9video.mp4\n",
      "Loading  D:\\videos\\ar21\\2020_07_08_ 215805\\9video.mp4\n",
      "Duration of video [s]:  400.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  400  found with (before cropping) frame dimensions:  1200 400\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 29.33it/s]                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [00:12, 33.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\videos\\ar21\\2020_07_08_ 215805...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_ar21_07_06_20Face2Jul7shuffle1_821000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_R-Arash-2020-02-28\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml';\n",
    "#path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19-Arash-2020-03-26\\\\config.yaml'\n",
    "path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19LR_R-Arash-2020-04-30\\\\config.yaml'\n",
    "path_config_file = 'D:\\\\videos\\\\ar21\\\\2020-07-06\\\\ar21_07_06_20Face2-Arash-2020-07-07\\\\config.yaml';\n",
    "\n",
    "import os\n",
    "\n",
    "Mainfolder = 'E:\\\\movies\\\\ar2breathing\\\\10_06_19'\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019'\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19'\n",
    "Mainfolder = 'E:\\\\movies\\\\MUSCIMOL\\\\ar19tear19salin\\\\10_08_19'\n",
    "Mainfolder = 'D:\\\\videos\\\\ar21\\\\2020_07_08_ 215805'\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.mp4') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('R.avi') and not f.endswith('L.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.mp4') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "\n",
    "#path_config_file = 'F:\\\\ar19muscimol500ug500nlrightside\\\\10_10_19\\\\ar19_10102019-Fassihi-2019-11-12\\\\config.yaml';\n",
    "\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml'\n",
    "##text_files = ['']\n",
    "#text_files = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\20-18-27.avi'\n",
    "\n",
    "print(text_files)\n",
    "#deeplabcut.analyze_videos(path_config_file,text_files[1:len(text_files)],shuffle=1, save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,text_files[3],shuffle=1, save_as_csv=True)\n",
    "deeplabcut.analyze_videos(path_config_file,text_files,shuffle=1, save_as_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track non tracked files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:\\movies_Rat_SC_project\\ar2breathing\\10_06_19\\22-25-05.avi\n",
      "Using snapshot-20000 for model F:\\ar2breathing\\10_06_19\\ar2_10062019_ii-Fassihi-2019-10-07\\dlc-models\\iteration-1\\ar2_10062019_iiOct7-trainset95shuffle1\n",
      "INFO:tensorflow:Restoring parameters from F:\\ar2breathing\\10_06_19\\ar2_10062019_ii-Fassihi-2019-10-07\\dlc-models\\iteration-1\\ar2_10062019_iiOct7-trainset95shuffle1\\train\\snapshot-20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from F:\\ar2breathing\\10_06_19\\ar2_10062019_ii-Fassihi-2019-10-07\\dlc-models\\iteration-1\\ar2_10062019_iiOct7-trainset95shuffle1\\train\\snapshot-20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    }
   ],
   "source": [
    "# Track non tracked files \n",
    "import os\n",
    "path_config_file = 'F:\\\\ar2breathing\\\\10_06_19\\\\ar2_10062019_ii-Fassihi-2019-10-07\\\\config.yaml';\n",
    "\n",
    "Mainfolder = 'Y:\\\\movies_Rat_SC_project\\\\ar2breathing\\\\10_06_19'\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('breathing.avi')]\n",
    "text_files2 = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('L.avi') ]\n",
    "#print(text_files)\n",
    "#%whos\n",
    "\n",
    "text_files3 = [f.replace(\"L.\", \".\") for f in text_files2 ]\n",
    "\n",
    "one_not_two = set(text_files) - set(text_files3)\n",
    "one_not_two = 'Y:\\\\movies_Rat_SC_project\\\\ar2breathing\\\\10_06_19\\\\22-25-05.avi'\n",
    "print(one_not_two)\n",
    "deeplabcut.analyze_videos(path_config_file,one_not_two,shuffle=1, save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml'\n",
    "video=['D:\\\\rat_movies_SC\\\\ar17\\\\02_25_19\\\\22-38-53.avi']\n",
    "deeplabcut.analyze_videos(path_config_file,video,shuffle=1, save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar17\\\\02_25_19'\n",
    "f2 = os.listdir(Mainfolder)\n",
    "text_files = [Mainfolder+'\\\\'+f for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "print(text_files)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [This is important step actually]\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. Make sure to provide the correct value of the \"iterations\" as it will be used to create the unique directory where the extracted frames will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\movies\\ar2breathing\\10_08_19\\ar2breathing_10_08_19LR_R-Arash-2020-04-30\\config.yaml\n",
      "network parameters: DeepCut_resnet50_ar2breathing_10_08_19LR_RApr30shuffle1_163000\n",
      "Method  uncertain  found  172  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "yes/noyes\n",
      "Loading video...\n",
      "Duration of video [s]:  2.4 , recorded @  200.0 fps!\n",
      "Overall # of frames:  480 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 2.4  seconds.\n",
      "Extracting and downsampling... 171  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171it [00:00, 744.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [472, 18, 184, 21, 94, 318, 180, 20, 216, 47, 81, 190, 100, 198, 41, 12, 228, 83, 44, 477]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: E:\\movies\\ar2breathing\\10_08_19\\20-18-27R.avi Coordinates for cropping: None\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\20-18-27R.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n"
     ]
    }
   ],
   "source": [
    "#video=['D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\analyzed\\\\18-37-27.avi']\n",
    "#video=['D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\17-33-50video.mp4']\n",
    "#video=['D:\\\\Dropbox\\\\ar17\\\\02_25_19\\\\22-37-23.avi']\n",
    "video = ['D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\11-09-14.avi']\n",
    "video = ['D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-19-45.avi','D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-31-05.avi','D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-30-40.avi']\n",
    "#15-17-08v\n",
    "video = ['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-27-18.avi','D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-47.avi']\n",
    "video = ['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-26video.mp4']\n",
    "video = ['E:\\\\movies\\\\ar2breathing\\\\10_06_19\\\\21-57-55L.avi']\n",
    "video = ['E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\20-18-27R.avi']\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml';\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019-Fassihi-2019-03-12\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19\\\\sc_ar14_06182019-Fassihi-2019-06-19\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "print(path_config_file)\n",
    "\n",
    "#deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',p_bound=.6)\n",
    "#deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',comparisonbodyparts =  ['nose','snout'],p_bound=.6)\n",
    "deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',p_bound=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\movies_Rat_SC_project\\ar20\\06_20_19\\17-30-40avi\n"
     ]
    }
   ],
   "source": [
    "print(video[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b91127c43abf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMainfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtext_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMainfolder\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.avi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19'"
     ]
    }
   ],
   "source": [
    "\n",
    "path_config_file = 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19\\\\sc_ar19_02072019-Fassihi4-2019-02-13\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "import os\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19'\n",
    "\n",
    "\n",
    "f = os.listdir(Mainfolder)\n",
    "text_files = [f for f in os.listdir(Mainfolder) if f.endswith('.avi')]\n",
    "\n",
    "\n",
    "my_list = text_files\n",
    "thisApen = Mainfolder+'kir'\n",
    "thisApen = thisApen.replace(\"kir\", \"\\\\\")\n",
    "string = thisApen\n",
    "my_new_list = [ string + x for x in my_list]\n",
    "\n",
    "deeplabcut.extract_outlier_frames(path_config_file,my_new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot activate multiple GUI eventloops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows\n",
      "Checking labels if they are outside the image\n",
      "Checking labels if they are outside the image\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "On level 0, label max (1) >= length of level  (1). NOTE: this index is in an inconsistent state",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\refinement.py\u001b[0m in \u001b[0;36msaveDataSet\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMainFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhumanscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'likelihood'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36mset_levels\u001b[1;34m(self, levels, level, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0midx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset_identity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         idx._set_levels(levels, level=level, validate=True,\n\u001b[1;32m--> 278\u001b[1;33m                         verify_integrity=verify_integrity)\n\u001b[0m\u001b[0;32m    279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36m_set_levels\u001b[1;34m(self, levels, level, copy, validate, verify_integrity)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverify_integrity\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_levels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[1;34m(self, labels, levels)\u001b[0m\n\u001b[0;32m    176\u001b[0m                                  \u001b[1;34m\" level  (%d). NOTE: this index is in an\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                                  \" inconsistent state\" % (i, label.max(),\n\u001b[1;32m--> 178\u001b[1;33m                                                           len(level)))\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: On level 0, label max (1) >= length of level  (1). NOTE: this index is in an inconsistent state"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "#import matplotlib\n",
    "#print(matplotlib.__version__)\n",
    "%gui wx\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019-Fassihi-2019-03-12\\\\config.yaml'\n",
    "#print(path_config_file)\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 2.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "#Once all folders are relabeled, check them and advance. See how to check labels, above!\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refine labels, append these frames to the original dataset to create a new iteration of training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "list_of_ints = list(range(2))\n",
    "print(list_of_ints)\n",
    "deeplabcut.create_training_dataset(path_config_file,Shuffles= list_of_ints) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\rat_movies_SC\\ar2breathing\\10_06_19\\ar19salin_10-06-19_LR-Arash-2020-01-24\\config.yaml\n",
      "Starting %  D:\\rat_movies_SC\\ar2breathing\\10_06_19\\Right ['D:\\\\rat_movies_SC\\\\ar2breathing\\\\10_06_19\\\\Right\\\\22-17-49R.avi']\n",
      "Loading  D:\\rat_movies_SC\\ar2breathing\\10_06_19\\Right\\22-17-49R.avi and data.\n",
      "False 0 202 0 181\n",
      "562\n",
      "Duration of video [s]:  2.81 , recorded with  200.0 fps!\n",
      "Overall # of frames:  562 with cropped frame dimensions:  202 181\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 562/562 [02:39<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labeled frames were created, now generating video...\n"
     ]
    }
   ],
   "source": [
    "print(path_config_file)\n",
    "videofile  = ['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-02.avi','D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-47.avi']\n",
    "videofile = ['F:\\\\ar2breathing\\\\10_18_19\\\\00-16-30video.mp4']\n",
    "videofile = ['F:\\\\ar2breathing\\\\10_18_19\\\\00-16-30video.mp4']\n",
    "videofile = ['D:\\\\rat_movies_SC\\\\ar2breathing\\\\10_06_19\\\\Right\\\\22-17-49R.avi']\n",
    "\n",
    "deeplabcut.create_labeled_video(path_config_file,videofile,save_frames=True) # my_new_list was created in prevouse cell as all videos in the folder \n",
    "#deeplabcut.create_labeled_video(path_config_file,text_files,save_frames=True) # my_new_list was created in prevouse cell as all videos in the folder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos (optional)\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook #for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,my_new_list)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
