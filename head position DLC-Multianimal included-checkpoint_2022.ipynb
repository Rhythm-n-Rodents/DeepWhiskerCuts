{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# Arash SC create a project for head position\n",
    "\n",
    "\n",
    "\n",
    "This notebook demonstrates the necessary steps to use python and DeepLabCut for creating and analysins videos from orientation \n",
    "experiment \n",
    "\n",
    "This notebook illustrates how to:\n",
    " \n",
    "- make a movie from images \n",
    "- create a project\n",
    "- extract training frames\n",
    "- label the frames\n",
    "- plot the labeled images (optional)\n",
    "- create a training set\n",
    "- train a network\n",
    "- evaluate a network\n",
    "- analyze a novel video\n",
    "- create an automatically labeled video (optional)\n",
    "- Go to Matlab \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Create a new project\n",
    "\n",
    "It is always good idea to keep the projects seperate. This function creates a new project with subdirectories and a basic configuration file in the user defined directory otherwise the project is created in the current working directory.\n",
    "\n",
    "You can always add new videos to the project at any stage of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DKLAb\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\DKLAb\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\DKLAb\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\DKLAb\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\DKLAb\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\DKLAb\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\DKLAb\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\dask\\dataframe\\utils.py:15: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "## https://github.com/AlexEMG/DeepLabCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task='ar21_07_06_20LR_R' # Enter the name of your experiment Task\n",
    "task='Sideview_Aug' \n",
    "task='Topview3435_FEB22' \n",
    "\n",
    "experimenter='Arash' # Enter the name of the experimenter\n",
    "Mainfolder =  'D:\\\\\\videos\\\\AR19distance\\\\2020_09_14_ 215321'; # Enter the name of the folder with images folders inside \n",
    "Mainfolder = 'F:\\\\videos\\\\ar34motor\\\\2022_02_04\\\\';\n",
    "filenames = ['130video.mp4','140video.mp4','19video.mp4','24video.mp4','60video.mp4','33video.mp4']; # Enter the name of the files you want to train\n",
    "video = [str(Mainfolder)+str(f) for f in filenames]; # add path to each file\n",
    "Mainfolder2 = 'F:\\\\videos\\\\ar35motor\\\\2022_02_04\\\\';\n",
    "filenames2 = ['80video.mp4','90video.mp4','44video.mp4','40video.mp4','287video.mp4','286video.mp4']; # Enter the name of the files you want to train\n",
    "video2 = [str(Mainfolder2)+str(f) for f in filenames2]; # add path to each file\n",
    "video = video+video2\n",
    "#Mainfolder3 = 'D:\\\\Sidevideos\\\\ar343rdday\\\\2021_07_16\\\\';\n",
    "\n",
    "#filenames2 = ['22.avi','24.avi','25.avi']; # Enter the name of the files you want to train\n",
    "#video2 = [str(Mainfolder3)+str(f) for f in filenames2]; # add path to each file\n",
    "#video = video+video2\n",
    "\n",
    "print(video)\n",
    "#deeplabcut.create_new_project(task,experimenter,video, working_directory=Mainfolder,copy_videos=False) #change the working directory to where you want the folders created.\n",
    "deeplabcut.create_new_project(task,experimenter, video, working_directory='D:\\\\Sidevideos\\\\DLC',copy_videos=True, multianimal=False)\n",
    "#deeplabcut.create_new_project(task,experimenter, video,copy_videos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yXW0bx1oEJA"
   },
   "source": [
    "## Extract frames from videos \n",
    "A key point for a successful feature detector is to select diverse frames, which are typical for the behavior you study that should be labeled.\n",
    "\n",
    "This function selects N frames either uniformly sampled from a particular video (or folder) (algo=='uniform'). Note: this might not yield diverse frames, if the behavior is sparsely distributed (consider using kmeans), and/or select frames manually etc.\n",
    "\n",
    "Also make sure to get select data from different (behavioral) sessions and different animals if those vary substantially (to train an invariant feature detector).\n",
    "\n",
    "Individual images should not be too big (i.e. < 850 x 850 pixel). Although this can be taken care of later as well, it is advisable to crop the frames, to remove unnecessary parts of the frame as much as possible.\n",
    "\n",
    "Always check the output of cropping. If you are happy with the results proceed to labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1ulumCuoEJC"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face2-Arash-2020-09-15\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar32_10_09_20Face3-Arash-2020-10-10\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar30_10_10_14spouts-Arash-2020-10-24\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\ar32_10_11_12-Arash-2020-11-14\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\ar302_10_11_14-Arash-2020-11-16\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\ar32_10_11_24-Arash-2020-11-25\\\\config.yaml';\n",
    "path_config_file ='D:\\\\Sidevideos\\\\DLC\\\\Sideview_Aug-Arash-2021-08-04\\\\config.yaml';\n",
    "path_config_file ='D:\\\\Sidevideos\\\\DLC\\\\Topview3435_FEB22-Arash-2022-02-06\\\\config.yaml';\n",
    "#Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#deeplabcut.extract_frames(path_config_file,'automatic','uniform',crop=True) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n",
    "#deeplabcut.extract_frames(path_config_file,'automatic','uniform',crop=True, checkcropping=True) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n",
    "#You can change the cropping to false, then delete the checkcropping part!\n",
    "deeplabcut.extract_frames(path_config_file,'manual',crop=True) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the config path and load deeplabcut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the Path config file path\n",
    "path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19LR_R-Arash-2020-04-30\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar21\\\\2020-07-06\\\\ar21_07_06_20Face2-Arash-2020-07-07\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face3-Arash-2020-09-16\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\2020_10_09\\\\ar32_10_09_20Face3-Arash-2020-10-10\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\notebook\\\\ar30_10_10_14spouts-Arash-2020-10-24\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar30\\\\ar30_10_11_04-Arash-2020-11-05\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\ar32_10_11_12-Arash-2020-11-14\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\ar302_10_11_14-Arash-2020-11-16\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\ar32_10_11_24-Arash-2020-11-25\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar32\\\\ar32_10_11_24-Arash-2020-11-25\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\Sideview4-Arash-2021-07-18\\\\config.yaml'\n",
    "path_config_file = 'D:\\\\Sidevideos\\\\DLC\\\\Sideview4-Arash-2021-07-18\\\\config.yaml'\n",
    "\n",
    "path_config_file ='D:\\\\Sidevideos\\\\DLC\\\\Sideview_Aug-Arash-2021-08-04\\\\config.yaml';\n",
    "path_config_file ='D:\\\\Sidevideos\\\\DLC\\\\Topview3435_FEB22-Arash-2022-02-06\\\\config.yaml';\n",
    "path_config_file ='E:\\\\DLC\\\\SideviewLeft_Feb2022-Arash-2022-02-08\\\\config.yaml';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add videos from other folders and rats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying the videos\n",
      "Copying the videos\n",
      "Copying the videos\n",
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n"
     ]
    }
   ],
   "source": [
    "Mainfolder =  'D:\\\\Sidevideos\\\\ar35Motor\\\\2022_02_04'; # Enter the name of the folder with images folders inside \n",
    "filenames = ['20L.avi','21L.avi','20L.avi','21L.avi']; # Enter the name of the files you want to train\n",
    "#filenames = ['6L.avi']; # Enter the name of the files you want to train\n",
    "video = [str(Mainfolder)+str(f) for f in filenames]; # add path to each file\n",
    "Mainfolder2 = 'D:\\\\Sidevideos\\\\ar35Motor\\\\2022_02_04\\\\';\n",
    "filenames2 = ['29video.mp4','30video.mp4','31video.mp4']; # Enter the name of the files you want to train\n",
    "video2 = [str(Mainfolder2)+str(f) for f in filenames2]; # add path to each file\n",
    "video = video+video2\n",
    "deeplabcut.add_new_videos(path_config_file, video2, copy_videos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\DLC\\SideviewLeft_Feb2022-Arash-2022-02-08\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "print(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gjn6ZDonoEJH"
   },
   "source": [
    "## Label the extracted frames\n",
    "Only videos in the config file can be used to extract the frames. Extracted labels for each video are stored in the project directory under the subdirectory **'labeled-data'**. Each subdirectory is named after the name of the video. The toolbox has a labeling toolbox which could be used for labeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyROSOiEoEJI"
   },
   "outputs": [],
   "source": [
    "%gui wx\n",
    "\n",
    "deeplabcut.label_frames(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vim95ZvkPSeN"
   },
   "source": [
    "**Check the labels**\n",
    "\n",
    "Checking if the labels were created and stored correctly is beneficial for training, since labeling is one of the most critical parts for creating the training dataset. The DeepLabCut toolbox provides a function `check\\_labels'  to do so. It is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwvgPJouPP2O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Arash.\n",
      "E:\\DLC\\SideviewLeft_Feb2022-Arash-2022-02-08\\labeled-data\\141video_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:05<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\DLC\\SideviewLeft_Feb2022-Arash-2022-02-08\\labeled-data\\145video_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\DLC\\SideviewLeft_Feb2022-Arash-2022-02-08\\labeled-data\\157video_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\DLC\\SideviewLeft_Feb2022-Arash-2022-02-08\\labeled-data\\233video_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  6.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:03<00:00,  5.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:04<00:00,  5.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  6.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:03<00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add_new_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mainfolder =  'D:\\\\videos\\\\ar32\\\\2020_11_12\\\\'; # Enter the name of the folder with images folders inside \n",
    "filenames = ['158.avi','160.avi']; # Enter the name of the files you want to train\n",
    "#filenames = ['6L.avi']; # Enter the name of the files you want to train\n",
    "video = [str(Mainfolder)+str(f) for f in filenames]; # add path to each file\n",
    "deeplabcut.add_new_videos(path_config_file, video, copy_videos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder: Build your skeleton connections before you create a training set!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\ipykernel\\eventloops.py\u001b[0m in \u001b[0;36mon_timer\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mdef\u001b[0m \u001b[0mon_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<deeplabcut.utils.skeleton.SkeletonBuilder at 0x19350436cc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.SkeletonBuilder(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "of87fOjgPqzH"
   },
   "source": [
    "If the labels need adjusted, you can use the refinement GUI to move them around! Check that out below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "This function generates the training data information for DeepCut (which requires a mat file) based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles. \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([143,  10, 126, 108,  97,   2, 130,  86, 106, 175,  27,  59,  78,\n",
       "           26,   9,  89, 142, 128,  14, 129,  35,  52,  66, 127, 161,  63,\n",
       "           56,  61,  31, 124, 155, 118, 176, 144, 125,  64,   4, 113,  46,\n",
       "           92,  16,  79,  55, 173,  65,  12,  23,  29,  95, 104, 133, 172,\n",
       "          109, 134,  42,  93, 116,  41, 149,  47,  70,  94, 163, 165, 166,\n",
       "          168,  60, 156, 164, 121,  85,  58, 107, 114,   0, 151,  40, 157,\n",
       "            7,   1, 137,   8, 117,  53, 136, 177,  30,  74,  69,  13, 132,\n",
       "           96, 171,  44, 174, 162, 146,  20, 122,  28, 141,  77,  91, 112,\n",
       "           84,  75,  49, 123, 119, 159,  50,  25,  54, 105,  87, 147,  81,\n",
       "           45, 160, 158, 140, 152,   5, 154,  37,  17, 103, 111,   6,  15,\n",
       "           98,  68,  82, 115, 101, 120,  11, 150,  51,  71,   3, 167,  88,\n",
       "           24,  36,  73,  22, 100, 138,  76, 148,  80,  34,  39, 139, 131,\n",
       "           38, 169,  57, 110,  18, 170,  48, 178, 145,  99, 135,  72,  90,\n",
       "           83]),\n",
       "   array([153,  32,  62,  19,  21, 102,  43,  67,  33])))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\DLC\\SideviewLeft_Feb2022-Arash-2022-02-08\\training-datasets\\iteration-0\\UnaugmentedDataSet_SideviewLeft_Feb2022Feb8  already exists!\n",
      "E:\\DLC\\SideviewLeft_Feb2022-Arash-2022-02-08\\training-datasets\\iteration-0\\UnaugmentedDataSet_SideviewLeft_Feb2022Feb8  already exists!\n",
      "You passed a split with the following fraction: 95%\n",
      "E:\\DLC\\SideviewLeft_Feb2022-Arash-2022-02-08\\dlc-models\\iteration-0\\SideviewLeft_Feb2022Feb8-trainset95shuffle1  already exists!\n",
      "E:\\DLC\\SideviewLeft_Feb2022-Arash-2022-02-08\\dlc-models\\iteration-0\\SideviewLeft_Feb2022Feb8-trainset95shuffle1/train  already exists!\n",
      "E:\\DLC\\SideviewLeft_Feb2022-Arash-2022-02-08\\dlc-models\\iteration-0\\SideviewLeft_Feb2022Feb8-trainset95shuffle1/test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n",
      "E:\\DLC\\SideviewLeft_Feb2022-Arash-2022-02-08\\training-datasets\\iteration-0\\UnaugmentedDataSet_SideviewLeft_Feb2022Feb8  already exists!\n",
      "You passed a split with the following fraction: 95%\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_training_model_comparison(path_config_file, num_shuffles=1, net_types=['resnet_50'], augmenter_types=['default', 'imgaug'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training  \n",
    "### If yu want to use your GPU, you need to exit here and either work from the Docker container, your own TensorFlow installation in an Anaconda env\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['Nose', 'Head', 'Eye'],\n",
      " 'alpha_r': 0.02,\n",
      " 'batch_size': 1,\n",
      " 'clahe': True,\n",
      " 'claheratio': 0.1,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_SideviewLeft_Feb2022Feb8\\\\SideviewLeft_Feb2022_Arash95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'edge': False,\n",
      " 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'histeq': True,\n",
      " 'histeqratio': 0.1,\n",
      " 'init_weights': 'C:\\\\Users\\\\DKLAb\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_SideviewLeft_Feb2022Feb8\\\\Documentation_data-SideviewLeft_Feb2022_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'E:\\\\DLC\\\\SideviewLeft_Feb2022-Arash-2022-02-08',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'sharpen': False,\n",
      " 'sharpenratio': 0.3,\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'E:\\\\DLC\\\\SideviewLeft_Feb2022-Arash-2022-02-08\\\\dlc-models\\\\iteration-0\\\\SideviewLeft_Feb2022Feb8-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Starting with imgaug pose-dataset loader (=default).\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Display_iters overwritten as 1000\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'E:\\\\DLC\\\\SideviewLeft_Feb2022-Arash-2022-02-08\\\\dlc-models\\\\iteration-0\\\\SideviewLeft_Feb2022Feb8-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2]], 'all_joints_names': ['Nose', 'Head', 'Eye'], 'alpha_r': 0.02, 'clahe': True, 'claheratio': 0.1, 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_SideviewLeft_Feb2022Feb8\\\\SideviewLeft_Feb2022_Arash95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]}, 'histeq': True, 'histeqratio': 0.1, 'init_weights': 'C:\\\\Users\\\\DKLAb\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_SideviewLeft_Feb2022Feb8\\\\Documentation_data-SideviewLeft_Feb2022_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 3, 'pos_dist_thresh': 17, 'project_path': 'E:\\\\DLC\\\\SideviewLeft_Feb2022-Arash-2022-02-08', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'sharpen': False, 'sharpenratio': 0.3, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000 loss: 0.0164 lr: 0.005\n",
      "iteration: 2000 loss: 0.0075 lr: 0.005\n",
      "iteration: 3000 loss: 0.0063 lr: 0.005\n",
      "iteration: 4000 loss: 0.0055 lr: 0.005\n",
      "iteration: 5000 loss: 0.0052 lr: 0.005\n",
      "iteration: 6000 loss: 0.0050 lr: 0.005\n",
      "iteration: 7000 loss: 0.0048 lr: 0.005\n",
      "iteration: 8000 loss: 0.0045 lr: 0.005\n",
      "iteration: 9000 loss: 0.0045 lr: 0.005\n",
      "iteration: 10000 loss: 0.0045 lr: 0.005\n",
      "iteration: 11000 loss: 0.0056 lr: 0.02\n",
      "iteration: 12000 loss: 0.0052 lr: 0.02\n",
      "iteration: 13000 loss: 0.0049 lr: 0.02\n",
      "iteration: 14000 loss: 0.0047 lr: 0.02\n",
      "iteration: 15000 loss: 0.0045 lr: 0.02\n",
      "iteration: 16000 loss: 0.0044 lr: 0.02\n",
      "iteration: 17000 loss: 0.0043 lr: 0.02\n",
      "iteration: 18000 loss: 0.0042 lr: 0.02\n",
      "iteration: 19000 loss: 0.0040 lr: 0.02\n",
      "iteration: 20000 loss: 0.0042 lr: 0.02\n",
      "iteration: 21000 loss: 0.0040 lr: 0.02\n",
      "iteration: 22000 loss: 0.0039 lr: 0.02\n",
      "iteration: 23000 loss: 0.0037 lr: 0.02\n",
      "iteration: 24000 loss: 0.0038 lr: 0.02\n",
      "iteration: 25000 loss: 0.0038 lr: 0.02\n",
      "iteration: 26000 loss: 0.0037 lr: 0.02\n",
      "iteration: 27000 loss: 0.0036 lr: 0.02\n",
      "iteration: 28000 loss: 0.0037 lr: 0.02\n",
      "iteration: 29000 loss: 0.0036 lr: 0.02\n",
      "iteration: 30000 loss: 0.0036 lr: 0.02\n",
      "iteration: 31000 loss: 0.0036 lr: 0.02\n",
      "iteration: 32000 loss: 0.0034 lr: 0.02\n",
      "iteration: 33000 loss: 0.0035 lr: 0.02\n",
      "iteration: 34000 loss: 0.0034 lr: 0.02\n",
      "iteration: 35000 loss: 0.0035 lr: 0.02\n",
      "iteration: 36000 loss: 0.0034 lr: 0.02\n",
      "iteration: 37000 loss: 0.0034 lr: 0.02\n",
      "iteration: 38000 loss: 0.0034 lr: 0.02\n",
      "iteration: 39000 loss: 0.0035 lr: 0.02\n",
      "iteration: 40000 loss: 0.0034 lr: 0.02\n",
      "iteration: 41000 loss: 0.0034 lr: 0.02\n",
      "iteration: 42000 loss: 0.0033 lr: 0.02\n",
      "iteration: 43000 loss: 0.0034 lr: 0.02\n",
      "iteration: 44000 loss: 0.0034 lr: 0.02\n",
      "iteration: 45000 loss: 0.0033 lr: 0.02\n",
      "iteration: 46000 loss: 0.0032 lr: 0.02\n",
      "iteration: 47000 loss: 0.0033 lr: 0.02\n",
      "iteration: 48000 loss: 0.0033 lr: 0.02\n",
      "iteration: 49000 loss: 0.0032 lr: 0.02\n",
      "iteration: 50000 loss: 0.0032 lr: 0.02\n",
      "iteration: 51000 loss: 0.0032 lr: 0.02\n",
      "iteration: 52000 loss: 0.0032 lr: 0.02\n",
      "iteration: 53000 loss: 0.0032 lr: 0.02\n",
      "iteration: 54000 loss: 0.0032 lr: 0.02\n",
      "iteration: 55000 loss: 0.0031 lr: 0.02\n",
      "iteration: 56000 loss: 0.0032 lr: 0.02\n",
      "iteration: 57000 loss: 0.0031 lr: 0.02\n",
      "iteration: 58000 loss: 0.0031 lr: 0.02\n",
      "iteration: 59000 loss: 0.0031 lr: 0.02\n",
      "iteration: 60000 loss: 0.0031 lr: 0.02\n",
      "iteration: 61000 loss: 0.0032 lr: 0.02\n",
      "iteration: 62000 loss: 0.0031 lr: 0.02\n",
      "iteration: 63000 loss: 0.0031 lr: 0.02\n",
      "iteration: 64000 loss: 0.0031 lr: 0.02\n",
      "iteration: 65000 loss: 0.0030 lr: 0.02\n",
      "iteration: 66000 loss: 0.0030 lr: 0.02\n",
      "iteration: 67000 loss: 0.0031 lr: 0.02\n",
      "iteration: 68000 loss: 0.0030 lr: 0.02\n",
      "iteration: 69000 loss: 0.0031 lr: 0.02\n",
      "iteration: 70000 loss: 0.0030 lr: 0.02\n",
      "iteration: 71000 loss: 0.0030 lr: 0.02\n",
      "iteration: 72000 loss: 0.0031 lr: 0.02\n",
      "iteration: 73000 loss: 0.0029 lr: 0.02\n",
      "iteration: 74000 loss: 0.0029 lr: 0.02\n",
      "iteration: 75000 loss: 0.0031 lr: 0.02\n",
      "iteration: 76000 loss: 0.0029 lr: 0.02\n",
      "iteration: 77000 loss: 0.0030 lr: 0.02\n",
      "iteration: 78000 loss: 0.0029 lr: 0.02\n",
      "iteration: 79000 loss: 0.0029 lr: 0.02\n",
      "iteration: 80000 loss: 0.0029 lr: 0.02\n",
      "iteration: 81000 loss: 0.0029 lr: 0.02\n",
      "iteration: 82000 loss: 0.0028 lr: 0.02\n",
      "iteration: 83000 loss: 0.0029 lr: 0.02\n",
      "iteration: 84000 loss: 0.0029 lr: 0.02\n",
      "iteration: 85000 loss: 0.0029 lr: 0.02\n",
      "iteration: 86000 loss: 0.0030 lr: 0.02\n",
      "iteration: 87000 loss: 0.0029 lr: 0.02\n",
      "iteration: 88000 loss: 0.0029 lr: 0.02\n",
      "iteration: 89000 loss: 0.0028 lr: 0.02\n",
      "iteration: 90000 loss: 0.0028 lr: 0.02\n",
      "iteration: 91000 loss: 0.0029 lr: 0.02\n",
      "iteration: 92000 loss: 0.0028 lr: 0.02\n",
      "iteration: 93000 loss: 0.0029 lr: 0.02\n",
      "iteration: 94000 loss: 0.0028 lr: 0.02\n",
      "iteration: 95000 loss: 0.0028 lr: 0.02\n",
      "iteration: 96000 loss: 0.0028 lr: 0.02\n",
      "iteration: 97000 loss: 0.0028 lr: 0.02\n",
      "iteration: 98000 loss: 0.0028 lr: 0.02\n",
      "iteration: 99000 loss: 0.0027 lr: 0.02\n",
      "iteration: 100000 loss: 0.0028 lr: 0.02\n",
      "iteration: 101000 loss: 0.0028 lr: 0.02\n",
      "iteration: 102000 loss: 0.0028 lr: 0.02\n",
      "iteration: 103000 loss: 0.0028 lr: 0.02\n",
      "iteration: 104000 loss: 0.0028 lr: 0.02\n",
      "iteration: 105000 loss: 0.0028 lr: 0.02\n",
      "iteration: 106000 loss: 0.0028 lr: 0.02\n",
      "iteration: 107000 loss: 0.0027 lr: 0.02\n",
      "iteration: 108000 loss: 0.0027 lr: 0.02\n",
      "iteration: 109000 loss: 0.0027 lr: 0.02\n",
      "iteration: 110000 loss: 0.0027 lr: 0.02\n",
      "iteration: 111000 loss: 0.0028 lr: 0.02\n",
      "iteration: 112000 loss: 0.0027 lr: 0.02\n",
      "iteration: 113000 loss: 0.0027 lr: 0.02\n",
      "iteration: 114000 loss: 0.0027 lr: 0.02\n",
      "iteration: 115000 loss: 0.0026 lr: 0.02\n",
      "iteration: 116000 loss: 0.0026 lr: 0.02\n",
      "iteration: 117000 loss: 0.0026 lr: 0.02\n",
      "iteration: 118000 loss: 0.0027 lr: 0.02\n",
      "iteration: 119000 loss: 0.0025 lr: 0.02\n",
      "iteration: 120000 loss: 0.0027 lr: 0.02\n",
      "iteration: 121000 loss: 0.0026 lr: 0.02\n",
      "iteration: 122000 loss: 0.0027 lr: 0.02\n",
      "iteration: 123000 loss: 0.0026 lr: 0.02\n",
      "iteration: 124000 loss: 0.0027 lr: 0.02\n",
      "iteration: 125000 loss: 0.0026 lr: 0.02\n",
      "iteration: 126000 loss: 0.0027 lr: 0.02\n",
      "iteration: 127000 loss: 0.0026 lr: 0.02\n",
      "iteration: 128000 loss: 0.0026 lr: 0.02\n",
      "iteration: 129000 loss: 0.0026 lr: 0.02\n",
      "iteration: 130000 loss: 0.0026 lr: 0.02\n",
      "iteration: 131000 loss: 0.0026 lr: 0.02\n",
      "iteration: 132000 loss: 0.0026 lr: 0.02\n",
      "iteration: 133000 loss: 0.0026 lr: 0.02\n",
      "iteration: 134000 loss: 0.0026 lr: 0.02\n",
      "iteration: 135000 loss: 0.0026 lr: 0.02\n",
      "iteration: 136000 loss: 0.0026 lr: 0.02\n",
      "iteration: 137000 loss: 0.0026 lr: 0.02\n",
      "iteration: 138000 loss: 0.0027 lr: 0.02\n",
      "iteration: 139000 loss: 0.0025 lr: 0.02\n",
      "iteration: 140000 loss: 0.0026 lr: 0.02\n",
      "iteration: 141000 loss: 0.0025 lr: 0.02\n",
      "iteration: 142000 loss: 0.0026 lr: 0.02\n",
      "iteration: 143000 loss: 0.0026 lr: 0.02\n",
      "iteration: 144000 loss: 0.0025 lr: 0.02\n",
      "iteration: 145000 loss: 0.0025 lr: 0.02\n",
      "iteration: 146000 loss: 0.0026 lr: 0.02\n",
      "iteration: 147000 loss: 0.0025 lr: 0.02\n",
      "iteration: 148000 loss: 0.0026 lr: 0.02\n",
      "iteration: 149000 loss: 0.0025 lr: 0.02\n",
      "iteration: 150000 loss: 0.0026 lr: 0.02\n",
      "iteration: 151000 loss: 0.0025 lr: 0.02\n",
      "iteration: 152000 loss: 0.0025 lr: 0.02\n",
      "iteration: 153000 loss: 0.0025 lr: 0.02\n",
      "iteration: 154000 loss: 0.0025 lr: 0.02\n",
      "iteration: 155000 loss: 0.0024 lr: 0.02\n",
      "iteration: 156000 loss: 0.0025 lr: 0.02\n",
      "iteration: 157000 loss: 0.0025 lr: 0.02\n",
      "iteration: 158000 loss: 0.0025 lr: 0.02\n",
      "iteration: 159000 loss: 0.0025 lr: 0.02\n",
      "iteration: 160000 loss: 0.0025 lr: 0.02\n",
      "iteration: 161000 loss: 0.0024 lr: 0.02\n",
      "iteration: 162000 loss: 0.0025 lr: 0.02\n",
      "iteration: 163000 loss: 0.0025 lr: 0.02\n",
      "iteration: 164000 loss: 0.0024 lr: 0.02\n",
      "iteration: 165000 loss: 0.0025 lr: 0.02\n",
      "iteration: 166000 loss: 0.0024 lr: 0.02\n",
      "iteration: 167000 loss: 0.0025 lr: 0.02\n",
      "iteration: 168000 loss: 0.0025 lr: 0.02\n",
      "iteration: 169000 loss: 0.0024 lr: 0.02\n",
      "iteration: 170000 loss: 0.0023 lr: 0.02\n",
      "iteration: 171000 loss: 0.0025 lr: 0.02\n",
      "iteration: 172000 loss: 0.0024 lr: 0.02\n",
      "iteration: 173000 loss: 0.0024 lr: 0.02\n",
      "iteration: 174000 loss: 0.0024 lr: 0.02\n",
      "iteration: 175000 loss: 0.0024 lr: 0.02\n",
      "iteration: 176000 loss: 0.0024 lr: 0.02\n",
      "iteration: 177000 loss: 0.0024 lr: 0.02\n",
      "iteration: 178000 loss: 0.0025 lr: 0.02\n",
      "iteration: 179000 loss: 0.0024 lr: 0.02\n",
      "iteration: 180000 loss: 0.0023 lr: 0.02\n",
      "iteration: 181000 loss: 0.0024 lr: 0.02\n",
      "iteration: 182000 loss: 0.0024 lr: 0.02\n",
      "iteration: 183000 loss: 0.0024 lr: 0.02\n",
      "iteration: 184000 loss: 0.0024 lr: 0.02\n",
      "iteration: 185000 loss: 0.0024 lr: 0.02\n",
      "iteration: 186000 loss: 0.0024 lr: 0.02\n",
      "iteration: 187000 loss: 0.0023 lr: 0.02\n",
      "iteration: 188000 loss: 0.0024 lr: 0.02\n",
      "iteration: 189000 loss: 0.0024 lr: 0.02\n",
      "iteration: 190000 loss: 0.0023 lr: 0.02\n",
      "iteration: 191000 loss: 0.0023 lr: 0.02\n",
      "iteration: 192000 loss: 0.0024 lr: 0.02\n",
      "iteration: 193000 loss: 0.0024 lr: 0.02\n",
      "iteration: 194000 loss: 0.0023 lr: 0.02\n",
      "iteration: 195000 loss: 0.0024 lr: 0.02\n",
      "iteration: 196000 loss: 0.0023 lr: 0.02\n",
      "iteration: 197000 loss: 0.0023 lr: 0.02\n",
      "iteration: 198000 loss: 0.0023 lr: 0.02\n",
      "iteration: 199000 loss: 0.0023 lr: 0.02\n",
      "iteration: 200000 loss: 0.0023 lr: 0.02\n",
      "iteration: 201000 loss: 0.0023 lr: 0.02\n",
      "iteration: 202000 loss: 0.0023 lr: 0.02\n",
      "iteration: 203000 loss: 0.0023 lr: 0.02\n",
      "iteration: 204000 loss: 0.0023 lr: 0.02\n",
      "iteration: 205000 loss: 0.0023 lr: 0.02\n",
      "iteration: 206000 loss: 0.0023 lr: 0.02\n",
      "iteration: 207000 loss: 0.0023 lr: 0.02\n",
      "iteration: 208000 loss: 0.0023 lr: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 209000 loss: 0.0023 lr: 0.02\n",
      "iteration: 210000 loss: 0.0023 lr: 0.02\n",
      "iteration: 211000 loss: 0.0023 lr: 0.02\n",
      "iteration: 212000 loss: 0.0023 lr: 0.02\n",
      "iteration: 213000 loss: 0.0022 lr: 0.02\n",
      "iteration: 214000 loss: 0.0023 lr: 0.02\n",
      "iteration: 215000 loss: 0.0023 lr: 0.02\n",
      "iteration: 216000 loss: 0.0023 lr: 0.02\n",
      "iteration: 217000 loss: 0.0023 lr: 0.02\n",
      "iteration: 218000 loss: 0.0023 lr: 0.02\n",
      "iteration: 219000 loss: 0.0023 lr: 0.02\n",
      "iteration: 220000 loss: 0.0022 lr: 0.02\n",
      "iteration: 221000 loss: 0.0022 lr: 0.02\n",
      "iteration: 222000 loss: 0.0023 lr: 0.02\n",
      "iteration: 223000 loss: 0.0023 lr: 0.02\n",
      "iteration: 224000 loss: 0.0022 lr: 0.02\n",
      "iteration: 225000 loss: 0.0022 lr: 0.02\n",
      "iteration: 226000 loss: 0.0022 lr: 0.02\n",
      "iteration: 227000 loss: 0.0022 lr: 0.02\n",
      "iteration: 228000 loss: 0.0022 lr: 0.02\n",
      "iteration: 229000 loss: 0.0022 lr: 0.02\n",
      "iteration: 230000 loss: 0.0022 lr: 0.02\n",
      "iteration: 231000 loss: 0.0023 lr: 0.02\n",
      "iteration: 232000 loss: 0.0022 lr: 0.02\n",
      "iteration: 233000 loss: 0.0022 lr: 0.02\n",
      "iteration: 234000 loss: 0.0021 lr: 0.02\n",
      "iteration: 235000 loss: 0.0022 lr: 0.02\n",
      "iteration: 236000 loss: 0.0022 lr: 0.02\n",
      "iteration: 237000 loss: 0.0022 lr: 0.02\n",
      "iteration: 238000 loss: 0.0022 lr: 0.02\n",
      "iteration: 239000 loss: 0.0021 lr: 0.02\n",
      "iteration: 240000 loss: 0.0021 lr: 0.02\n",
      "iteration: 241000 loss: 0.0021 lr: 0.02\n",
      "iteration: 242000 loss: 0.0021 lr: 0.02\n",
      "iteration: 243000 loss: 0.0021 lr: 0.02\n",
      "iteration: 244000 loss: 0.0021 lr: 0.02\n",
      "iteration: 245000 loss: 0.0022 lr: 0.02\n",
      "iteration: 246000 loss: 0.0022 lr: 0.02\n",
      "iteration: 247000 loss: 0.0022 lr: 0.02\n",
      "iteration: 248000 loss: 0.0022 lr: 0.02\n",
      "iteration: 249000 loss: 0.0022 lr: 0.02\n",
      "iteration: 250000 loss: 0.0021 lr: 0.02\n",
      "iteration: 251000 loss: 0.0021 lr: 0.02\n",
      "iteration: 252000 loss: 0.0021 lr: 0.02\n",
      "iteration: 253000 loss: 0.0022 lr: 0.02\n",
      "iteration: 254000 loss: 0.0021 lr: 0.02\n",
      "iteration: 255000 loss: 0.0021 lr: 0.02\n",
      "iteration: 256000 loss: 0.0022 lr: 0.02\n",
      "iteration: 257000 loss: 0.0022 lr: 0.02\n",
      "iteration: 258000 loss: 0.0021 lr: 0.02\n",
      "iteration: 259000 loss: 0.0021 lr: 0.02\n",
      "iteration: 260000 loss: 0.0021 lr: 0.02\n",
      "iteration: 261000 loss: 0.0020 lr: 0.02\n",
      "iteration: 262000 loss: 0.0021 lr: 0.02\n",
      "iteration: 263000 loss: 0.0021 lr: 0.02\n",
      "iteration: 264000 loss: 0.0021 lr: 0.02\n",
      "iteration: 265000 loss: 0.0021 lr: 0.02\n",
      "iteration: 266000 loss: 0.0021 lr: 0.02\n",
      "iteration: 267000 loss: 0.0021 lr: 0.02\n",
      "iteration: 268000 loss: 0.0021 lr: 0.02\n",
      "iteration: 269000 loss: 0.0021 lr: 0.02\n",
      "iteration: 270000 loss: 0.0020 lr: 0.02\n",
      "iteration: 271000 loss: 0.0022 lr: 0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8253cc711f6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m                 \u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m             )  # pass on path and file name for pose_cfg.yaml!\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         [_, loss_val, summary] = sess.run(\n\u001b[1;32m--> 277\u001b[1;33m             \u001b[1;33m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_summaries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m         )\n\u001b[0;32m    279\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file,shuffle=1,displayiters=1000,saveiters=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['Nose', 'Head', 'Eye'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_SideviewLeft_Feb2022Feb8\\\\SideviewLeft_Feb2022_Arash95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\DKLAb\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'E:\\\\DLC\\\\SideviewLeft_Feb2022-Arash-2022-02-08\\\\dlc-models\\\\iteration-0\\\\SideviewLeft_Feb2022Feb8-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\DLC\\SideviewLeft_Feb2022-Arash-2022-02-08/evaluation-results/  already exists!\n",
      "E:\\DLC\\SideviewLeft_Feb2022-Arash-2022-02-08\\evaluation-results\\iteration-0\\SideviewLeft_Feb2022Feb8-trainset95shuffle1  already exists!\n",
      "Running  DLC_resnet50_SideviewLeft_Feb2022Feb8shuffle1_271000  with # of trainingiterations: 271000\n",
      "This net has already been evaluated!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file,Shuffles=[1], plotting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [],
   "source": [
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_R-Arash-2020-02-28\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml';\n",
    "#path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19-Arash-2020-03-26\\\\config.yaml'\n",
    "#path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19LR_R-Arash-2020-04-30\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\videos\\\\ar21\\\\2020-07-06\\\\ar21_07_06_20Face2-Arash-2020-07-07\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face3-Arash-2020-09-16\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar19_09_15_20Face3-Arash-2020-09-16\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\videos\\\\ar32\\\\2020_10_09\\\\ar32_10_09_20Face3-Arash-2020-10-10\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\videos\\\\ar30\\\\ar30_10_11_04-Arash-2020-11-05\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\videos\\\\ar32\\\\ar32_10_11_24-Arash-2020-11-25\\\\config.yaml';\n",
    "\n",
    "import os\n",
    "#path_config_file = 'D:\\\\notebook\\\\ar30_10_10_14spouts-Arash-2020-10-24\\\\config.yaml';\n",
    "Mainfolder = 'E:\\\\movies\\\\ar2breathing\\\\10_06_19'\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019'\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19'\n",
    "Mainfolder = 'E:\\\\movies\\\\MUSCIMOL\\\\ar19tear19salin\\\\10_08_19'\n",
    "Mainfolder = 'D:\\\\videos\\\\ar32\\\\2020_11_24'\n",
    "Mainfolder = 'D:\\\\Sidevideos\\\\ar30motor\\\\2021_07_09'\n",
    "Mainfolder = 'D:\\\\Sidevideos\\\\ar32motor\\\\2021_08_02'\n",
    "\n",
    "\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('R.avi') and not f.endswith('L.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.mp4') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "\n",
    "#path_config_file = 'F:\\\\ar19muscimol500ug500nlrightside\\\\10_10_19\\\\ar19_10102019-Fassihi-2019-11-12\\\\config.yaml';\n",
    "\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml'\n",
    "##text_files = ['']\n",
    "#text_files = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\20-18-27.avi'\n",
    "\n",
    "print(text_files)\n",
    "#deeplabcut.analyze_videos(path_config_file,text_files[1:len(text_files)],shuffle=1, save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,text_files[3],shuffle=1, save_as_csv=True)\n",
    "deeplabcut.analyze_videos(path_config_file,text_files,shuffle=1, save_as_csv=True)\n",
    "deeplabcut.filterpredictions(path_config_file,text_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track non tracked files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track non tracked files \n",
    "import os\n",
    "path_config_file = 'F:\\\\ar2breathing\\\\10_06_19\\\\ar2_10062019_ii-Fassihi-2019-10-07\\\\config.yaml';\n",
    "\n",
    "Mainfolder = 'Y:\\\\movies_Rat_SC_project\\\\ar2breathing\\\\10_06_19'\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('breathing.avi')]\n",
    "text_files2 = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('L.avi') ]\n",
    "#print(text_files)\n",
    "#%whos\n",
    "\n",
    "text_files3 = [f.replace(\"L.\", \".\") for f in text_files2 ]\n",
    "one_not_two = set(text_files) - set(text_files3)\n",
    "one_not_two = 'Y:\\\\movies_Rat_SC_project\\\\ar2breathing\\\\10_06_19\\\\22-25-05.avi'\n",
    "print(one_not_two)\n",
    "deeplabcut.analyze_videos(path_config_file,one_not_two,shuffle=1, save_as_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track Tracklets and then filter for multiple animals (maybe whiskers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mainfolder = 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\'\n",
    "import os\n",
    "\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "print(text_files)\n",
    "deeplabcut.convert_detections2tracklets(path_config_file, text_files, videotype='avi',\n",
    "                                                    shuffle=1, trainingsetindex=0, track_method='skeleton')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.refine_tracklets(path_config_file, pickle_or_h5_file, videofile_path, min_swap_len=2, min_tracklet_len=2, trail_len=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter the results using median model\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "deeplabcut.filterpredictions(path_config_file,text_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.plot_trajectories(path_config_file,text_files,filtered = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first we create a vector of destination file names\n",
    "import os \n",
    "\n",
    "dirname = os.path.dirname(text_files[1]) \n",
    "\n",
    "thesenames= [os.path.basename(f)  for f in text_files] \n",
    "text_files2 = [os.path.join( os.path.join(os.path.dirname(text_files[1]),'labled'),f) for f in thesenames ]  \n",
    "\n",
    "#os.mkdir\n",
    "if not (os.path.isdir(os.path.join(os.path.dirname(text_files[1]),'labled'))):\n",
    " os.mkdir(os.path.join(os.path.dirname(text_files[1]),'labled'))\n",
    "# Print the directory name   \n",
    "print(text_files2[1]) \n",
    "for f in text_files:\n",
    "\n",
    "#deeplabcut.create_labeled_video(path_config_file,videofile,save_frames=True) # my_new_list was created in prevouse cell as all videos in the folder \n",
    "#deeplabcut.create_labeled_video(path_config_file,[text_files[0],text_files2[0]],save_frames=True)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [This is important step actually]\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. Make sure to provide the correct value of the \"iterations\" as it will be used to create the unique directory where the extracted frames will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video=['D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\analyzed\\\\18-37-27.avi']\n",
    "#video=['D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\17-33-50video.mp4']\n",
    "#video=['D:\\\\Dropbox\\\\ar17\\\\02_25_19\\\\22-37-23.avi']\n",
    "video = ['D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\11-09-14.avi']\n",
    "video = ['D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-19-45.avi','D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-31-05.avi','D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-30-40.avi']\n",
    "#15-17-08v\n",
    "video = ['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-27-18.avi','D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-47.avi']\n",
    "video = ['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-26video.mp4']\n",
    "video = ['E:\\\\movies\\\\ar2breathing\\\\10_06_19\\\\21-57-55L.avi']\n",
    "video = text_files[0]\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml';\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019-Fassihi-2019-03-12\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19\\\\sc_ar14_06182019-Fassihi-2019-06-19\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "print(path_config_file)\n",
    "\n",
    "#deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',p_bound=.6)\n",
    "#deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',comparisonbodyparts =  ['nose','snout'],p_bound=.6)\n",
    "deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',p_bound=.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [],
   "source": [
    "\n",
    "path_config_file = 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19\\\\sc_ar19_02072019-Fassihi4-2019-02-13\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "import os\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19'\n",
    "\n",
    "\n",
    "f = os.listdir(Mainfolder)\n",
    "text_files = [f for f in os.listdir(Mainfolder) if f.endswith('.avi')]\n",
    "\n",
    "\n",
    "my_list = text_files\n",
    "thisApen = Mainfolder+'kir'\n",
    "thisApen = thisApen.replace(\"kir\", \"\\\\\")\n",
    "string = thisApen\n",
    "my_new_list = [ string + x for x in my_list]\n",
    "\n",
    "deeplabcut.extract_outlier_frames(path_config_file,my_new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [],
   "source": [
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "#import matplotlib\n",
    "#print(matplotlib.__version__)\n",
    "%gui wx\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019-Fassihi-2019-03-12\\\\config.yaml'\n",
    "#print(path_config_file)\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [],
   "source": [
    "#Once all folders are relabeled, check them and advance. See how to check labels, above!\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refine labels, append these frames to the original dataset to create a new iteration of training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_of_ints = list(range(2))\n",
    "print(list_of_ints)\n",
    "deeplabcut.create_training_dataset(path_config_file,Shuffles= list_of_ints) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos (optional)\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook #for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,my_new_list)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
