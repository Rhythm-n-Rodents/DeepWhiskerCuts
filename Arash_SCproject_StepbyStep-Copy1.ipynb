{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# DeepLabCut Toolbox\n",
    "https://github.com/AlexEMG/DeepLabCut\n",
    "\n",
    "\n",
    "This notebook demonstrates the necessary steps to use python and DeepLabCut for creating and analysins videos from orientation \n",
    "experiment \n",
    "\n",
    "This notebook illustrates how to:\n",
    " \n",
    "- make a movie from images \n",
    "- create a project\n",
    "- extract training frames\n",
    "- label the frames\n",
    "- plot the labeled images (optional)\n",
    "- create a training set\n",
    "- train a network\n",
    "- evaluate a network\n",
    "- analyze a novel video\n",
    "- create an automatically labeled video (optional)\n",
    "- Go to Matlab \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Make  movie from images \n",
    "\n",
    "this step is to produce movie per trial. Each trial forlder contains around 600 images from each trial and the second row of each image.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['13-11-35', '23-38-41', '23-38-47', '23-38-59', '23-42-17', '23-43-13', '23-43-44', '23-44-15', '23-44-47', '23-45-18', '23-46-38', '23-51-40', '23-52-15', '23-53-25', '23-54-05', '23-54-29', '23-54-51', '23-55-13', '23-55-37', '23-56-00', '23-56-34', '23-57-05', '23-57-34', '23-58-12', '23-58-40', '23-59-08', '23-59-36']\n",
      "F:\\ar2breathing\\10_09_19\\23-42-17.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-43-13.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-43-44.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-44-15.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-44-47.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-45-18.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-46-38.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-51-40.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-52-15.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-53-25.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-54-05.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-54-29.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-54-51.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-55-13.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-55-37.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-56-00.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-56-34.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-57-05.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-57-34.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-58-12.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-58-40.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-59-08.avi\n",
      "F:\\ar2breathing\\10_09_19\\23-59-36.avi\n"
     ]
    }
   ],
   "source": [
    "# enter the folder name \n",
    "Mainfolder = 'F:\\\\ar2breathing\\\\10_09_19';\n",
    "#F:\\ar2breathing\\10_18_19\n",
    "# entries for the xls file\n",
    "Namesforarray =['Trialnumber','Licknumber','sidethatanimalshouldgo','timeinsecond','sensservomotor','movespots','correct','lickoccured','lihgontrials','allpulsesoflight','lightduration','Frequ','timestamp','RD'];\n",
    "\n",
    "import os # this is to get folder information and creat files \n",
    "import cv2 # this is important and is reading and writing images and video \n",
    "import subprocess \n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import xlsxwriter  # this is to write xls files \n",
    "from PIL import Image\n",
    "# define a functino to convert video_input into  video_output in mpeg format\n",
    "def convert_video(video_input, video_output):\n",
    "    cmds = ['ffmpeg', '-i', video_input, video_output]\n",
    "    subprocess.Popen(cmds)\n",
    "\n",
    "\n",
    "                                                                                                                        \n",
    "Ratid = 50019;\n",
    "this_date = 100819\n",
    "col = 0\n",
    "included_extensions = ['.png']\n",
    "K_kir = Mainfolder;\n",
    "All_Folders = os.listdir(Mainfolder)\n",
    "print(All_Folders)\n",
    "for num in range(0,len(All_Folders)):     #to iterate between 10 to 20\n",
    "\n",
    " KK = os.path.join(K_kir+os.sep, All_Folders[num])\n",
    " KKavi =  os.path.join(K_kir+os.sep, All_Folders[num]+'.avi')\n",
    " if os.path.isfile(KKavi):\n",
    "   continue\n",
    " if not os.path.isdir(KK):\n",
    "   continue\n",
    " dirContents = os.listdir(KK)\n",
    " if len(dirContents) == 0:\n",
    "  shutil.rmtree(KK, ignore_errors=False, onerror=None)\n",
    "  continue\n",
    " os.chdir(KK)\n",
    " my_file = os.path.join(K_kir,All_Folders[num]+'.xlsx');\n",
    " workbook = xlsxwriter.Workbook(my_file)\n",
    " worksheet = workbook.add_worksheet()\n",
    " files = filter(os.path.isfile, os.listdir(KK));\n",
    " files = [os.path.join(KK, f) for f in files] # add path to each file\n",
    " files.sort(key=lambda x: os.path.getmtime(x))\n",
    " nEWfiles = [os.path.splitext(os.path.basename(f)) for f in  files] # add path to each file\n",
    " nEWfiles = [int(f[0]) for f in nEWfiles]\n",
    " nEWfiles = sorted(nEWfiles)\n",
    " files = [os.path.join(KK, str(f)+'.png' )  for f in nEWfiles] # add path to each file\n",
    " video_name = (KK + '.avi');\n",
    " video_name2 =(KK+'video'+ '.mp4');\n",
    " print(video_name)\n",
    " frame = cv2.imread(os.path.join(Mainfolder, files[0]))\n",
    " height, width, layers = frame.shape\n",
    " video = cv2.VideoWriter(video_name, 0, 1, (width,height))\n",
    " fps = 100\n",
    " images = files\n",
    " worksheet.write_row(0, 0, Namesforarray)\n",
    " for idx,image in enumerate(images):\n",
    "  #worksheet.write_row( idx+1,col, mat)\n",
    "  frame = cv2.imread(os.path.join(Mainfolder, images[idx]))\n",
    "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY);\n",
    "  Mylist = np.array(gray[1,0:12]);\n",
    "  mat1_single = np.reshape(Mylist, -1)\n",
    "  mat = np.concatenate((mat1_single,[Ratid],[this_date]))\n",
    "  worksheet.write_row( idx+1,col, mat)\n",
    "  video.write(frame)\n",
    " workbook.close()\n",
    " cv2.destroyAllWindows()\n",
    " video.release()\n",
    " #os.chdir(Mainfolder)\n",
    " #shutil.rmtree(KK, ignore_errors=Fal``se, onerror=None)\n",
    " convert_video(video_name, video_name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Create a new project\n",
    "\n",
    "It is always good idea to keep the projects seperate. This function creates a new project with subdirectories and a basic configuration file in the user defined directory otherwise the project is created in the current working directory.\n",
    "\n",
    "You can always add new videos to the project at any stage of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [],
   "source": [
    "import deeplabcut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\videos\"\n",
      "Created \"F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\labeled-data\"\n",
      "Created \"F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\training-datasets\"\n",
      "Created \"F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\dlc-models\"\n",
      "Copying the videos\n",
      "F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\videos\\00-00-00video.mp4\n",
      "F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\videos\\00-00-22video.mp4\n",
      "F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\videos\\00-00-46video.mp4\n",
      "Generated \"F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\config.yaml\"\n",
      "\n",
      "A new project with name ar2breathing10_10_19-Fassihi2-2019-12-18 is created at F:\\ar2breathing\\10_10_19 and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'F:\\\\ar2breathing\\\\10_10_19\\\\ar2breathing10_10_19-Fassihi2-2019-12-18\\\\config.yaml'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task='ar2breathing10_10_19' # Enter the name of your experiment Task\n",
    "experimenter='Fassihi2' # Enter the name of the experimenter\n",
    "video=['D:\\\\Notebook\\\\sc\\\\sc-Fassihi-2018-12-16\\\\videos\\\\video14-23-08.avi'] \n",
    "video=['D:\\\\rat movies SC\\\\ar17\\\\01_11_19\\\\video12-29-40.avi'] \n",
    "video=['D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\analyzed\\\\18-36-10video.MP4']\n",
    "video=['D:\\\\movies_Rat_SC_project\\\\ar20\\\\07_08_19\\\\19-28-43video.mp4','D:\\\\movies_Rat_SC_project\\\\ar20\\\\07_08_19\\\\19-28-58video.mp4','D:\\\\movies_Rat_SC_project\\\\ar20\\\\07_08_19\\\\19-29-06video.mp4'] \n",
    "#Mainfolder = 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19'\n",
    "video=['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-26video.mp4','D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-02video.mp4','D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-26-36video.mp4'] \n",
    "video=['F:\\\\ar2breathing\\\\10_10_19\\\\00-00-00video.mp4','F:\\\\ar2breathing\\\\10_10_19\\\\00-00-22video.mp4','F:\\\\ar2breathing\\\\10_10_19\\\\00-00-46video.mp4'] \n",
    "\n",
    "Mainfolder = 'F:\\\\ar2breathing\\\\10_10_19';\n",
    "\n",
    "#D:\\rat movies SC\\ar15\\01_11_19\n",
    "# Enter the paths of your videos you want to grab frames from.\n",
    "# deeplabcut.create_new_project(task,experimenter,video, working_directory='Full path of the working directory',copy_videos=True/False) #change the working directory to where you want the folders created.\n",
    "deeplabcut.create_new_project(task,experimenter,video, working_directory=Mainfolder,copy_videos=True) #change the working directory to where you want the folders created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yXW0bx1oEJA"
   },
   "source": [
    "## Extract frames from videos \n",
    "A key point for a successful feature detector is to select diverse frames, which are typical for the behavior you study that should be labeled.\n",
    "\n",
    "This function selects N frames either uniformly sampled from a particular video (or folder) (algo=='uniform'). Note: this might not yield diverse frames, if the behavior is sparsely distributed (consider using kmeans), and/or select frames manually etc.\n",
    "\n",
    "Also make sure to get select data from different (behavioral) sessions and different animals if those vary substantially (to train an invariant feature detector).\n",
    "\n",
    "Individual images should not be too big (i.e. < 850 x 850 pixel). Although this can be taken care of later as well, it is advisable to crop the frames, to remove unnecessary parts of the frame as much as possible.\n",
    "\n",
    "Always check the output of cropping. If you are happy with the results proceed to labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1ulumCuoEJC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Do you want to extract (perhaps additional) frames for video: F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\videos\\00-00-00video.mp4 ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 1200.0  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\videos\\00-00-22video.mp4 ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 1200.0  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\videos\\00-00-46video.mp4 ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 1200.0  seconds.\n",
      "\n",
      "Frames were selected.\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "path_config_file = 'F:\\\\ar2breathing\\\\10_10_19\\\\ar2breathing10_10_19-Fassihi2-2019-12-18\\\\config.yaml'\n",
    "#Enter the path of the config file that was just created from the above step (check the folder)\n",
    "deeplabcut.extract_frames(path_config_file,'automatic','uniform',crop=True) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n",
    "#deeplabcut.extract_frames(path_config_file,'automatic','uniform',crop=True, checkcropping=True) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n",
    "#You can change the cropping to false, then delete the checkcropping part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\sc_ar20_06202019-Fassihi-2019-06-20\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar20\\\\07_08_19\\\\sc_ar20_07082019-Fassihi3-2019-07-09\\\\config.yaml'\n",
    "path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\09_17_19\\\\ar14_09172019_ii-Fassihi-2019-09-17\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19_10102019-Fassihi-2019-11-12\\\\config.yaml'\n",
    "path_config_file = 'D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\ar19_10082019-Fassihi-2019-11-25\\\\config.yaml'\n",
    "path_config_file = 'D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19_waterspouts\\\\ar19_10082019_waterspouts-Fassihi-2019-11-28\\\\config.yaml'\n",
    "path_config_file = 'F:\\\\ar2breathing\\\\10_10_19\\\\ar2breathing10_10_19-Fassihi2-2019-12-18\\\\config.yaml'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gjn6ZDonoEJH"
   },
   "source": [
    "## Label the extracted frames\n",
    "Only videos in the config file can be used to extract the frames. Extracted labels for each video are stored in the project directory under the subdirectory **'labeled-data'**. Each subdirectory is named after the name of the video. The toolbox has a labeling toolbox which could be used for labeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyROSOiEoEJI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "%gui wx\n",
    "#path_config_file = 'D:\\\\rat movies SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019-Fassihi-2019-03-12\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml'\n",
    "\n",
    "deeplabcut.label_frames(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vim95ZvkPSeN"
   },
   "source": [
    "**Check the labels**\n",
    "\n",
    "Checking if the labels were created and stored correctly is beneficial for training, since labeling is one of the most critical parts for creating the training dataset. The DeepLabCut toolbox provides a function `check\\_labels'  to do so. It is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwvgPJouPP2O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Fassihi2.\n",
      "They are stored in the following folder: F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\labeled-data\\00-00-00video_labeled.\n",
      "They are stored in the following folder: F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\labeled-data\\00-00-22video_labeled.\n",
      "They are stored in the following folder: F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\labeled-data\\00-00-46video_labeled.\n",
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    }
   ],
   "source": [
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar2breathing\\\\10_04_19\\\\ar14_09172019_ii-Fassihi-2019-10-05\\\\config.yaml'\n",
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "of87fOjgPqzH"
   },
   "source": [
    "If the labels need adjusted, you can use the refinement GUI to move them around! Check that out below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "This function generates the training data information for DeepCut (which requires a mat file) based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles. \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar2breathing\\\\10_04_19\\\\ar14_09172019_ii-Fassihi-2019-10-05\\\\config.yaml'\n",
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training - If you want to use a CPU, continue. \n",
    "### If yu want to use your GPU, you need to exit here and either work from the Docker container, your own TensorFlow installation in an Anaconda env\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['Nose', 'Snout', 'Head'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar2breathing10_10_19Dec18\\\\ar2breathing10_10_19_Fassihi295shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Arash\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar2breathing10_10_19Dec18\\\\Documentation_data-ar2breathing10_10_19_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'F:\\\\ar2breathing\\\\10_10_19\\\\ar2breathing10_10_19-Fassihi2-2019-12-18',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'F:\\\\ar2breathing\\\\10_10_19\\\\ar2breathing10_10_19-Fassihi2-2019-12-18\\\\dlc-models\\\\iteration-0\\\\ar2breathing10_10_19Dec18-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'use_gt_segm': False,\n",
      " 'video': False,\n",
      " 'video_batch': False,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt\n",
      "Display_iters overwritten as 1000\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'F:\\\\ar2breathing\\\\10_10_19\\\\ar2breathing10_10_19-Fassihi2-2019-12-18\\\\dlc-models\\\\iteration-0\\\\ar2breathing10_10_19Dec18-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'dataset_type': 'default', 'use_gt_segm': False, 'batch_size': 1, 'video': False, 'video_batch': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2]], 'all_joints_names': ['Nose', 'Snout', 'Head'], 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar2breathing10_10_19Dec18\\\\ar2breathing10_10_19_Fassihi295shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\Arash\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar2breathing10_10_19Dec18\\\\Documentation_data-ar2breathing10_10_19_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 3, 'pos_dist_thresh': 17, 'project_path': 'F:\\\\ar2breathing\\\\10_10_19\\\\ar2breathing10_10_19-Fassihi2-2019-12-18', 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000 loss: 0.0248 lr: 0.005\n",
      "iteration: 2000 loss: 0.0125 lr: 0.005\n",
      "iteration: 3000 loss: 0.0101 lr: 0.005\n",
      "iteration: 4000 loss: 0.0081 lr: 0.005\n",
      "iteration: 5000 loss: 0.0075 lr: 0.005\n",
      "iteration: 6000 loss: 0.0067 lr: 0.005\n",
      "iteration: 7000 loss: 0.0063 lr: 0.005\n",
      "iteration: 8000 loss: 0.0058 lr: 0.005\n",
      "iteration: 9000 loss: 0.0059 lr: 0.005\n",
      "iteration: 10000 loss: 0.0052 lr: 0.005\n",
      "iteration: 11000 loss: 0.0088 lr: 0.02\n",
      "iteration: 12000 loss: 0.0072 lr: 0.02\n",
      "iteration: 13000 loss: 0.0063 lr: 0.02\n",
      "iteration: 14000 loss: 0.0059 lr: 0.02\n",
      "iteration: 15000 loss: 0.0054 lr: 0.02\n",
      "iteration: 16000 loss: 0.0051 lr: 0.02\n",
      "iteration: 17000 loss: 0.0050 lr: 0.02\n",
      "iteration: 18000 loss: 0.0047 lr: 0.02\n",
      "iteration: 19000 loss: 0.0046 lr: 0.02\n",
      "iteration: 20000 loss: 0.0044 lr: 0.02\n",
      "iteration: 21000 loss: 0.0041 lr: 0.02\n",
      "iteration: 22000 loss: 0.0042 lr: 0.02\n",
      "iteration: 23000 loss: 0.0039 lr: 0.02\n",
      "iteration: 24000 loss: 0.0037 lr: 0.02\n",
      "iteration: 25000 loss: 0.0037 lr: 0.02\n",
      "iteration: 26000 loss: 0.0039 lr: 0.02\n",
      "iteration: 27000 loss: 0.0038 lr: 0.02\n",
      "iteration: 28000 loss: 0.0036 lr: 0.02\n",
      "iteration: 29000 loss: 0.0034 lr: 0.02\n",
      "iteration: 30000 loss: 0.0034 lr: 0.02\n",
      "iteration: 31000 loss: 0.0034 lr: 0.02\n",
      "iteration: 32000 loss: 0.0032 lr: 0.02\n",
      "iteration: 33000 loss: 0.0032 lr: 0.02\n",
      "iteration: 34000 loss: 0.0034 lr: 0.02\n",
      "iteration: 35000 loss: 0.0030 lr: 0.02\n",
      "iteration: 36000 loss: 0.0030 lr: 0.02\n",
      "iteration: 37000 loss: 0.0031 lr: 0.02\n",
      "iteration: 38000 loss: 0.0033 lr: 0.02\n",
      "iteration: 39000 loss: 0.0032 lr: 0.02\n",
      "iteration: 40000 loss: 0.0030 lr: 0.02\n",
      "iteration: 41000 loss: 0.0029 lr: 0.02\n",
      "iteration: 42000 loss: 0.0030 lr: 0.02\n",
      "iteration: 43000 loss: 0.0029 lr: 0.02\n",
      "iteration: 44000 loss: 0.0030 lr: 0.02\n",
      "iteration: 45000 loss: 0.0029 lr: 0.02\n",
      "iteration: 46000 loss: 0.0029 lr: 0.02\n",
      "iteration: 47000 loss: 0.0029 lr: 0.02\n",
      "iteration: 48000 loss: 0.0028 lr: 0.02\n",
      "iteration: 49000 loss: 0.0028 lr: 0.02\n",
      "iteration: 50000 loss: 0.0028 lr: 0.02\n",
      "iteration: 51000 loss: 0.0029 lr: 0.02\n",
      "iteration: 52000 loss: 0.0027 lr: 0.02\n",
      "iteration: 53000 loss: 0.0027 lr: 0.02\n",
      "iteration: 54000 loss: 0.0029 lr: 0.02\n",
      "iteration: 55000 loss: 0.0027 lr: 0.02\n",
      "iteration: 56000 loss: 0.0028 lr: 0.02\n",
      "iteration: 57000 loss: 0.0026 lr: 0.02\n",
      "iteration: 58000 loss: 0.0027 lr: 0.02\n",
      "iteration: 59000 loss: 0.0027 lr: 0.02\n",
      "iteration: 60000 loss: 0.0026 lr: 0.02\n",
      "iteration: 61000 loss: 0.0027 lr: 0.02\n",
      "iteration: 62000 loss: 0.0025 lr: 0.02\n",
      "iteration: 63000 loss: 0.0029 lr: 0.02\n",
      "iteration: 64000 loss: 0.0027 lr: 0.02\n",
      "iteration: 65000 loss: 0.0026 lr: 0.02\n",
      "iteration: 66000 loss: 0.0026 lr: 0.02\n",
      "iteration: 67000 loss: 0.0025 lr: 0.02\n",
      "iteration: 68000 loss: 0.0024 lr: 0.02\n",
      "iteration: 69000 loss: 0.0024 lr: 0.02\n",
      "iteration: 70000 loss: 0.0025 lr: 0.02\n",
      "iteration: 71000 loss: 0.0024 lr: 0.02\n",
      "iteration: 72000 loss: 0.0024 lr: 0.02\n",
      "iteration: 73000 loss: 0.0025 lr: 0.02\n",
      "iteration: 74000 loss: 0.0025 lr: 0.02\n",
      "iteration: 75000 loss: 0.0023 lr: 0.02\n",
      "iteration: 76000 loss: 0.0022 lr: 0.02\n",
      "iteration: 77000 loss: 0.0023 lr: 0.02\n",
      "iteration: 78000 loss: 0.0021 lr: 0.02\n",
      "iteration: 79000 loss: 0.0023 lr: 0.02\n",
      "iteration: 80000 loss: 0.0023 lr: 0.02\n",
      "iteration: 81000 loss: 0.0023 lr: 0.02\n",
      "iteration: 82000 loss: 0.0022 lr: 0.02\n",
      "iteration: 83000 loss: 0.0023 lr: 0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-25efc44a6b39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, gputouse, max_snapshots_to_keep, autotune, displayiters, saveiters, maxiters)\u001b[0m\n\u001b[0;32m     87\u001b[0m           \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m       \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m           \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, gputouse, max_snapshots_to_keep, autotune, displayiters, saveiters, maxiters)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m           \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mcurrent_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         [_, loss_val, summary] = sess.run([train_op, total_loss, merged_summaries],\n\u001b[1;32m--> 142\u001b[1;33m                                           feed_dict={learning_rate: current_lr})\n\u001b[0m\u001b[0;32m    143\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mtrain_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#path_config_file = 'D:\\\\rat movies SC\\\\ar19\\\\02_07_19\\\\sc_ar19_02072019-Fassihi4-2019-02-13\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\rat movies SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019-Fassihi-2019-03-12\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_confic_file = 'D:\\rat_movies_SC\\ar17record\\02_27_19\\sc_ar17record_02272019-Fassihi-2019-03-05\\config.yaml'\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019_4-Fassihi-2019-05-02\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "deeplabcut.train_network(path_config_file,shuffle=1,displayiters=1000,saveiters=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['Nose', 'Snout', 'Head'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar2breathing10_10_19Dec18\\\\ar2breathing10_10_19_Fassihi295shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Arash\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar2breathing10_10_19Dec18\\\\Documentation_data-ar2breathing10_10_19_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'F:\\\\ar2breathing\\\\10_10_19\\\\ar2breathing10_10_19-Fassihi2-2019-12-18',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'F:\\\\ar2breathing\\\\10_10_19\\\\ar2breathing10_10_19-Fassihi2-2019-12-18\\\\dlc-models\\\\iteration-0\\\\ar2breathing10_10_19Dec18-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'use_gt_segm': False,\n",
      " 'video': False,\n",
      " 'video_batch': False,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DeepCut_resnet50_ar2breathing10_10_19Dec18shuffle1_83000  with # of trainingiterations: 83000\n",
      "INFO:tensorflow:Restoring parameters from F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\dlc-models\\iteration-0\\ar2breathing10_10_19Dec18-trainset95shuffle1\\train\\snapshot-83000\n",
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [00:07,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-83000\n",
      "Results for 83000  training iterations: 95 1 train error: 2.05 pixels. Test error: 2.9  pixels.\n",
      "With pcutoff of 0.1  train error: 2.05 pixels. Test error: 2.9 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    }
   ],
   "source": [
    "#deeplabcut.evaluate_network(path_config_file)\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml'\n",
    "deeplabcut.evaluate_network(path_config_file,Shuffles=[1], plotting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\ar2breathing\\10_08_19\\18-59-47video.mp4\n",
      "187\n",
      "F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\config.yaml\n",
      "Using snapshot-83000 for model F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\dlc-models\\iteration-0\\ar2breathing10_10_19Dec18-trainset95shuffle1\n",
      "INFO:tensorflow:Restoring parameters from F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\dlc-models\\iteration-0\\ar2breathing10_10_19Dec18-trainset95shuffle1\\train\\snapshot-83000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from F:\\ar2breathing\\10_10_19\\ar2breathing10_10_19-Fassihi2-2019-12-18\\dlc-models\\iteration-0\\ar2breathing10_10_19Dec18-trainset95shuffle1\\train\\snapshot-83000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  F:\\ar2breathing\\10_08_19\\18-56-02video.mp4\n",
      "Loading  F:\\ar2breathing\\10_08_19\\18-56-02video.mp4\n",
      "Duration of video [s]:  1200.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  1200  found with (before cropping) frame dimensions:  1024 390\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/1200 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#path_config_file = 'D:\\\\Notebook\\\\sc\\\\sc-Fassihi-2018-12-15\\\\config.yaml' # Enter the path of the config file that was just created from the above step (check the folder)\n",
    "whismovie = 4;\n",
    "#videofile_path = ['D:\\\\Notebook\\\\sc\\\\sc-Fassihi-2018-12-16\\\\videos\\\\video14-23-50.avi'] #Enter the list of videos to analyze.\n",
    "#path_config_file = 'D:\\\\rat movies SC\\\\ar19\\\\02_07_19\\\\sc_ar19_02072019-Fassihi4-2019-02-13\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file ='D:\\\\rat movies SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019-Fassihi-2019-03-05\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "import os\n",
    "Mainfolder = 'F:\\\\ar2breathing\\\\10_18_19'\n",
    "\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar17\\\\02_25_19'\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19'\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019'\n",
    "Mainfolder = 'F:\\\\ar2breathing\\\\10_08_19'\n",
    "\n",
    "#text_files = [f for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.mp4') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "video = ['D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_19_19\\\\18-16-44.avi']\n",
    "#video = ['D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\15-51-42.avi','D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_19_19\\\\18-16-44.avi']\n",
    "video = ['D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\15-51-42.avi','D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_19_19\\\\18-16-44.avi']\n",
    "\n",
    "#print(video)\n",
    "video = ['F:\\\\ar2breathing\\\\10_18_19\\\\00-16-30video.mp4']\n",
    "print(text_files[3])\n",
    "print(len(text_files))\n",
    "print(path_config_file)\n",
    "\n",
    "#deeplabcut.analyze_videos(path_config_file,text_files[1:len(text_files)],shuffle=1, save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,text_files[3],shuffle=1, save_as_csv=True)\n",
    "deeplabcut.analyze_videos(path_config_file,text_files,shuffle=1, save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19\\\\15-16-14.avi', 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19\\\\15-16-20.avi', 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19\\\\15-17-08.avi', 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19\\\\15-17-15.avi', 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19\\\\15-17-33.avi', 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19\\\\15-17-50.avi', 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19\\\\15-18-01.avi', 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19\\\\15-18-08.avi']\n"
     ]
    }
   ],
   "source": [
    "print(text_files[2:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml'\n",
    "video=['D:\\\\rat_movies_SC\\\\ar17\\\\02_25_19\\\\22-38-53.avi']\n",
    "deeplabcut.analyze_videos(path_config_file,video,shuffle=1, save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar17\\\\02_25_19'\n",
    "f2 = os.listdir(Mainfolder)\n",
    "text_files = [Mainfolder+'\\\\'+f for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "print(text_files)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [This is important step actually]\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. Make sure to provide the correct value of the \"iterations\" as it will be used to create the unique directory where the extracted frames will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\ar2breathing\\10_18_19\\ar2breathing10_18_19-Fassihi-2019-12-16\\config.yaml\n",
      "network parameters: DeepCut_resnet50_ar2breathing10_18_19Dec16shuffle1_68000\n",
      "Method  uncertain  found  54  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "yes/noyes\n",
      "Frames from video 00-13-17video  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  1400.0 , recorded @  1.0 fps!\n",
      "Overall # of frames:  1400 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1400.0  seconds.\n",
      "Extracting and downsampling... 53  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [00:06,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [21, 1134, 1075, 30, 1122, 160, 49, 152, 1129, 1142, 1131, 161, 1132, 1137, 24, 151, 18, 157, 1124]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: F:\\ar2breathing\\10_18_19\\00-13-17video.mp4 Coordinates for cropping: None\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\00-13-17video.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n"
     ]
    }
   ],
   "source": [
    "#video=['D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\analyzed\\\\18-37-27.avi']\n",
    "#video=['D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\17-33-50video.mp4']\n",
    "#video=['D:\\\\Dropbox\\\\ar17\\\\02_25_19\\\\22-37-23.avi']\n",
    "video = ['D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\11-09-14.avi']\n",
    "video = ['D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-19-45.avi','D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-31-05.avi','D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-30-40.avi']\n",
    "#15-17-08v\n",
    "video = ['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-27-18.avi','D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-47.avi']\n",
    "video = ['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-26video.mp4']\n",
    "video = ['F:\\\\ar2breathing\\\\10_18_19\\\\00-13-17video.mp4']\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019-Fassihi-2019-03-12\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19\\\\sc_ar14_06182019-Fassihi-2019-06-19\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "print(path_config_file)\n",
    "\n",
    "#deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',p_bound=.6)\n",
    "deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',comparisonbodyparts =  ['nose','snout'],p_bound=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\movies_Rat_SC_project\\ar20\\06_20_19\\17-30-40avi\n"
     ]
    }
   ],
   "source": [
    "print(video[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b91127c43abf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMainfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtext_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMainfolder\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.avi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19'"
     ]
    }
   ],
   "source": [
    "\n",
    "path_config_file = 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19\\\\sc_ar19_02072019-Fassihi4-2019-02-13\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "import os\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19'\n",
    "\n",
    "\n",
    "f = os.listdir(Mainfolder)\n",
    "text_files = [f for f in os.listdir(Mainfolder) if f.endswith('.avi')]\n",
    "\n",
    "\n",
    "my_list = text_files\n",
    "thisApen = Mainfolder+'kir'\n",
    "thisApen = thisApen.replace(\"kir\", \"\\\\\")\n",
    "string = thisApen\n",
    "my_new_list = [ string + x for x in my_list]\n",
    "\n",
    "deeplabcut.extract_outlier_frames(path_config_file,my_new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot activate multiple GUI eventloops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Windows\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "#import matplotlib\n",
    "#print(matplotlib.__version__)\n",
    "%gui wx\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019-Fassihi-2019-03-12\\\\config.yaml'\n",
    "#print(path_config_file)\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 3.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "#Once all folders are relabeled, check them and advance. See how to check labels, above!\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refine labels, append these frames to the original dataset to create a new iteration of training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "F:\\ar2breathing\\10_18_19\\ar2breathing10_18_19-Fassihi-2019-12-16\\training-datasets\\iteration-3\\UnaugmentedDataSet_ar2breathing10_18_19Dec16  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "list_of_ints = list(range(2))\n",
    "print(list_of_ints)\n",
    "deeplabcut.create_training_dataset(path_config_file,Shuffles= list_of_ints) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\ar2breathing\\10_18_19\\ar2breathing10_18_19-Fassihi-2019-12-16\\config.yaml\n",
      "Starting %  F:\\ar2breathing\\10_18_19 ['F:\\\\ar2breathing\\\\10_18_19\\\\00-16-30video.mp4']\n",
      "Loading  F:\\ar2breathing\\10_18_19\\00-16-30video.mp4 and data.\n",
      "False 0 1024 0 390\n",
      "1200\n",
      "Duration of video [s]:  1200.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  1200 with cropped frame dimensions:  1024 390\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▊                                        | 589/1200 [01:47<02:32,  4.00it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-732b49390e2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvideofile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'F:\\\\ar2breathing\\\\10_18_19\\\\00-16-30video.mp4'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_labeled_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvideofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_frames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# my_new_list was created in prevouse cell as all videos in the folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#deeplabcut.create_labeled_video(path_config_file,text_files,save_frames=True) # my_new_list was created in prevouse cell as all videos in the folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\utils\\make_labeled_video.py\u001b[0m in \u001b[0;36mcreate_labeled_video\u001b[1;34m(config, videos, videotype, shuffle, trainingsetindex, filtered, save_frames, Frames2plot, delete, displayedbodyparts, codec, outputframerate, destfolder)\u001b[0m\n\u001b[0;32m    327\u001b[0m                     \u001b[0mclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[1;31m#CreateVideoSlow(clip,Dataframe,tmpfolder,cfg[\"dotsize\"],cfg[\"colormap\"],cfg[\"alphavalue\"],cfg[\"pcutoff\"],cfg[\"cropping\"],cfg[\"x1\"],cfg[\"x2\"],cfg[\"y1\"],cfg[\"y2\"],delete,DLCscorer,bodyparts)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m                     \u001b[0mCreateVideoSlow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideooutname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtmpfolder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dotsize\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"colormap\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alphavalue\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pcutoff\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcropping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDLCscorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbodyparts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputframerate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFrames2plot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideooutname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcodec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\utils\\make_labeled_video.py\u001b[0m in \u001b[0;36mCreateVideoSlow\u001b[1;34m(videooutname, clip, Dataframe, tmpfolder, dotsize, colormap, alphavalue, pcutoff, cropping, x1, x2, y1, y2, delete, DLCscorer, bodyparts2plot, outputframerate, Frames2plot)\u001b[0m\n\u001b[0;32m    145\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mny\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                 \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mbpindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbodyparts2plot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2698\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2699\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2700\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2701\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1810\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5494\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    628\u001b[0m         \u001b[0mA\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m--> 630\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msafe_masked_invalid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         if (self._A.dtype != np.uint8 and\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36msafe_masked_invalid\u001b[1;34m(x, copy)\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 793\u001b[1;33m         \u001b[0mxm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_invalid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    794\u001b[0m         \u001b[0mxm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshrink_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Arash\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\numpy\\ma\\core.py\u001b[0m in \u001b[0;36mmasked_invalid\u001b[1;34m(a, copy)\u001b[0m\n\u001b[0;32m   2364\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2366\u001b[1;33m         \u001b[0mcondition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m~\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2367\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMaskedArray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2368\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA5FJREFUeJzt1MENwCAQwLDS/Xc+tgCJ2BPklTUzHwDv+28HAHCG4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QMQGL4sE9RSocXsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 737.28x280.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(path_config_file)\n",
    "videofile  = ['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-02.avi','D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-47.avi']\n",
    "videofile = ['F:\\\\ar2breathing\\\\10_18_19\\\\00-16-30video.mp4']\n",
    "\n",
    "deeplabcut.create_labeled_video(path_config_file,videofile,save_frames=True) # my_new_list was created in prevouse cell as all videos in the folder \n",
    "#deeplabcut.create_labeled_video(path_config_file,text_files,save_frames=True) # my_new_list was created in prevouse cell as all videos in the folder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos (optional)\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook #for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,my_new_list)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
