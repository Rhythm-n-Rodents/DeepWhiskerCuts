{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# Arash SC create a project for head position\n",
    "\n",
    "\n",
    "\n",
    "This notebook demonstrates the necessary steps to use python and DeepLabCut for creating and analysins videos from orientation \n",
    "experiment \n",
    "\n",
    "This notebook illustrates how to:\n",
    " \n",
    "- make a movie from images \n",
    "- create a project\n",
    "- extract training frames\n",
    "- label the frames\n",
    "- plot the labeled images (optional)\n",
    "- create a training set\n",
    "- train a network\n",
    "- evaluate a network\n",
    "- analyze a novel video\n",
    "- create an automatically labeled video (optional)\n",
    "- Go to Matlab \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Create a new project\n",
    "\n",
    "It is always good idea to keep the projects seperate. This function creates a new project with subdirectories and a basic configuration file in the user defined directory otherwise the project is created in the current working directory.\n",
    "\n",
    "You can always add new videos to the project at any stage of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [],
   "source": [
    "import deeplabcut\n",
    "## https://github.com/AlexEMG/DeepLabCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\videos\\\\ar21\\\\2020_07_08\\\\5L.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\6L.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror5R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror6R.avi']\n",
      "Created \"D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\videos\"\n",
      "Created \"D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\labeled-data\"\n",
      "Created \"D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\training-datasets\"\n",
      "Created \"D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\dlc-models\"\n",
      "Copying the videos\n",
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\videos\\5L.avi\n",
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\videos\\6L.avi\n",
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\videos\\Mirror5R.avi\n",
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\videos\\Mirror6R.avi\n",
      "Generated \"D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\config.yaml\"\n",
      "\n",
      "A new project with name ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29 is created at D:\\videos\\ar21\\2020_07_08 and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\\\config.yaml'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task='ar21_07_06_20LR_R' # Enter the name of your experiment Task\n",
    "task='ar21_08_06_20LR_LandR_twopoints' # \n",
    "experimenter='Arash' # Enter the name of the experimenter\n",
    "Mainfolder =  'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\'; # Enter the name of the folder with images folders inside \n",
    "filenames = ['5L.avi','6L.avi','Mirror5R.avi','Mirror6R.avi']; # Enter the name of the files you want to train\n",
    "#filenames = ['6L.avi']; # Enter the name of the files you want to train\n",
    "video = [str(Mainfolder)+str(f) for f in filenames]; # add path to each file\n",
    "print(video)\n",
    "#deeplabcut.create_new_project(task,experimenter,video, working_directory=Mainfolder,copy_videos=False) #change the working directory to where you want the folders created.\n",
    "deeplabcut.create_new_project(task,experimenter, video,working_directory=Mainfolder,copy_videos=True, multianimal=False)\n",
    "#deeplabcut.create_new_project(task,experimenter, video,copy_videos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yXW0bx1oEJA"
   },
   "source": [
    "## Extract frames from videos \n",
    "A key point for a successful feature detector is to select diverse frames, which are typical for the behavior you study that should be labeled.\n",
    "\n",
    "This function selects N frames either uniformly sampled from a particular video (or folder) (algo=='uniform'). Note: this might not yield diverse frames, if the behavior is sparsely distributed (consider using kmeans), and/or select frames manually etc.\n",
    "\n",
    "Also make sure to get select data from different (behavioral) sessions and different animals if those vary substantially (to train an invariant feature detector).\n",
    "\n",
    "Individual images should not be too big (i.e. < 850 x 850 pixel). Although this can be taken care of later as well, it is advisable to crop the frames, to remove unnecessary parts of the frame as much as possible.\n",
    "\n",
    "Always check the output of cropping. If you are happy with the results proceed to labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the config path and load deeplabcut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the Path config file path\n",
    "path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19LR_R-Arash-2020-04-30\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar21\\\\2020-07-06\\\\ar21_07_06_20Face2-Arash-2020-07-07\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\Dropbox\\\\Notebook\\\\ar21_08_06_20Face4-Arash-2020-07-15\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_L_M7-Arash-2020-07-22\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_M8-Arash-2020-07-28\\\\config.yaml';\n",
    "path_config_file = 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\\\config.yaml';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying the videos\n",
      "Copying the videos\n",
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n"
     ]
    }
   ],
   "source": [
    "Mainfolder =  'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\'; # Enter the name of the folder with images folders inside \n",
    "filenames = ['20L.avi','21L.avi']; # Enter the name of the files you want to train\n",
    "#filenames = ['6L.avi']; # Enter the name of the files you want to train\n",
    "video = [str(Mainfolder)+str(f) for f in filenames]; # add path to each file\n",
    "deeplabcut.add_new_videos(path_config_file, video, copy_videos=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1ulumCuoEJC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Do you want to extract (perhaps additional) frames for video: D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\videos\\5L.avi ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 2.0  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\videos\\6L.avi ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 1.55  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\videos\\Mirror5R.avi ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 9.97  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\videos\\Mirror6R.avi ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 7.75  seconds.\n",
      "Frames were successfully extracted.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#Enter the path of the config file that was just created from the above step (check the folder)\n",
    "deeplabcut.extract_frames(path_config_file,'automatic','uniform',crop=False) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n",
    "#deeplabcut.extract_frames(path_config_file,'automatic','uniform',crop=True, checkcropping=True) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n",
    "#You can change the cropping to false, then delete the checkcropping part!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gjn6ZDonoEJH"
   },
   "source": [
    "## Label the extracted frames\n",
    "Only videos in the config file can be used to extract the frames. Extracted labels for each video are stored in the project directory under the subdirectory **'labeled-data'**. Each subdirectory is named after the name of the video. The toolbox has a labeling toolbox which could be used for labeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyROSOiEoEJI",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "%gui wx\n",
    "\n",
    "deeplabcut.label_frames(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vim95ZvkPSeN"
   },
   "source": [
    "**Check the labels**\n",
    "\n",
    "Checking if the labels were created and stored correctly is beneficial for training, since labeling is one of the most critical parts for creating the training dataset. The DeepLabCut toolbox provides a function `check\\_labels'  to do so. It is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwvgPJouPP2O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Arash.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 41.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 45.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 44.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 40.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder: Build your skeleton connections before you create a training set!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\ipykernel\\eventloops.py\u001b[0m in \u001b[0;36mon_timer\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mdef\u001b[0m \u001b[0mon_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<deeplabcut.utils.skeleton.SkeletonBuilder at 0x2764c4e9710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.SkeletonBuilder(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "of87fOjgPqzH"
   },
   "source": [
    "If the labels need adjusted, you can use the refinement GUI to move them around! Check that out below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "This function generates the training data information for DeepCut (which requires a mat file) based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles. \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\training-datasets\\iteration-0\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_twopointsJul29  already exists!\n",
      "You passed a split with the following fraction: 95%\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n",
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\training-datasets\\iteration-0\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_twopointsJul29  already exists!\n",
      "You passed a split with the following fraction: 95%\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_training_model_comparison(path_config_file, num_shuffles=1, net_types=['resnet_50'], augmenter_types=['default', 'imgaug'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\training-datasets\\iteration-0\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_twopointsJul29  already exists!\n",
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\dlc-models\\iteration-0\\ar21_08_06_20LR_LandR_twopointsJul29-trainset95shuffle1  already exists!\n",
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\dlc-models\\iteration-0\\ar21_08_06_20LR_LandR_twopointsJul29-trainset95shuffle1/train  already exists!\n",
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\dlc-models\\iteration-0\\ar21_08_06_20LR_LandR_twopointsJul29-trainset95shuffle1/test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([27, 23, 42, 61, 13, 14, 59,  9, 33, 18, 47, 56, 29, 35, 40, 41, 37,\n",
       "          11, 77, 53, 75, 34, 72, 64, 79, 45, 44, 51,  5,  1, 43, 58, 70, 78,\n",
       "          30,  7, 55, 26, 66, 16, 46, 31,  2,  8, 49, 24, 22, 12, 21, 62, 17,\n",
       "          36, 32, 50, 38, 39, 76, 63, 60, 25, 28, 52, 57, 68, 15, 69, 74, 20,\n",
       "           4,  0, 67, 73, 48, 65, 10, 19]), array([ 3,  6, 71, 54])))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#deeplabcut.create_training_dataset(path_config_file)\n",
    "deeplabcut.create_training_dataset(path_config_file, augmenter_type='imgaug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\training-datasets\\iteration-0\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_twopointsJul29  already exists!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'individuals'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2ad61c8ffbe8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_multianimaltraining_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_shuffles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\multiple_individuals_trainingsetmanipulation.py\u001b[0m in \u001b[0;36mcreate_multianimaltraining_dataset\u001b[1;34m(config, num_shuffles, Shuffles, windows2linux, net_type, numdigits)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;31m# multianimal case:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mdataset_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"multi-animal-imgaug\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[0mpartaffinityfield_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauxfun_multianimal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetpafgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprintnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;31m# ATTENTION: order has to be multibodyparts, then uniquebodyparts (for indexing)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Utilizing the following graph:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartaffinityfield_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\utils\\auxfun_multianimal.py\u001b[0m in \u001b[0;36mgetpafgraph\u001b[1;34m(cfg, printnames)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \"\"\"\n\u001b[0;32m     46\u001b[0m     individuals, uniquebodyparts, multianimalbodyparts = extractindividualsandbodyparts(\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mcfg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     )\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# Attention this order has to be consistent (for training set creation, training, inference etc.)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\utils\\auxfun_multianimal.py\u001b[0m in \u001b[0;36mextractindividualsandbodyparts\u001b[1;34m(cfg)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextractindividualsandbodyparts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mindividuals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"individuals\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"uniquebodyparts\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mindividuals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\ruamel\\yaml\\comments.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;31m# type: (Any) -> Any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mordereddict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmerged\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerge_attrib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'individuals'"
     ]
    }
   ],
   "source": [
    "    deeplabcut.create_multianimaltraining_dataset(path_config_file, num_shuffles=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training  \n",
    "### If yu want to use your GPU, you need to exit here and either work from the Docker container, your own TensorFlow installation in an Anaconda env\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['wb1', 'wb2', 'wb3'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_twopointsJul29\\\\ar21_08_06_20LR_LandR_twopoints_Arash95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Tennessee\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_twopointsJul29\\\\Documentation_data-ar21_08_06_20LR_LandR_twopoints_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\\\dlc-models\\\\iteration-0\\\\ar21_08_06_20LR_LandR_twopointsJul29-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with imgaug pose-dataset loader.\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Display_iters overwritten as 1000\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\\\dlc-models\\\\iteration-0\\\\ar21_08_06_20LR_LandR_twopointsJul29-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'weigh_only_present_joints': False, 'pairwise_huber_loss': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2]], 'all_joints_names': ['wb1', 'wb2', 'wb3'], 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_twopointsJul29\\\\ar21_08_06_20LR_LandR_twopoints_Arash95shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\Tennessee\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_twopointsJul29\\\\Documentation_data-ar21_08_06_20LR_LandR_twopoints_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 3, 'pos_dist_thresh': 17, 'project_path': 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29', 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000 loss: 0.0279 lr: 0.005\n",
      "iteration: 2000 loss: 0.0129 lr: 0.005\n",
      "iteration: 3000 loss: 0.0110 lr: 0.005\n",
      "iteration: 4000 loss: 0.0103 lr: 0.005\n",
      "iteration: 5000 loss: 0.0096 lr: 0.005\n",
      "iteration: 6000 loss: 0.0091 lr: 0.005\n",
      "iteration: 7000 loss: 0.0088 lr: 0.005\n",
      "iteration: 8000 loss: 0.0082 lr: 0.005\n",
      "iteration: 9000 loss: 0.0082 lr: 0.005\n",
      "iteration: 10000 loss: 0.0079 lr: 0.005\n",
      "iteration: 11000 loss: 0.0127 lr: 0.02\n",
      "iteration: 12000 loss: 0.0104 lr: 0.02\n",
      "iteration: 13000 loss: 0.0091 lr: 0.02\n",
      "iteration: 14000 loss: 0.0090 lr: 0.02\n",
      "iteration: 15000 loss: 0.0083 lr: 0.02\n",
      "iteration: 16000 loss: 0.0083 lr: 0.02\n",
      "iteration: 17000 loss: 0.0079 lr: 0.02\n",
      "iteration: 18000 loss: 0.0080 lr: 0.02\n",
      "iteration: 19000 loss: 0.0073 lr: 0.02\n",
      "iteration: 20000 loss: 0.0071 lr: 0.02\n",
      "iteration: 21000 loss: 0.0073 lr: 0.02\n",
      "iteration: 22000 loss: 0.0070 lr: 0.02\n",
      "iteration: 23000 loss: 0.0066 lr: 0.02\n",
      "iteration: 24000 loss: 0.0067 lr: 0.02\n",
      "iteration: 25000 loss: 0.0067 lr: 0.02\n",
      "iteration: 26000 loss: 0.0068 lr: 0.02\n",
      "iteration: 27000 loss: 0.0064 lr: 0.02\n",
      "iteration: 28000 loss: 0.0063 lr: 0.02\n",
      "iteration: 29000 loss: 0.0060 lr: 0.02\n",
      "iteration: 30000 loss: 0.0062 lr: 0.02\n",
      "iteration: 31000 loss: 0.0060 lr: 0.02\n",
      "iteration: 32000 loss: 0.0062 lr: 0.02\n",
      "iteration: 33000 loss: 0.0058 lr: 0.02\n",
      "iteration: 34000 loss: 0.0058 lr: 0.02\n",
      "iteration: 35000 loss: 0.0060 lr: 0.02\n",
      "iteration: 36000 loss: 0.0059 lr: 0.02\n",
      "iteration: 37000 loss: 0.0056 lr: 0.02\n",
      "iteration: 38000 loss: 0.0058 lr: 0.02\n",
      "iteration: 39000 loss: 0.0058 lr: 0.02\n",
      "iteration: 40000 loss: 0.0056 lr: 0.02\n",
      "iteration: 41000 loss: 0.0054 lr: 0.02\n",
      "iteration: 42000 loss: 0.0057 lr: 0.02\n",
      "iteration: 43000 loss: 0.0054 lr: 0.02\n",
      "iteration: 44000 loss: 0.0055 lr: 0.02\n",
      "iteration: 45000 loss: 0.0056 lr: 0.02\n",
      "iteration: 46000 loss: 0.0056 lr: 0.02\n",
      "iteration: 47000 loss: 0.0055 lr: 0.02\n",
      "iteration: 48000 loss: 0.0055 lr: 0.02\n",
      "iteration: 49000 loss: 0.0054 lr: 0.02\n",
      "iteration: 50000 loss: 0.0053 lr: 0.02\n",
      "iteration: 51000 loss: 0.0052 lr: 0.02\n",
      "iteration: 52000 loss: 0.0053 lr: 0.02\n",
      "iteration: 53000 loss: 0.0054 lr: 0.02\n",
      "iteration: 54000 loss: 0.0052 lr: 0.02\n",
      "iteration: 55000 loss: 0.0052 lr: 0.02\n",
      "iteration: 56000 loss: 0.0051 lr: 0.02\n",
      "iteration: 57000 loss: 0.0049 lr: 0.02\n",
      "iteration: 58000 loss: 0.0053 lr: 0.02\n",
      "iteration: 59000 loss: 0.0050 lr: 0.02\n",
      "iteration: 60000 loss: 0.0051 lr: 0.02\n",
      "iteration: 61000 loss: 0.0049 lr: 0.02\n",
      "iteration: 62000 loss: 0.0049 lr: 0.02\n",
      "iteration: 63000 loss: 0.0049 lr: 0.02\n",
      "iteration: 64000 loss: 0.0046 lr: 0.02\n",
      "iteration: 65000 loss: 0.0046 lr: 0.02\n",
      "iteration: 66000 loss: 0.0047 lr: 0.02\n",
      "iteration: 67000 loss: 0.0046 lr: 0.02\n",
      "iteration: 68000 loss: 0.0046 lr: 0.02\n",
      "iteration: 69000 loss: 0.0044 lr: 0.02\n",
      "iteration: 70000 loss: 0.0043 lr: 0.02\n",
      "iteration: 71000 loss: 0.0043 lr: 0.02\n",
      "iteration: 72000 loss: 0.0044 lr: 0.02\n",
      "iteration: 73000 loss: 0.0045 lr: 0.02\n",
      "iteration: 74000 loss: 0.0043 lr: 0.02\n",
      "iteration: 75000 loss: 0.0041 lr: 0.02\n",
      "iteration: 76000 loss: 0.0040 lr: 0.02\n",
      "iteration: 77000 loss: 0.0042 lr: 0.02\n",
      "iteration: 78000 loss: 0.0042 lr: 0.02\n",
      "iteration: 79000 loss: 0.0040 lr: 0.02\n",
      "iteration: 80000 loss: 0.0040 lr: 0.02\n",
      "iteration: 81000 loss: 0.0041 lr: 0.02\n",
      "iteration: 82000 loss: 0.0041 lr: 0.02\n",
      "iteration: 83000 loss: 0.0040 lr: 0.02\n",
      "iteration: 84000 loss: 0.0040 lr: 0.02\n",
      "iteration: 85000 loss: 0.0041 lr: 0.02\n",
      "iteration: 86000 loss: 0.0040 lr: 0.02\n",
      "iteration: 87000 loss: 0.0040 lr: 0.02\n",
      "iteration: 88000 loss: 0.0041 lr: 0.02\n",
      "iteration: 89000 loss: 0.0038 lr: 0.02\n",
      "iteration: 90000 loss: 0.0039 lr: 0.02\n",
      "iteration: 91000 loss: 0.0038 lr: 0.02\n",
      "iteration: 92000 loss: 0.0037 lr: 0.02\n",
      "iteration: 93000 loss: 0.0039 lr: 0.02\n",
      "iteration: 94000 loss: 0.0038 lr: 0.02\n",
      "iteration: 95000 loss: 0.0038 lr: 0.02\n",
      "iteration: 96000 loss: 0.0037 lr: 0.02\n",
      "iteration: 97000 loss: 0.0035 lr: 0.02\n",
      "iteration: 98000 loss: 0.0039 lr: 0.02\n",
      "iteration: 99000 loss: 0.0037 lr: 0.02\n",
      "iteration: 100000 loss: 0.0037 lr: 0.02\n",
      "iteration: 101000 loss: 0.0035 lr: 0.02\n",
      "iteration: 102000 loss: 0.0035 lr: 0.02\n",
      "iteration: 103000 loss: 0.0038 lr: 0.02\n",
      "iteration: 104000 loss: 0.0036 lr: 0.02\n",
      "iteration: 105000 loss: 0.0039 lr: 0.02\n",
      "iteration: 106000 loss: 0.0037 lr: 0.02\n",
      "iteration: 107000 loss: 0.0036 lr: 0.02\n",
      "iteration: 108000 loss: 0.0035 lr: 0.02\n",
      "iteration: 109000 loss: 0.0036 lr: 0.02\n",
      "iteration: 110000 loss: 0.0036 lr: 0.02\n",
      "iteration: 111000 loss: 0.0037 lr: 0.02\n",
      "iteration: 112000 loss: 0.0036 lr: 0.02\n",
      "iteration: 113000 loss: 0.0034 lr: 0.02\n",
      "iteration: 114000 loss: 0.0035 lr: 0.02\n",
      "iteration: 115000 loss: 0.0033 lr: 0.02\n",
      "iteration: 116000 loss: 0.0034 lr: 0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8253cc711f6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m                 \u001b[0mallow_growth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m             )  # pass on path and file name for pose_cfg.yaml!\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[0;32m    252\u001b[0m         [_, loss_val, summary] = sess.run(\n\u001b[0;32m    253\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_summaries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcurrent_lr\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m         )\n\u001b[0;32m    256\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file,shuffle=1,displayiters=1000,saveiters=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['wb1', 'wb2', 'wb3'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_twopointsJul29\\\\ar21_08_06_20LR_LandR_twopoints_Arash95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Tennessee\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_twopointsJul29\\\\Documentation_data-ar21_08_06_20LR_LandR_twopoints_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\\\dlc-models\\\\iteration-0\\\\ar21_08_06_20LR_LandR_twopointsJul29-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_resnet50_ar21_08_06_20LR_LandR_twopointsJul29shuffle1_116000  with # of trainingiterations: 116000\n",
      "Initializing ResNet\n",
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:01, 63.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-116000\n",
      "Results for 116000  training iterations: 95 1 train error: 1.37 pixels. Test error: 2.84  pixels.\n",
      "With pcutoff of 0.6  train error: 1.37 pixels. Test error: 2.84 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file,Shuffles=[1], plotting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to crop frames for folder:  D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\labeled-data\\5L ?\n",
      "(yes/no):no\n",
      "Do you want to crop frames for folder:  D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\labeled-data\\6L ?\n",
      "(yes/no):no\n",
      "Do you want to crop frames for folder:  D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\labeled-data\\Mirror5R ?\n",
      "(yes/no):no\n",
      "Do you want to crop frames for folder:  D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\labeled-data\\Mirror6R ?\n",
      "(yes/no):no\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.cropimagesandlabels(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# maDeepLabCut [CRITICAL POINT]:\n",
    "\n",
    "You need to cross validate parameters before inference. Here, you will run the new function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_M8-Arash-2020-07-28\\evaluation-results\\iteration-0\\ar21_08_06_20LR_LandR_M8Jul28-trainset95shuffle1  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3'],\n",
      " 'batch_size': 8,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_M8Jul28\\\\ar21_08_06_20LR_LandR_M8_Arash95shuffle1.pickle',\n",
      " 'dataset_type': 'multi-animal-imgaug',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 500,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Tennessee\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_M8Jul28\\\\Documentation_data-ar21_08_06_20LR_LandR_M8_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minconfidence': 0.01,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 200000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'nmsradius': 5.0,\n",
      " 'num_joints': 3,\n",
      " 'num_limbs': 3,\n",
      " 'num_outputs': 1,\n",
      " 'optimizer': 'adam',\n",
      " 'pafwidth': 20,\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_loss_weight': 0.1,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_graph': [[0, 1], [0, 2], [1, 2]],\n",
      " 'partaffinityfield_predict': True,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_M8-Arash-2020-07-28',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 10000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_M8-Arash-2020-07-28\\\\dlc-models\\\\iteration-0\\\\ar21_08_06_20LR_LandR_M8Jul28-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3'],\n",
      " 'batch_size': 8,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_M8Jul28\\\\ar21_08_06_20LR_LandR_M8_Arash95shuffle1.pickle',\n",
      " 'dataset_type': 'multi-animal-imgaug',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 500,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Tennessee\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_M8Jul28\\\\Documentation_data-ar21_08_06_20LR_LandR_M8_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minconfidence': 0.01,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 200000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'nmsradius': 5.0,\n",
      " 'num_joints': 3,\n",
      " 'num_limbs': 3,\n",
      " 'num_outputs': 1,\n",
      " 'optimizer': 'adam',\n",
      " 'pafwidth': 20,\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_loss_weight': 0.1,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_graph': [[0, 1], [0, 2], [1, 2]],\n",
      " 'partaffinityfield_predict': True,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_M8-Arash-2020-07-28',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 10000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_M8-Arash-2020-07-28\\\\dlc-models\\\\iteration-0\\\\ar21_08_06_20LR_LandR_M8Jul28-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_M8-Arash-2020-07-28\\evaluation-results\\iteration-0\\ar21_08_06_20LR_LandR_M8Jul28-trainset95shuffle1\\DLC_resnet50_ar21_08_06_20LR_LandR_M8Jul28shuffle1_61000-snapshot-61000.h5\n",
      "rpck 0.4274058533447156 rpck train: 0.5465617821401828\n",
      "rmse 2.671441690452579 miss 3.3333333333333335 hit 2.6666666666666665\n",
      "rpck 0.8171225716378936 rpck train: 0.8505130816255133\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.7728165068930348 rpck train: 0.6984763117678787\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.4953223513389355 rpck train: 0.3452612017585131\n",
      "rmse 1.3715207504659115 miss 3.0 hit 3.0\n",
      "rpck 0.8171225716378936 rpck train: 0.8590070072016283\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.7728165068930348 rpck train: 0.7800704658916352\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7316316638027375 rpck train: 0.6943945643982419\n",
      "rmse 4.349920819074306 miss 1.25 hit 4.0\n",
      "rpck 0.7728165068930348 rpck train: 0.8629963437739245\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.8171225716378936 rpck train: 0.8697188766395273\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8298787317603399\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8360384029681021\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.40461742769876374 rpck train: 0.44227721016410676\n",
      "rmse 2.418821269572053 miss 3.5 hit 2.5\n",
      "rpck 0.4830443834954534 rpck train: 0.6122211094735546\n",
      "rmse 2.5686785677963675 miss 2.75 hit 2.5\n",
      "rpck 0.7728165068930348 rpck train: 0.8013969996958733\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.7843886952327096\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.4953223513389355 rpck train: 0.3436657841218512\n",
      "rmse 1.3715207504659115 miss 3.0 hit 3.0\n",
      "rpck 0.4953223513389355 rpck train: 0.3751666235012889\n",
      "rmse 1.3715207504659115 miss 3.0 hit 3.0\n",
      "rpck 0.8171225716378936 rpck train: 0.8444556745722132\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.8171225716378936 rpck train: 0.8298787317603399\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8298787317603399\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8531222811219952\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.6974704668460505 rpck train: 0.7024437203515228\n",
      "rmse 4.156814277661967 miss 1.5 hit 3.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8444556745722132\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8697188766395273\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8505130816255133\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8298787317603399\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8653670146227934\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8590070072016283\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8781299039553009\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8444556745722132\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8298787317603399\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8531222811219952\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.8171225716378936 rpck train: 0.8298787317603399\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8781299039553009\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8590070072016283\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.8171225716378936 rpck train: 0.8298787317603399\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8237690346464915\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.8171225716378936 rpck train: 0.8590070072016283\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.7728165068930348 rpck train: 0.8673257303004336\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.8171225716378936 rpck train: 0.8781299039553009\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.8171225716378936 rpck train: 0.8590070072016283\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.8171225716378936 rpck train: 0.8781299039553009\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8781299039553009\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8673257303004336\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.8171225716378936 rpck train: 0.8360384029681021\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8781299039553009\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.8171225716378936 rpck train: 0.8781299039553009\n",
      "rmse 4.781751922893468 miss 0.5 hit 4.75\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n",
      "rpck 0.7728165068930348 rpck train: 0.8802809298149985\n",
      "rmse 4.275641817457459 miss 1.0 hit 4.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['bodypart1', 'bodypart2', 'bodypart3'],\n",
      " 'batch_size': 8,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_M8Jul28\\\\ar21_08_06_20LR_LandR_M8_Arash95shuffle1.pickle',\n",
      " 'dataset_type': 'multi-animal-imgaug',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 500,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Tennessee\\\\Anaconda3\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_M8Jul28\\\\Documentation_data-ar21_08_06_20LR_LandR_M8_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minconfidence': 0.01,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 200000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'nmsradius': 5.0,\n",
      " 'num_joints': 3,\n",
      " 'num_limbs': 3,\n",
      " 'num_outputs': 1,\n",
      " 'optimizer': 'adam',\n",
      " 'pafwidth': 20,\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_loss_weight': 0.1,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_graph': [[0, 1], [0, 2], [1, 2]],\n",
      " 'partaffinityfield_predict': True,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_M8-Arash-2020-07-28',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 10000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_M8-Arash-2020-07-28\\\\dlc-models\\\\iteration-0\\\\ar21_08_06_20LR_LandR_M8Jul28-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_M8-Arash-2020-07-28\\evaluation-results\\iteration-0\\ar21_08_06_20LR_LandR_M8Jul28-trainset95shuffle1\\DLC_resnet50_ar21_08_06_20LR_LandR_M8Jul28shuffle1_61000-snapshot-61000.h5\n",
      "Saving optimal inference parameters...\n",
      "   train_iter  train_frac  shuffle  rmse_train  hits_train  misses_train  falsepos_train  ndetects_train  pck_train  rpck_train  rmse_test  hits_test  misses_test  falsepos_test  ndetects_test  pck_test  rpck_test\n",
      "0     61000.0        95.0      1.0     2.83285    5.421053      0.447368             0.0        1.947368   0.866009     0.80208   4.275642       4.25          1.0            0.0            1.5      0.75   0.662517\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_multianimal_crossvalidate(path_config_file, Shuffles=[1], edgewisecondition=True, leastbpts=1, init_points=20, n_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save maps(optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29/evaluation-results/  already exists!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\\\training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_twopointsJul29\\\\Documentation_data-ar21_08_06_20LR_LandR_twopoints_95shuffle[1].pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2b058c1aa108>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_save_all_maps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\visualizemaps.py\u001b[0m in \u001b[0;36mextract_save_all_maps\u001b[1;34m(config, shuffle, trainingsetindex, comparisonbodyparts, gputouse, rescale, Indices, modelprefix, dest_folder, nplots_per_row)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[0mrescale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[0mIndices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m         \u001b[0mmodelprefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\visualizemaps.py\u001b[0m in \u001b[0;36mextract_maps\u001b[1;34m(config, shuffle, trainingsetindex, comparisonbodyparts, gputouse, rescale, Indices, modelprefix)\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0mtrainFraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauxiliaryfunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoadMetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"project_path\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadatafn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         )\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\utils\\auxiliaryfunctions.py\u001b[0m in \u001b[0;36mLoadMetadata\u001b[1;34m(metadatafile)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mLoadMetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadatafile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadatafile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m         [\n\u001b[0;32m    379\u001b[0m             \u001b[0mtrainingdata_details\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\\\training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ar21_08_06_20LR_LandR_twopointsJul29\\\\Documentation_data-ar21_08_06_20LR_LandR_twopoints_95shuffle[1].pickle'"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_save_all_maps(path_config_file, shuffle=[1], Indices=[0, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. \n",
    "for R videos use L config file but mirror R videos the scrips to create mirror file is called: **inverseL_Rwhiskermovies**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror10R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror11R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror12R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror13R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror14R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror15R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror16R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror17R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror18R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror19R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror1R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror20R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror21R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror22R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror23R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror24R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror25R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror26R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror27R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror28R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror29R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror2R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror30R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror31R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror32R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror33R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror34R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror35R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror36R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror37R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror38R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror39R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror3R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror40R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror41R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror42R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror43R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror45R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror46R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror47R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror48R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror49R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror4R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror50R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror51R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror52R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror5R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror6R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror7R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror8R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror9R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror10R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror11R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror12R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror13R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror14R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror15R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror16R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror17R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror18R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror19R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror1R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror20R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror21R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror22R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror23R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror24R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror25R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror26R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror27R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror28R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror29R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror2R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror30R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror31R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror32R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror33R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror34R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror35R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror36R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror37R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror38R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror39R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror3R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror40R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror41R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror42R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror43R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror44R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror45R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror46R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror47R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror48R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror49R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror4R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror50R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror51R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror52R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror5R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror6R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror7R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror8R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror9R.avi']\n"
     ]
    }
   ],
   "source": [
    "Mainfolder = 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\'\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "Xfiles = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('R.avi')] # find all files with R.avi as file name\n",
    "Xfiles2 = [Path(f) for f in Xfiles] # make each file name path to extract the parents and anme\n",
    "Xfiles3 = [os.path.join(f.parents[0],'Mirror'+f.name) for f in Xfiles2] # creat a same as files but with Mirror added to the file names\n",
    "Mainfolders =  [os.path.join(f.parents[0],f.stem[:-1]) for f in Xfiles2]\n",
    "print(Xfiles3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror10R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror11R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror12R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror13R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror14R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror15R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror16R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror17R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror18R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror19R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror1R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror20R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror21R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror22R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror23R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror24R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror25R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror26R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror27R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror28R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror29R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror2R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror30R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror31R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror32R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror33R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror34R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror35R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror36R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror37R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror38R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror39R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror3R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror40R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror41R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror42R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror43R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror45R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror46R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror47R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror48R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror49R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror4R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror50R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror51R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror52R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror5R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror6R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror7R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror8R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\Mirror9R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror10R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror11R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror12R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror13R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror14R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror15R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror16R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror17R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror18R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror19R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror1R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror20R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror21R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror22R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror23R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror24R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror25R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror26R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror27R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror28R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror29R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror2R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror30R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror31R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror32R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror33R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror34R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror35R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror36R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror37R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror38R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror39R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror3R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror40R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror41R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror42R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror43R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror44R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror45R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror46R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror47R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror48R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror49R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror4R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror50R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror51R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror52R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror5R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror6R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror7R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror8R.avi', 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\MirrorMirror9R.avi']\n",
      "Using snapshot-116000 for model D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\dlc-models\\iteration-0\\ar21_08_06_20LR_LandR_twopointsJul29-trainset95shuffle1\n",
      "Initializing ResNet\n",
      "Starting to analyze %  D:\\videos\\ar21\\2020_07_08\\Mirror11R.avi\n",
      "D:\\videos\\ar21\\2020_07_08  already exists!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "DLC_resnet50_ar21_08_06_20LR_LandR_twopointsJul29shuffle1_116000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_R-Arash-2020-02-28\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml';\n",
    "#path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19-Arash-2020-03-26\\\\config.yaml'\n",
    "#path_config_file = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\ar2breathing_10_08_19LR_R-Arash-2020-04-30\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\videos\\\\ar21\\\\2020-07-06\\\\ar21_07_06_20Face2-Arash-2020-07-07\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_L_M7-Arash-2020-07-22\\\\config.yaml';\n",
    "#path_config_file = 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_M8-Arash-2020-07-28\\\\config.yaml';\n",
    "import os\n",
    "\n",
    "Mainfolder = 'E:\\\\movies\\\\ar2breathing\\\\10_06_19'\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019'\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19'\n",
    "Mainfolder = 'E:\\\\movies\\\\MUSCIMOL\\\\ar19tear19salin\\\\10_08_19'\n",
    "Mainfolder = 'D:\\\\videos\\\\ar21\\\\2020_07_08'\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('R.avi') and not f.endswith('L.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "text_files = Xfiles3;\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.mp4') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "\n",
    "#path_config_file = 'F:\\\\ar19muscimol500ug500nlrightside\\\\10_10_19\\\\ar19_10102019-Fassihi-2019-11-12\\\\config.yaml';\n",
    "\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml'\n",
    "##text_files = ['']\n",
    "#text_files = 'E:\\\\movies\\\\ar2breathing\\\\10_08_19\\\\20-18-27.avi'\n",
    "\n",
    "print(text_files)\n",
    "#deeplabcut.analyze_videos(path_config_file,text_files[1:len(text_files)],shuffle=1, save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,text_files[3],shuffle=1, save_as_csv=True)\n",
    "scorername=deeplabcut.analyze_videos(path_config_file,text_files[1],shuffle=1, save_as_csv=True)\n",
    "print(scorername)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track non tracked files (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track non tracked files \n",
    "import os\n",
    "path_config_file = 'F:\\\\ar2breathing\\\\10_06_19\\\\ar2_10062019_ii-Fassihi-2019-10-07\\\\config.yaml';\n",
    "\n",
    "Mainfolder = 'Y:\\\\movies_Rat_SC_project\\\\ar2breathing\\\\10_06_19'\n",
    "text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('.avi') and not f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('breathing.avi')]\n",
    "text_files2 = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('L.avi') ]\n",
    "#print(text_files)\n",
    "#%whos\n",
    "\n",
    "text_files3 = [f.replace(\"L.\", \".\") for f in text_files2 ]\n",
    "one_not_two = set(text_files) - set(text_files3)\n",
    "one_not_two = 'Y:\\\\movies_Rat_SC_project\\\\ar2breathing\\\\10_06_19\\\\22-25-05.avi'\n",
    "print(one_not_two)\n",
    "deeplabcut.analyze_videos(path_config_file,one_not_two,shuffle=1, save_as_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track Tracklets and then filter for multiple animals (maybe whiskers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f619b7b1309b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m deeplabcut.convert_detections2tracklets(path_config_file, text_files, videotype='avi',\n\u001b[0;32m      7\u001b[0m                                                     shuffle=1, trainingsetindex=0, track_method='skeleton')\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_files' is not defined"
     ]
    }
   ],
   "source": [
    "Mainfolder = 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\'\n",
    "import os\n",
    "\n",
    "#text_files = [os.path.join(Mainfolder,f) for f in os.listdir(Mainfolder) if f.endswith('L.avi') and not f.endswith('R.avi') and not f.endswith('R.avi') and not f.endswith('videopoints.avi') and not f.endswith('videopoints.avi')]\n",
    "print(text_files)\n",
    "deeplabcut.convert_detections2tracklets(path_config_file, text_files, videotype='avi',\n",
    "                                                    shuffle=1, trainingsetindex=0, track_method='skeleton')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating labeled video for  10L\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\10LDLC_resnet50_ar21_08_06_20LR_LandR_twopointsJul29shuffle1_116000_full.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-78a8471ea5c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#path_config_file = 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_M8-Arash-2020-07-28\\\\config.yaml';\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_video_with_all_detections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorername\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\utils\\make_labeled_video.py\u001b[0m in \u001b[0;36mcreate_video_with_all_detections\u001b[1;34m(config, videos, DLCscorername, displayedbodyparts, destfolder)\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Creating labeled video for \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_pickle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\10LDLC_resnet50_ar21_08_06_20LR_LandR_twopointsJul29shuffle1_116000_full.pickle'"
     ]
    }
   ],
   "source": [
    "#path_config_file = 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\ar21_08_06_20LR_LandR_M8-Arash-2020-07-28\\\\config.yaml';\n",
    "\n",
    "deeplabcut.create_video_with_all_detections(path_config_file, text_files, scorername)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\videos\\ar21\\2020_07_08\\Mirror29R.avi\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\ipykernel\\eventloops.py\u001b[0m in \u001b[0;36mon_timer\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mdef\u001b[0m \u001b[0mon_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<deeplabcut.refine_training_dataset.tracklets.TrackletManager at 0x1e932a5b400>,\n",
       " <deeplabcut.refine_training_dataset.tracklets.TrackletVisualizer at 0x1e932a5b7f0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videofile_path = text_files[20]\n",
    "print (videofile_path)\n",
    "pickle_or_h5_file = 'Mirror29RDLC_resnet50_ar21_08_06_20LR_LandR_M8Jul28shuffle1_61000_sk.pickle'\n",
    "pickle_or_h5_file= os.path.join( os.path.dirname(videofile_path),pickle_or_h5_file)\n",
    "\n",
    "deeplabcut.refine_tracklets(path_config_file, pickle_or_h5_file, videofile_path, min_swap_len=2, min_tracklet_len=2, trail_len=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_L_M7-Arash-2020-07-22\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "print(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter the results using median model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror10R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror11R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror12R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror13R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror14R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror15R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror16R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror17R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror18R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror19R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror1R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror20R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror21R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror22R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror23R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror24R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror25R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror26R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror27R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror28R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror29R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror2R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror30R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror31R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror32R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror33R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror34R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror35R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror36R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror37R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror38R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror39R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror3R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror40R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror41R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror42R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror43R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror45R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror46R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror47R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror48R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror49R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror4R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror50R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror51R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror52R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror5R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror6R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror7R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror8R.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model D:\\videos\\ar21\\2020_07_08\\Mirror9R.avi\n",
      "Saving filtered csv poses!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.filterpredictions(path_config_file,text_files,shuffle=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\videos\\ar21\\2020_07_08\\ar21_08_06_20LR_LandR_twopoints-Arash-2020-07-29\\config.yaml\n",
      "Loading  D:\\videos\\ar21\\2020_07_08\\11L.avi and data.\n",
      "D:\\videos\\ar21\\2020_07_08\\plot-poses\\11L  already exists!\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n"
     ]
    }
   ],
   "source": [
    "print(path_config_file)\n",
    "deeplabcut.create_labeled_video(path_config_file,text_files,save_frames=False)\n",
    "\n",
    "deeplabcut.plot_trajectories(path_config_file,text_files[1],filtered = True,shuffle=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first we create a vector of destination file names\n",
    "import os \n",
    "\n",
    "dirname = os.path.dirname(text_files[1]) \n",
    "thesenames= [os.path.basename(f)  for f in text_files] \n",
    "text_files2 = [os.path.join( os.path.join(os.path.dirname(text_files[1]),'labled'),f) for f in thesenames ]  \n",
    "\n",
    "#os.mkdir\n",
    "if not (os.path.isdir(os.path.join(os.path.dirname(text_files[1]),'labled'))):\n",
    " os.mkdir(os.path.join(os.path.dirname(text_files[1]),'labled'))\n",
    "# Print the directory name   \n",
    "video = 'D:\\\\videos\\\\ar21\\\\2020_07_08\\\\5L.avi'\n",
    "deeplabcut.create_labeled_video(path_config_file,video,save_frames=False)\n",
    "#for f in text_files:\n",
    "#deeplabcut.create_labeled_video(path_config_file,videofile,save_frames=True) # my_new_list was created in prevouse cell as all videos in the folder \n",
    "#deeplabcut.create_labeled_video(path_config_file,f,save_frames=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [This is important step actually]\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. Make sure to provide the correct value of the \"iterations\" as it will be used to create the unique directory where the extracted frames will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\videos\\ar21\\2020_07_08\\12L.avi\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-629ee7a9d71f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',p_bound=.6)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',comparisonbodyparts =  ['nose','snout'],p_bound=.6)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_outlier_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutlieralgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uncertain'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_bound\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py\u001b[0m in \u001b[0;36mextract_outlier_frames\u001b[1;34m(config, videos, videotype, shuffle, trainingsetindex, outlieralgorithm, comparisonbodyparts, epsilon, p_bound, ARdegree, MAdegree, alpha, extractionalgorithm, automatic, cluster_resizewidth, cluster_color, opencv, savelabeled, destfolder, modelprefix, track_method)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mtrainFraction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TrainingFraction\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrainingsetindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[0mmodelprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodelprefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m     )\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\utils\\auxiliaryfunctions.py\u001b[0m in \u001b[0;36mGetScorerName\u001b[1;34m(cfg, shuffle, trainFraction, trainingsiterations, modelprefix)\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[0mincreasing_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mSnapshots\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[0mSnapshots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSnapshots\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mincreasing_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m         \u001b[0mSNP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSnapshots\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msnapshotindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m         \u001b[0mtrainingsiterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSNP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index -1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "#video=['D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\analyzed\\\\18-37-27.avi']\n",
    "#video=['D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\17-33-50video.mp4']\n",
    "#video=['D:\\\\Dropbox\\\\ar17\\\\02_25_19\\\\22-37-23.avi']\n",
    "video = ['D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\11-09-14.avi']\n",
    "video = ['D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-19-45.avi','D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-31-05.avi','D:\\\\movies_Rat_SC_project\\\\ar20\\\\06_20_19\\\\17-30-40.avi']\n",
    "#15-17-08v\n",
    "video = ['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-27-18.avi','D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-47.avi']\n",
    "video = ['D:\\\\rat_movies_SC\\\\ar19tear19salin\\\\10_08_19\\\\00-24-26video.mp4']\n",
    "video = ['E:\\\\movies\\\\ar2breathing\\\\10_06_19\\\\21-57-55L.avi']\n",
    "video = text_files[2]\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar19muscimol\\\\10_10_2019\\\\ar19muscimol10-10-19_LR_L-Arash-2020-03-01\\\\config.yaml';\n",
    "\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar17record\\\\02_27_19\\\\sc_ar17record_02272019_3-Fassihi-2019-04-28\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019-Fassihi-2019-03-12\\\\config.yaml'\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar14\\\\06_18_19\\\\sc_ar14_06182019-Fassihi-2019-06-19\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "print(video)\n",
    "\n",
    "#deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',p_bound=.6)\n",
    "#deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',comparisonbodyparts =  ['nose','snout'],p_bound=.6)\n",
    "deeplabcut.extract_outlier_frames(path_config_file,video,outlieralgorithm='uncertain',p_bound=.9,shuffle=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\videos\\ar21\\2020_07_08\\Mirror12R.avi\n",
      "No unfiltered data file found in D:\\videos\\ar21\\2020_07_08 for video Mirror12R and scorer DLC_resnet50_ar21_08_06_20LR_LandR_M8Jul28shuffle1_61000.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.analyzeskeleton(path_config_file, video, videotype='avi', shuffle=1, trainingsetindex=0, save_as_csv=False, destfolder=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\movies_Rat_SC_project\\ar20\\06_20_19\\17-30-40avi\n"
     ]
    }
   ],
   "source": [
    "print(video[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b91127c43abf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMainfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtext_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMainfolder\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.avi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19'"
     ]
    }
   ],
   "source": [
    "\n",
    "path_config_file = 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19\\\\sc_ar19_02072019-Fassihi4-2019-02-13\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "import os\n",
    "Mainfolder = 'D:\\\\rat_movies_SC\\\\ar19\\\\02_07_19'\n",
    "\n",
    "\n",
    "f = os.listdir(Mainfolder)\n",
    "text_files = [f for f in os.listdir(Mainfolder) if f.endswith('.avi')]\n",
    "\n",
    "\n",
    "my_list = text_files\n",
    "thisApen = Mainfolder+'kir'\n",
    "thisApen = thisApen.replace(\"kir\", \"\\\\\")\n",
    "string = thisApen\n",
    "my_new_list = [ string + x for x in my_list]\n",
    "\n",
    "deeplabcut.extract_outlier_frames(path_config_file,my_new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [],
   "source": [
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "#import matplotlib\n",
    "#print(matplotlib.__version__)\n",
    "%gui wx\n",
    "#path_config_file = 'D:\\\\rat_movies_SC\\\\ar15record\\\\02_27_19\\\\sc_ar15record_02272019-Fassihi-2019-03-12\\\\config.yaml'\n",
    "#print(path_config_file)\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 2.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "#Once all folders are relabeled, check them and advance. See how to check labels, above!\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar1\\\\05_24_19\\\\sc_aa1_05242019-Fassihi-2019-05-30\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "#path_config_file = 'D:\\\\movies_Rat_SC_project\\\\ar3\\\\06_07_19\\\\sc_aa3_06072019-Fassihi-2019-06-10\\\\config.yaml' #Enter the path of the config file that was just created from the above step (check the folder)\n",
    "\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refine labels, append these frames to the original dataset to create a new iteration of training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "list_of_ints = list(range(2))\n",
    "print(list_of_ints)\n",
    "deeplabcut.create_training_dataset(path_config_file,Shuffles= list_of_ints) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos (optional)\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook #for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,my_new_list)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
